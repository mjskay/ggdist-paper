number,url,link,author,title,body,closed,comments,from_users,notes,createdAt,closedAt,labels,reactionGroups,state,updatedAt,milestone,assignees,id
174,https://github.com/mjskay/ggdist/issues/174,https://github.com/mjskay/ggdist/issues/174,arthur-albuquerque,Fill with >1 colors,"Hi Matthew,

I want to fill a ggdist plot with > 1 colors. In the example below, I would like to fill in values below -1, between -1 and 0, and above 0.

How could one do it?

Thanks!

``` r
set.seed(123)

library(ggplot2)
library(ggdist)

data.frame(p = rnorm(10e4, -1, 1)) |> 
  ggplot() +
  aes(x = p, fill = after_stat(x < 0)) +
  stat_halfeye()
```

![](https://i.imgur.com/nocGT07.png)<!-- -->

<sup>Created on 2023-03-23 with [reprex v2.0.2](https://reprex.tidyverse.org)</sup>
",TRUE,"----------------------------
mjskay:

The expression inside `after_stat()` can return anything you would normally assign to the corresponding aesthetic (`fill` in this case). So `after_stat(x < 0)` just takes advantage of the fact that `x < 0` returns a logical vector, which ggplot2 then uses to create a discrete fill color scale.

In your case you'd want an expression inside `after_stat()` that creates a factor with levels corresponding to the bins on `x` that you're looking for. The most direct way to do that is probably `cut(x, breaks = c(-Inf, -1, 0, Inf))`. Does that help?

----------------------------
arthur-albuquerque:

That's perfect. This is very useful for ROPE plots. An example would be a good addition to ggdist's documentation.

Thanks!",TRUE,help,2023-03-23 11:07:36,2023-03-24 01:38:17,,,CLOSED,2023-03-24 01:38:17,NA,,I_kwDOEBBtO85hl1qh
173,https://github.com/mjskay/ggdist/issues/173,https://github.com/mjskay/ggdist/issues/173,joshua-goldberg,Cryptic error message from curve_interval,"Hi there!

I've been messing around with `curve_interval`s to summarize data, but am encountering a rather unhelpful error message:  `Error in rowMeans(pointwise_depths, na.rm = na.rm) : 'x' must be an array of at least two dimensions`. I'm willing to believe that my data may not be a good fit for a curve-wise interval (or at least that `point_interval` is the appropriate option), but I'd appreciate some combination of a more informative error message and/or more examples of `curve_interval`(perhaps including the `.along` argument?) that illustrate use cases. 

My data are not evenly or identically distributed along the 'x' variable across curves, which seems to be problematic. Happy to come up with a reprex if that's helpful to diagnose the issue, but this may be known/intended/desirable behavior, so I'll save a bit of digital ink for the moment.

Cheers,
J",FALSE,,TRUE,bug,2023-03-17 20:47:26,NA,,,OPEN,2023-03-17 20:47:58,NA,,I_kwDOEBBtO85hJoHL
172,https://github.com/mjskay/ggdist/issues/172,https://github.com/mjskay/ggdist/issues/172,mccarthy-m-g,Support ordering for lines in `geom_lineribbon()`,"This issue is continuing the conversation in #171. See https://github.com/mjskay/ggdist/issues/171#issuecomment-1459110543 onwards.

## Request

71f346b added support for an explicit order aesthetic for `geom_lineribbon()`, making it possible to group ribbons together in layers as demonstrated in the reprex below. It would be nice if it was also possible to control the order of lines so they could be grouped with their ribbons. For example, in the plot below it would be nice to have a way to order the ribbons and lines in the following layers:

1. Group ""a"" ribbons
2. Group ""a"" line
3. Group ""b"" ribbons
4. Group ""b"" line

This isn't an urgent feature, and it's easy to workaround (see next section); but if it is possible it would be a nice to have.

``` r
library(tidyverse)
library(ggdist)

set.seed(1234)
n = 5000

df = tibble(
  .draw = 1:n,
  intercept = rnorm(n, 3, 1),
  slope = rnorm(n, 1, 0.25),
  x = list(-4:5),
  y = map2(intercept, slope, ~ .x + .y * -4:5)
) %>%
  unnest(c(x, y))

df_2groups = rbind(
  mutate(df, g = ""a""),
  mutate(df, g = ""b"", y = (y - 2) * 0.5)
)

# Here it would be nice if there was a way to place the line for group ""a""
# below the ribbons for group ""b"":
df_2groups %>%
  ggplot(aes(x = x, y = y, fill = g)) +
  stat_lineribbon(aes(
    fill_ramp = after_stat(level),
    order = after_stat(interaction(level, group))
  )) +
  labs(title = ""stat_lineribbon(aes(order = after_stat(interaction(level, group))))"") +
  theme_ggdist()
```

![](https://i.imgur.com/wIcUpn2.png)<!-- -->

<sup>Created on 2023-03-08 with [reprex v2.0.2](https://reprex.tidyverse.org)</sup>

## Current workaround

A simple way to accomplish the desired result is to plot multiple geoms in the desired order using subsets of the data:

``` r
library(tidyverse)
library(ggdist)

set.seed(1234)
n = 5000

df = tibble(
  .draw = 1:n,
  intercept = rnorm(n, 3, 1),
  slope = rnorm(n, 1, 0.25),
  x = list(-4:5),
  y = map2(intercept, slope, ~ .x + .y * -4:5)
) %>%
  unnest(c(x, y))

df_2groups = rbind(
  mutate(df, g = ""a""),
  mutate(df, g = ""b"", y = (y - 2) * 0.5)
)

ggplot(mapping = aes(x = x, y = y, fill = g, fill_ramp = after_stat(level))) +
  stat_lineribbon(data = filter(df_2groups, g == ""a"")) +
  stat_lineribbon(data = filter(df_2groups, g == ""b"")) +
  theme_ggdist()
```

![](https://i.imgur.com/ic4nW5c.png)<!-- -->

<sup>Created on 2023-03-08 with [reprex v2.0.2](https://reprex.tidyverse.org)</sup>",FALSE,,TRUE,enhancement,2023-03-09 00:17:34,NA,,,OPEN,2023-03-09 00:17:34,NA,,I_kwDOEBBtO85gVQDE
171,https://github.com/mjskay/ggdist/issues/171,https://github.com/mjskay/ggdist/issues/171,mccarthy-m-g,Bug in `geom_lineribbon()` fill layer order ,"I'm trying to plot a survival curve with multiple intervals (66% and 95%) but ran into a bug with the fill scale when using `geom_lineribbon()`. Basically I can't plot both intervals in the darker to lighter fill order typical of ggdist. Instead I can either:

- Plot the 95% interval in the correct colour, but the 66% interval is hidden in a lower layer (if you set alpha you can see it under the 95% interval)
- Plot both intervals, but the fill colours are going in the wrong order (lighter to darker)

Here's a reprex:

``` r
library(survival)
library(tidyverse)
library(broom)
library(ggdist)

veterans_fit_95 <- survfit(
  Surv(time, status) ~ 1, data = veteran, conf.int = 0.95
)
veterans_fit_66 <- update(veterans_fit_95, conf.int = 0.66)

veterans_tidy <- list(`0.66` = veterans_fit_66, `0.95` = veterans_fit_95) |>
  map_df(tidy, .id = "".width"") |>
  mutate(.width = as.numeric(.width))

p <- ggplot(
  veterans_tidy, aes(x = time, y = estimate, ymin = conf.low, ymax = conf.high)
) +
  geom_lineribbon(step = ""hv"")

# Only the 95% interval is shown
p + scale_fill_brewer(direction = 1)
```

![](https://i.imgur.com/jVVkyi5.png)<!-- -->

``` r
# If you change the fill direction then both intervals are shown (but the colour
# order is reversed so this isn't a great workaround)
p + scale_fill_brewer(direction = -1)
```

![](https://i.imgur.com/cep3L9x.png)<!-- -->

``` r
# This also happens with manual fill
p + scale_fill_manual(values = c(""#DEEBF7"", ""#9ECAE1"")) # Doesn't work
```

![](https://i.imgur.com/TRDX48X.png)<!-- -->

``` r
p + scale_fill_manual(values = c(""#9ECAE1"", ""#DEEBF7"")) # Does work
```

![](https://i.imgur.com/IIWDqAM.png)<!-- -->

<sup>Created on 2023-03-01 with [reprex v2.0.2](https://reprex.tidyverse.org)</sup>
 ",TRUE,"----------------------------
mccarthy-m-g:

Here's another reprex with multiple survival curves in one plot. Adding just in case it's helpful for additional debugging.

``` r
library(survival)
library(tidyverse)
library(broom)
library(ggdist)

# Helper function for multiple intervals
dist_tidy <- function(x, conf.type = ""log-log"", conf.int = 0.95, ...) {
  purrr::map_df(
    purrr::set_names(conf.int),
    function(.x) broom::tidy(update(x, conf.type = conf.type, conf.int = .x)),
    .id = "".width""
  ) |>
    dplyr::mutate(.width = as.numeric(.width)) |>
    dplyr::relocate(.width, .after = dplyr::everything())
}

veterans_fit <- survfit(Surv(time, status) ~ trt, data = veteran)
veterans_fit_tidy <- dist_tidy(veterans_fit, conf.int = c(0.66, 0.95))

p <- ggplot(
  veterans_fit_tidy,
  aes(
    x = time, y = estimate,
    ymin = conf.low, ymax = conf.high,
    colour = strata,
    fill = strata, fill_ramp = factor(.width)
  )
) +
  scale_colour_brewer(palette = ""Dark2"") +
  scale_fill_brewer(palette = ""Set2"")

# Interval fills still in the wrong layer order (lighter to darker)
p + geom_lineribbon(step = ""hv"", alpha = 0.8)
```

![](https://i.imgur.com/H49xnwV.png)<!-- -->

``` r
# Changing the from colour inconsistently changes the fill layer order. Now the
# 66% interval for trt=2 is below the 95% interval. the Fill layer order for
# trt=1 is fine though...
p + geom_lineribbon(step = ""hv"") + scale_fill_ramp_discrete(from = ""gray50"")
```

![](https://i.imgur.com/D1bvKr1.png)<!-- -->

<sup>Created on 2023-03-01 with [reprex v2.0.2](https://reprex.tidyverse.org)</sup>

----------------------------
mjskay:

Hmm yeah, something weird going on here, likely in the heuristics lineribbon uses to pick draw order. They should be handling this case and I'm not sure why they aren't. 

Does make me think that adding something to make draw order explicitly controllable might be a better solution than the current approach anyway, which has always been a hack. I did that recently with geom_dots by allowing draw order to be set using the `order` aesthetic, maybe I'll do that here too. 

----------------------------
mccarthy-m-g:

Yeah, I was surprised by it. I did a bit more digging and it seems like the problem is caused by CIs that have `NA` values (see reprex below).

Having the option for an explicit `order` aesthetic might be nice. Would that make it possible to put all the ribbons from a group above all the ribbons from a different group, or would it just be for the `.width` level order? 

---

``` r
library(survival)
library(tidyverse)
library(broom)
library(ggdist)

# Helper function for multiple intervals
dist_tidy <- function(x, conf.type = ""log-log"", conf.int = 0.95, ...) {
  purrr::map_df(
    purrr::set_names(conf.int),
    function(.x) broom::tidy(update(x, conf.type = conf.type, conf.int = .x)),
    .id = "".width""
  ) |>
    dplyr::mutate(.width = as.numeric(.width)) |>
    dplyr::relocate(.width, .after = dplyr::everything())
}

# Null model ----
veterans_fit_1 <- survfit(Surv(time, status) ~ 1, data = veteran)
veterans_fit_1_tidy <- dist_tidy(veterans_fit_1, conf.int = c(0.66, 0.95))

# The last time always has an estimate of 0 and CIs of NA. Omitting these rows
# seems to fix things in null model reprex.
tail(arrange(veterans_fit_1_tidy, desc(estimate)), 2)
#> # A tibble: 2 × 9
#>    time n.risk n.event n.censor estimate std.error conf.high conf.low .width
#>   <dbl>  <dbl>   <dbl>    <dbl>    <dbl>     <dbl>     <dbl>    <dbl>  <dbl>
#> 1   999      1       1        0        0       Inf        NA       NA   0.66
#> 2   999      1       1        0        0       Inf        NA       NA   0.95

# Interval fills are ordered correctly
ggplot(
  na.omit(veterans_fit_1_tidy),
  aes(x = time, y = estimate, ymin = conf.low, ymax = conf.high)
) +
  geom_lineribbon(step = ""hv"") +
  scale_fill_brewer()
```

![](https://i.imgur.com/IAdfxKO.png)<!-- -->

``` r
# Group model ----
veterans_fit_2 <- survfit(Surv(time, status) ~ trt, data = veteran)
veterans_fit_2_tidy <- dist_tidy(veterans_fit_2, conf.int = c(0.66, 0.95))

# In the two group example the last time for each group has an estimate of 0
# and CIs of NA. Omitting these rows seems to fix most things but not all things.
tail(arrange(veterans_fit_2_tidy, desc(estimate)), 4)
#> # A tibble: 4 × 10
#>    time n.risk n.event n.censor estimate std.error conf.…¹ conf.…² strata .width
#>   <dbl>  <dbl>   <dbl>    <dbl>    <dbl>     <dbl>   <dbl>   <dbl> <chr>   <dbl>
#> 1   553      1       1        0        0       Inf      NA      NA trt=1    0.66
#> 2   999      1       1        0        0       Inf      NA      NA trt=2    0.66
#> 3   553      1       1        0        0       Inf      NA      NA trt=1    0.95
#> 4   999      1       1        0        0       Inf      NA      NA trt=2    0.95
#> # … with abbreviated variable names ¹​conf.high, ²​conf.low

# Not the desired plot, but the within-group interval fills are ordered
# correctly. The layers are intermingling between groups, but this happens in
# the ggdist vignettes too so that's expected behaviour.
ggplot(
  na.omit(veterans_fit_2_tidy),
  aes(x = time, y = estimate, ymin = conf.low, ymax = conf.high, colour = strata)
) +
  geom_lineribbon(step = ""hv"") +
  scale_fill_brewer()
```

![](https://i.imgur.com/oN7MYi4.png)<!-- -->

``` r
# However only the 95% interval seems to be shown if you replace the colour
# aesthetic with the fill aesthetic.
ggplot(
  na.omit(veterans_fit_2_tidy),
  aes(x = time, y = estimate, ymin = conf.low, ymax = conf.high, fill = strata)
) +
  geom_lineribbon(step = ""hv"", alpha = 1/4) +
  theme_dark()
```

![](https://i.imgur.com/KQSaT45.png)<!-- -->

``` r
# Adding fill_ramp gets us the desired result as long as the factor levels for
# width go from high to low.
ggplot(
  na.omit(veterans_fit_2_tidy),
  aes(x = time, y = estimate, ymin = conf.low, ymax = conf.high, fill = strata)
) +
  geom_lineribbon(
    aes(fill_ramp = factor(.width, levels = c(0.95, 0.66))),
    step = ""hv""
  )
```

![](https://i.imgur.com/baG1yzC.png)<!-- -->

<sup>Created on 2023-03-02 with [reprex v2.0.2](https://reprex.tidyverse.org)</sup>

----------------------------
mjskay:

> Yeah, I was surprised by it. I did a bit more digging and it seems like the problem is caused by CIs that have `NA` values (see reprex below).

Ah makes sense! I might adjust the logic to better account for `NA`s to handle this case then.

> Having the option for an explicit `order` aesthetic might be nice. Would that make it possible to put all the ribbons from a group above all the ribbons from a different group, or would it just be for the `.width` level order?

Yeah, I would probably make the current behavior the default but allow arbitrary re-ordering using `order`, which would include putting all of one group above another.

----------------------------
mccarthy-m-g:

Both those things would be great!

----------------------------
mjskay:

TODOs for me:

- [x] ignore `NA`s when calculating draw order based on widths
- [x] allow use of `order` to determine draw order of ribbons

----------------------------
mjskay:

Your original code should now produce the correct result on the dev version (install via `remotes::install_github(""mjskay/ggdist@dev"")`:

![image](https://user-images.githubusercontent.com/6345019/222643464-a6e8f4d2-84aa-4ae9-98ac-43ea1096aeb1.png)

This doesn't implement the arbitrary ordering via an `order` aesthetic yet, but I will do that at some point.

----------------------------
mjskay:

FYI dev branch now allows draw order of ribbons to be explicitly controlled via the `order` aesthetic. You could (e.g.) do something like `aes(order = interaction(-.width, strata))` to plot all the ribbons for each level of `strata` together.

----------------------------
mccarthy-m-g:

Awesome, both work great!

Would it be possible to order the lines with their ribbons too?

For example, I find it a bit disorienting that the green line is on top of the orange ribbons here; it would feel more natural if it was under the orange ribbons.

![image](https://user-images.githubusercontent.com/51542091/223590856-af0fa32f-2e0c-4808-b1c5-474a160ccda2.png)

 (I'm guessing the answer is no, and this would be better handled by adding two `geom_lineribbons()` to the plot each subset by a level of `strata`)

----------------------------
mjskay:

Hmm yeah. The lines are like that so that other types of displays (particularly gradient-style lineribbons with lots of low-opacity intervals) work well... but maybe I can figure out a reasonable solution that accommodates both. 

----------------------------
mccarthy-m-g:

I was mostly just curious, but if it is maybe possible want me to open a new issue for it?

----------------------------
mjskay:

sure, then I can close this one

----------------------------
mccarthy-m-g:

Closing since aa1e3b7 and 71f346b resolved the original issue.",TRUE,bug,2023-03-01 20:27:10,2023-03-09 00:20:03,,,CLOSED,2023-03-09 00:20:04,NA,,I_kwDOEBBtO85fs8uO
170,https://github.com/mjskay/ggdist/issues/170,https://github.com/mjskay/ggdist/issues/170,mjskay,make all distribution calculations up front,"Should be able to separate out the calculation parts and the presentation parts, which will simplify some stuff (like the sharing of slab and interval calculations). Basically a pipeline like:

1. Group everything and create objects that will store distribution information. Probably environments or R6 objects
2. Fill in the limits on those objects implied by the chosen density estimator. i.e. what is currently in `compute_limits()`
3. Fill in slab / interval / etc calculations. i.e. most of what is currently in `compute_slab()` and `compute_intervals()` but instead of putting them in the format for the data, store them internally, to be composed later. This would include calculating intervals, a grid, and density functions and intervals against that grid. Would also keep the pdf, cdf, and quantile functions for each dist around in its object for use later.
4. In stages, compose the datatype sections of output (slab and interval). e.g. the slab portion would use the grid + function evaluations as its basis, but add in interval containment info. The interval portion would use the interval evaluations as its basis, but add in pdf and cdf evaluations using the stored dist functions.

This should allow us to eliminate some duplicate work and also drop the use of the approximation functions for slab functions later (or, in the sample case, we can make these the stored functions).",FALSE,,FALSE,refactor,2023-02-15 22:54:30,NA,,,OPEN,2023-02-15 22:54:30,NA,,I_kwDOEBBtO85ekytw
169,https://github.com/mjskay/ggdist/issues/169,https://github.com/mjskay/ggdist/issues/169,pedbra,stat_interval behavior with log-transformed x-axis scale,"> platform       x86_64-w64-mingw32               
arch           x86_64                           
os             mingw32                          
crt            ucrt                             
system         x86_64, mingw32                  
status                                          
major          4                                
minor          2.2                              
year           2022                             
month          10                               
day            31                               
svn rev        83211                            
language       R                                
version.string R version 4.2.2 (2022-10-31 ucrt)

Using ggdist version '3.2.1', the following works as intended
```
p1 <- data.frame(
  values = rnorm(50, 10, 2),
  groups = c(rep(c(""A"", ""B""), 25))
) %>%
  ggplot(., aes(x=values, y=groups)) +
  ggdist::stat_interval()
p1
```

However, by log10-transforming the x-axis it no longer displays the intervals

```
p1 + scale_x_log10()
```

The problem was gone a few days ago, but might have occurred since I was changing R versions. However, I've tried in a few R versions now and the problem persists. Not sure if this is intended behavior and that the problem might be fixed by tweaking an argument within the _scale_x_log10()_. Although the data transformation can be done prior to plotting, I would prefer to scale the x-axis instead.",TRUE,"----------------------------
mjskay:

This is a bug in the CRAN version that has been fixed on github (but not CRAN yet). See #168

Should be fixed if you do `remotes::install_github(""mjskay/ggdist"")`",TRUE,bug,2023-02-03 13:47:28,2023-02-03 15:27:04,,,CLOSED,2023-02-03 15:27:04,NA,,I_kwDOEBBtO85dkk_I
168,https://github.com/mjskay/ggdist/issues/168,https://github.com/mjskay/ggdist/issues/168,qdread,stat_interval fails with log transformation,"I am not sure which package updates have caused this breaking cahnge, but I recently noticed some code I wrote a few months ago is now broken due to some unexpected behavior of `stat_interval()` if there is a log scale axis. For some reason making the axis scale logarithmic causes the computation of `stat_interval()` to fail, somewhere along the line a non-numeric argument is passed to `log()`.

Here is a reprex I made (*edited the post to make the reprex a lot more minimal*). Thanks in advance for your help (and for the great packages!)

```
library(ggplot2)
library(ggdist)

foo <- data.frame(grp = rep(letters[1:3], 1000), stuff = rlnorm(3000))

ggplot(foo, aes(x=grp, y=stuff)) + stat_interval() # Looks as expected
ggplot(foo, aes(x=grp, y=stuff)) + stat_interval() + scale_y_log10() # Fails
```

The warning returned by `... + scale_x_log10()`:

```
Warning message:
Computation failed in `stat_interval()`
Caused by error in `log()`:
! non-numeric argument to mathematical function 
```

Session info:

```
R version 4.2.2 (2022-10-31 ucrt)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19044)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.utf8  LC_CTYPE=English_United States.utf8    LC_MONETARY=English_United States.utf8
[4] LC_NUMERIC=C                           LC_TIME=English_United States.utf8    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] ggdist_3.2.0  ggplot2_3.4.0
```



",TRUE,"----------------------------
mjskay:

Thanks for catching this and for the straightforward reprex! Made it easy to isolate the bug. It should be fixed on master now; if you install the github version via `remotes::install_github(""mjskay/ggdist"")` you can double-check to make sure the fix works for you.

Thanks again!

----------------------------
qdread:

Thanks for addressing this so quickly! Curious whether it was caused by some change in ggplot2 v3.4?

----------------------------
mjskay:

Nah, it was entirely my fault :). In ggdist 3.2.0 I introduced a feature that shares some computation across slab and interval sub-geometries so that (e.g.) you can use `.width` and `level` aesthetics in `after_stat()` in slabs. This introduced a bug where if the slab is not present at all (as in `stat_interval()`) if the scale transformation function doesn't like `NULL`s it will fail.",TRUE,bug,2023-01-25 20:49:35,2023-01-26 02:34:47,,,CLOSED,2023-01-26 16:10:46,NA,,I_kwDOEBBtO85c0dTW
167,https://github.com/mjskay/ggdist/issues/167,https://github.com/mjskay/ggdist/issues/167,mjskay,ensure stat_slabinterval / stat_dotsinterval works on dist_sample with character or factor,"currently these are not fully supported in {distributional}, but if/when they are we should support them here too.",FALSE,,FALSE,enhancement,2022-12-27 02:50:02,NA,,,OPEN,2022-12-27 02:50:02,NA,,I_kwDOEBBtO85aFdr6
165,https://github.com/mjskay/ggdist/issues/165,https://github.com/mjskay/ggdist/issues/165,mjskay,"replace `slab_type = ""histogram""` with `density = ""histogram""` and deprecate `slab_type`","spun off from #113 

- [ ] allow density estimators to optionally return cdfs as part of their output (needed to align cdf values at bin midpoints)
- [ ] implement `density_histogram()` based on code from `compute_slab_sample`
- [ ] use an internal property of the stat to set the default value of the `f` computed variable instead of using slab_type to do this (for backwards compatibility)
- [ ] make `slab_type` default be `NULL` and deprecate it
- [ ] update stats that use `slab_type = ""histogram""` to use `density = ""histogram""`
- [ ] #118 
",FALSE,,FALSE,"enhancement,refactor,formalism",2022-12-23 01:16:57,NA,,,OPEN,2022-12-23 01:21:06,NA,,I_kwDOEBBtO85Z7ZlF
164,https://github.com/mjskay/ggdist/issues/164,https://github.com/mjskay/ggdist/issues/164,mjskay,deprecate old size scales,"Leaving these for now, but should deprecate eventually:

- [ ] deprecate old scales
   - [ ] `slab_size` -> `slab_linewidth`
   - [ ] `interval_size` -> `linewidth`

_Originally posted by @mjskay in https://github.com/mjskay/ggdist/issues/138#issuecomment-1308230521_
      ",FALSE,,FALSE,cleanup,2022-12-23 01:05:24,NA,,,OPEN,2022-12-23 01:21:31,NA,,I_kwDOEBBtO85Z7XNc
163,https://github.com/mjskay/ggdist/issues/163,https://github.com/mjskay/ggdist/issues/163,mjskay,Use optimization for bin nudging,Pretty sure could do constrained least squares where `R = diag(bin_count)` and `d = bin_count*bin_width` (or normalize by bin width so `d = bin_count`) subject to all adjacent pairs being at least binwidth apart (or 1 apart if normalized by binwidth). ,TRUE,,FALSE,enhancement,2022-12-13 08:25:06,2022-12-15 01:10:32,,,CLOSED,2022-12-15 01:10:32,NA,,I_kwDOEBBtO85ZB9AN
162,https://github.com/mjskay/ggdist/issues/162,https://github.com/mjskay/ggdist/issues/162,mjskay,Provide an `overflow` option to decide what to do when binwidth constraints are hit,"Along with #161, another way to help with scaling would be to allow `stackratio` and `dotsize` to be automatically selected when a `binwidth` constraint is hit (definitely a min, and maybe also a max?). For example, this would allow the automatic layout algorithm to guarantee both a minimum dot size and that the entire dotplot fits in the available space (currently it can guarantee the latter, but only by allowing dots to become arbitrarily small).

Currently, if `binwidth` is a range and the automatic binwidth algorithm choses a binwidth below the minimum of that range, the minimum binwidth will be used, but this can cause the tallest stack of dots to exceed the geom boundaries. However, we could allow some alternatives:

1. if `binwidth` is a range and the automatically selected `binwidth` is less than the user-specific minimum, pick a `dotsize` to make the visual dot size equal to the user-specified minimum `binwidth`, then pick `stackratio` such that the tallest bin touches the geom edge. 
",TRUE,"----------------------------
mjskay:

On second thought, this really shouldn't be triggered by setting stackratio and dotsize to `NA`... esp since this changes the meaning of `binwidth` to be `effective dot size`, and means that desired (baseline) stackratio and dotsize can't be set, but have to be fixed to 1.

Instead, maybe an option like `overflow = ""compress""` that would compress the stackratio (and maybe increase dotsize) on overflow? Would be a more transparent way of setting what to do when binwidth constraints are hit.",TRUE,enhancement,2022-12-07 04:52:35,2022-12-24 04:02:51,,,CLOSED,2022-12-24 04:02:51,NA,,I_kwDOEBBtO85YRWu3
161,https://github.com/mjskay/ggdist/issues/161,https://github.com/mjskay/ggdist/issues/161,mvuorre,More layouts for geom_dots*() (especially for large n),"It would be nice to have more alternatives for the `layout` argument in `geom_dots()` and friends, as discussed [here](https://fediscience.org/@mjskay/109467481228076107).

Specifically, I have in mind the quasi- and pseudorandom positions in the [vipor](https://github.com/sherrillmix/vipor) package, some of which are available easily in ggplot2 through the [ggbeeswarm](https://github.com/eclarke/ggbeeswarm) package (especially the `position_quasirandom()` layouts). Moreover, since ggdist already offers nice one-sided versions of slabs, it would be *awesome* to have e.g. a one-sided quasirandom layout, so you could plot groups next to another for easy visual comparison.

I explored some of these alternatives [here](https://vuorre.netlify.app/posts/raincloud-plot-alt/), but rather unsuccesfully. 

Kudos for the awesome pkg btw. I use it all the time!",TRUE,"----------------------------
mjskay:

Thanks! 

Yeah, I can see an argument for this kind of thing for when regular layouts don't scale. Another layout designed to address scaling issues is Daniel Zvinca's [density dotplots](https://www.linkedin.com/pulse/pursuit-diversity-data-visualization-jittering-access-daniel-zvinca/), so I might want to have something like that too.

----------------------------
mvuorre:

Yeah, that's great, this is basically what I had in mind (fig 23 in the blog post):

![](https://media-exp1.licdn.com/dms/image/C5612AQFyJQDFLFu-oQ/article-inline_image-shrink_1500_2232/0/1530887300430?e=1675900800&v=beta&t=9wr80JsTQ1Ke1Wp1FgaJ6z4YXtRZSzMM2JAd8CyvR_4)

But with all the ggdist goodies 💎 

----------------------------
mjskay:

Dunno how Daniel Zvinca made those density dotplots, but I came up with one quick and dirty way that doesn't even seem to need a new layout algorithm. e.g.:

```r
set.seed(1234)
x = rnorm(1000)

ggplot() +
  geom_dots(aes(x))
```
![image](https://user-images.githubusercontent.com/6345019/206068757-653a6f6e-4c1a-42af-b5a4-3a410fb50aac.png)

Now, a quick-and-dirty approach to density smoothing:

```r
# smooth x using a density estimator, returning new x of the same length
# (N.B. order is destroyed here, so output points have no correspondence
# to input points... might have to think about that)
smooth = function(x) {
  d = density(x)
  n = length(x)
  
  # determine how many (fractional) dots in each bin of the density estimate's grid
  bin = d$x
  f_times_n = d$y / sum(d$y) * n
  
  # get whole number counts of dots in each bin (guaranteeing they add up to
  # exactly n) by rounding the CDF implied by the density estimate
  F_times_n = round(cumsum(f_times_n))
  n_in_bin = F_times_n - c(0, F_times_n[-length(F_times_n)])
  
  # turn bins and counts into n values we can plot 
  inverse.rle(list(lengths = n_in_bin, values = bin))
}

ggplot() +
  geom_dots(aes(x = smooth(x)))
```
![image](https://user-images.githubusercontent.com/6345019/206068926-a7616b80-eb06-466e-8d9d-9672e8a3e0ba.png)

Still some details to work out (like, where to put this in the API --- not sure if it counts as a layout algorithm or something else....) but at first look seems easy enough to do!

----------------------------
mjskay:

Here's a slightly more worked-through implementation. Not sure when this will actually get into the package proper since I'd really want to figure out #113 first and use the same mechanism for custom density estimators here.

```r
#' smooth x using a density estimator, returning new x of the same length
#' @param x a numeric vector
#' @param trim if `TRUE`, density is trimmed to `range(x)`, and `range(smooth(x))`
#' is guaranteed to equal `range(x)`
#' @param ... additional parameters passed to [density()]
#' @noRd
smooth = function(x, trim = TRUE, ...) {
  if (length(x) < 2) return(x)
  
  cut = if (trim) 0 else 3
  d = density(x, cut = cut, ...)
  n = length(x)
  
  # determine how many (fractional) dots are in each bin of the density estimate's grid
  bin = d$x
  n_bin = length(bin)
  f_times_n = d$y / sum(d$y) * n
  
  # get whole number counts of dots in each bin (guaranteeing they add up to
  # exactly n) by rounding the CDF implied by the density estimate
  F_times_n = round(cumsum(f_times_n))
  n_in_bin = F_times_n - c(0, F_times_n[-n_bin])
  
  # turn bins and counts into n values (in sorted order)
  x_dens = inverse.rle(list(lengths = n_in_bin, values = bin))

  if (trim) {
    # when using trim = TRUE, we want the first and last points in the smoothed
    # estimate to exactly equal the original first and last point --- they
    # may not quite do that if the density was particularly low at the edges,
    # so we'll pull those two points out if necessary
    x_dens[[1]] = min(x)
    x_dens[[n]] = max(x)
  }
  
  # match up each smoothed value to a close value from `x` using the order of x
  x_dens[rank(x, ties.method = ""first"")]
}
```

----------------------------
mvuorre:

1. Amazing work.
2. Looks like #113 solves this too so that makes sense.

Thanks and keep up the good work!

----------------------------
mjskay:

Thanks! 

----------------------------
mjskay:

okay I had to figure out how to do weighted quantile estimation to actually do this properly, but an initial version is now on the [weighted-quantiles](https://github.com/mjskay/ggdist/tree/weighted-quantiles) branch if you want to try it out. For now I'm keeping it as a transformation function to be applied to the data rather than an option to `geom_dots()`. So you can do:

```r
set.seed(1234)
x = rnorm(1000)

ggplot() +
  geom_dots(aes(x = smooth_dots(x)))
```
![image](https://user-images.githubusercontent.com/6345019/206949189-16e01915-1c4c-453f-bbd7-a389a962265e.png)

While looking at other examples of this I saw it was sometimes paired with a hex-packing layout and I thought it looked pretty nice, so I added that too:

```r
ggplot() +
  geom_dots(aes(x = smooth_dots(x)), layout = ""hex"", stackratio = 0.9)
```
![image](https://user-images.githubusercontent.com/6345019/206949305-649578bb-b8a7-43ec-8a8e-d50992f7e672.png)

Of course this stuff also works with all the other options, e.g. changing side:

```r
ggplot() +
  geom_dots(aes(x = smooth_dots(x)), layout = ""hex"", stackratio = 0.9, side = ""both"")
```
![image](https://user-images.githubusercontent.com/6345019/206949495-37b63f8b-0363-41be-a827-1d76cfe2f936.png)

One question for you, @mvuorre: do you still have a need for a quasi-random layout? I'd love to know if these new options satisfy the use cases you were thinking about, or if you have use cases where a quasi-random layout would still be helpful to have.

----------------------------
mjskay:

Ah hrm, this wont be a good long-term solution since the smoothing should be applied to each group separately. Blast! I'll have to make it an argument or something then. Oh well.

Note to self:
- [ ] make `smooth_dots()` an argument or something
- [ ] update the `dotsinterval` vignette
- [ ] possibly un-export `smooth_dots()`

----------------------------
mvuorre:

Thanks so much for the effort on this. I am not quite sure if this will work for what I had in mind, I've tried some smaller sample distributions with many peaks and cannot get it to display well. For example:

```r
library(ggplot2)
library(ggdist)
set.seed(1234)
x = c(rnorm(50), rnorm(50, 3))

ggplot() +
  geom_dots(aes(x = smooth_dots(x)), binwidth = .05, dotsize = 1)
```

![image](https://user-images.githubusercontent.com/7349270/207008642-1eb6a5d9-b706-4e87-99fc-56191a09f332.png)



----------------------------
mjskay:

You've manually picked a very small bin size --- if you let it pick the binwidth automatically, are there problems with the result?

Unsmoothed:

```r
set.seed(1234)
x = c(rnorm(50), rnorm(50, 3))

ggplot() + 
  geom_dots(aes(x = x), dotsize = 1)
```
![image](https://user-images.githubusercontent.com/6345019/207179449-8511b8f5-db9a-4264-82c3-694b126b923f.png)

Smoothed:

```r
ggplot() + 
  geom_dots(aes(x = smooth_dots(x)), dotsize = 1)
```
![image](https://user-images.githubusercontent.com/6345019/207179724-ff56fc70-31cd-4d25-b47a-04b598c4f289.png)

Personally I'd go with unsmoothed here b/c of the small sample size, but either way I don't think I'd prefer a quasirandom layout over the dotplot layout. But I may not have found the right example of them yet. Possibly if there's a large, constant spike? Though even then I'd maybe adjust stackratio to be < 1 and/or dotsize to be > 1 rather than use a quasirandom layout (which should also be automatable using #162).

----------------------------
mvuorre:

I see, thanks that makes sense. I don't think there are problems with the output that way. At this point I think it is just a matter of style/taste. I'm not expecting you to take `geom_dots()` in this direction but here's just my 2 cents and what I'm trying to do: Possibly many comparisons of two groups (e.g. male/female) shown with ""mirrored"" dotplots/jittered points etc. If I draw this with the current `geom_dots(smooth_dots(...))` (and my limited skill in using it), I get a plot that basically (to my eye) bins the points too hard for me to ""see"" the comparisons.

``` r
library(tidyverse)
library(ggdist)
library(ggbeeswarm)
set.seed(1234)

dat <- tibble(
  f1 = rep(1:4, each = 50), 
  f2 = rep(1:2, length = 200),
  y = rnorm(200, f1 + f2 * .25)
) %>% 
  mutate(across(f1:f2, factor))


dat %>% 
  ggplot() + 
  geom_dots(
    aes(
      x = f1, 
      y = y, 
      fill = f2, 
      side = if_else(f2==""1"", ""left"", ""right"")
    )
  )
```

![](https://i.imgur.com/y76EJH2.png)<!-- -->

I get very close to my desired results with `position_quasirandom()`, but the points are jittered both left and right. I'd like the points on the left to only be jittered left, and points on the right to only be jittered to the right.

``` r

dat %>% 
  ggplot() +
  aes(x = f1, y = y, col = f2) +
  geom_point(
    position = position_quasirandom(width = .25/4, dodge.width = .25)
  )
```

![](https://i.imgur.com/NzPDlBt.png)<!-- -->

Maybe there is a way to specify that with `geom_dots() / smooth_dots()`? Another closely related method of jittering is in [`geom_sina()`](https://ggforce.data-imaginist.com/reference/geom_sina.html), but that is also two-sided.

Anyway these were just my ramblings. Feel free to ignore as a special use case and not general enough to warrant changes in how you see ggdist & `geom_dots()` working. Keep up the good work and thank you!

<sup>Created on 2022-12-13 with [reprex v2.0.2](https://reprex.tidyverse.org)</sup>

----------------------------
mjskay:

Ah got it! This is very helpful, thanks!

I think my main issue with `quasirandom` / `sina` is my bias towards layouts that are a bit more intentional --- it feels like there should be a better solution to the problems they solve. Thus, I really appreciate you giving me more info on your use case, which is exactly what I need to figure out something that might (hopefully) satisfy both of us :). Plus, I don't really know how I would do automatic binning with `sina`, since the height of a bin is not constrained by its width...

My first thought from the example you gave is that if you want smaller dots, there are two things to try: (1) reduce `scale` so that the dotplot takes up less space or (2) pass an interval to `binwidth` to set a maximum bin width.

(I'll give these examples using the `dev` branch, which has some improvements to dot layout)

E.g. a similar plot to your `position_quasirandom` example might use `scale = 0.25` to make `geom_dots()` find a binwidth such that the dotplots take up at most `0.25` of their allotted space (I also set `linewidth = 0` to get rid of dot outlines):

```r
library(tidyverse)
library(ggdist)
set.seed(1234)

dat <- tibble(
  f1 = rep(1:4, each = 50), 
  f2 = rep(1:2, length = 200),
  y = rnorm(200, f1 + f2 * .25)
) %>% 
  mutate(across(f1:f2, factor))


dat %>% 
  ggplot() + 
  geom_dots(
    aes(
      x = f1, 
      y = y, 
      fill = f2, 
      side = if_else(f2==""1"", ""left"", ""right"")
    ),
    scale = 0.25,
    linewidth = 0
  )
```
![image](https://user-images.githubusercontent.com/6345019/208572965-a990895b-7e87-47db-8af9-0573f10363d2.png)

Alternatively, you might decide you want the bin width in the y dimension to be at most 0.1, if that is some domain-relevant resolution at which you want to be able to see dots. If you set `binwidth = c(0, 0.1)`, the automatic binwidth algorithm will find a width in that range:

```r
dat %>% 
  ggplot() + 
  geom_dots(
    aes(
      x = f1, 
      y = y, 
      fill = f2, 
      side = if_else(f2==""1"", ""left"", ""right"")
    ),
    binwidth = c(0, 0.1),
    linewidth = 0
  )
```
![image](https://user-images.githubusercontent.com/6345019/208573469-61c4a33b-765e-41e9-8fa8-1ddb6715e552.png)

The other thing I'm getting from your example is that maybe you want the dots to be in their exact `y` positions. There are two combinations of options in ggdist that guarantee this: `layout = ""swarm""`, or `layout = ""weave"", overlaps = ""keep""` (the `overlaps` option is only in the dev version). E.g.:

```r
dat %>% 
  ggplot() + 
  geom_dots(
    aes(
      x = f1, 
      y = y, 
      fill = f2, 
      side = if_else(f2==""1"", ""left"", ""right"")
    ),
    binwidth = c(0, 0.1),
    linewidth = 0,
    layout = ""swarm""
  )
```
![image](https://user-images.githubusercontent.com/6345019/208573989-79cd58c7-f5d1-49e1-9b9b-ae693d271df3.png)

At this point, if you find the dots too small and want them to be visually bigger while maintaining the bin width of 0.1 (and exact y positions), you could also pick some number `k > 1` and set `dotsize = k` (visual width of the dot relative to bin size) and `stackratio = 1/k` (stacking height between dots). E.g.:

```r
dat %>% 
  ggplot() + 
  geom_dots(
    aes(
      x = f1, 
      y = y, 
      fill = f2, 
      side = if_else(f2==""1"", ""left"", ""right"")
    ),
    binwidth = c(0, 0.1),
    linewidth = 0,
    layout = ""swarm"",
    dotsize = 1.5,
    stackratio = 1/1.5
  )
```
![image](https://user-images.githubusercontent.com/6345019/208575493-d7323822-c438-4933-8596-9f52b2bad447.png)

Is this closer to what you're looking for?

This also makes me think that if you want an exact binwidth (say `0.1`) and just want the algorithm to pick a `dotsize` and `stackratio` to make the layout with that binwidth *and* visual dot size fit in the available space, that could be helpful. I opened an issue for that at #162.



----------------------------
mjskay:

I've now implemented a solution in #162 that automatically tweaks dotsize and stackratio, which I think lets you get a solution in line with what you're looking for. e.g.:

```r
dat %>% 
  ggplot() + 
  geom_dots(
    aes(
      x = f1, 
      y = y, 
      fill = f2, 
      side = if_else(f2==""1"", ""left"", ""right"")
    ),
    linewidth = 0, 
    scale = 0.25,
    binwidth = unit(5, ""pt""),
    layout = ""swarm"",   # or layout = ""weave"", overlaps = ""keep""
    overflow = ""compress""
  )
```
![image](https://user-images.githubusercontent.com/6345019/209606278-962bdf16-ddf4-4b24-9c5a-a504f4660e13.png)

This says:

- ensure each dotplot fits into 25% of the allotted space for the geom (`scale = 0.25`)
- make the bins/dots be 5 points in size (`unit(5, ""pt""`)
- use a layout where y positions of dots are exact (`layout = ""swarm""` or `layout = ""weave"", overlaps = ""keep""`)
- if the above `binwidth` setting would cause the dotplot to go beyond the requested 25% of the geom space (per `scale`), compress the distances between dots so that the dot sizes stay at 5 points but the dots may overlap a bit (`overflow = ""compress""`)

I might consider making a shortcut geom like a `geom_swarm()` and/or `geom_weave()` with this combo of binwidth/layout/overflow settings (then the only thing you'd need to set is `scale` if doing multiple together with dodging). Might be useful for EDA type applications.




----------------------------
mjskay:

I made the shortcut versions of these (`geom_swarm()` and `geom_weave()`), defaulting to `side = ""both""` and `overflow = ""compress""`, with `binwidth = unit(1.5, ""mm"")`, which is the same dot size as `geom_point()`. e.g.:

```r
library(dplyr)
library(ggplot2)
library(ggdist)

set.seed(1234)
data.frame(
    x = rnorm(400, c(1,4)),
    g = c(""a"",""b"")
) %>%
    ggplot(aes(x, y = g, fill = g)) +
    geom_weave(linewidth = 0)
```
![image](https://user-images.githubusercontent.com/6345019/211236692-78203281-0cfa-49b8-8331-b2cb0b3cae86.png)

I also added a `scale_side_mirrored()` to make setting the `side` aesthetic more grammar-of-graphics-like (#142). e.g.:

```r
set.seed(1234)
data.frame(
    x = rnorm(400, c(1,4)),
    g = c(""a"",""b"")
) %>%
    ggplot(aes(x, fill = g, side = g)) +
    geom_weave(linewidth = 0, scale = 0.5) +
    scale_side_mirrored()
```
![image](https://user-images.githubusercontent.com/6345019/211236985-6a0c2523-471c-4ad2-821d-1dda72692216.png)


I think that should cover all the use cases in this issue, so I am closing it for now. However, please let me know if there's something that doesn't work as expected / is not covered by this! Thanks again for the feedback.

----------------------------
mvuorre:

Hi! This is really amazing, and I think it works well with what I'm doing. Now onto writing the manuscripts 😉. Thank you for the detailed examples as well!

----------------------------
mjskay:

You're welcome! Good luck on the manuscripts! ",TRUE,enhancement,2022-12-06 20:02:45,2023-01-09 03:33:22,,,CLOSED,2023-01-10 08:29:29,NA,,I_kwDOEBBtO85YN-l_
160,https://github.com/mjskay/ggdist/issues/160,https://github.com/mjskay/ggdist/issues/160,mjskay,mini-DSL for probability expressions in after_stat(),"Could be nice to have a DSL for probability expressions in aesthetics, e.g. `p(x)` instead of `after_stat(pdf)`, `P(xdist <= x)` for `after_stat(cdf)`, that sort of thing...
",TRUE,,FALSE,"enhancement,formalism",2022-11-27 20:33:13,2022-12-24 04:02:51,,,CLOSED,2022-12-24 04:02:51,NA,,I_kwDOEBBtO85XWsri
159,https://github.com/mjskay/ggdist/issues/159,https://github.com/mjskay/ggdist/issues/159,mjskay,stat_dots dot size should not exceed 1 on discrete variables,"This is failure mode specifically on factors. See:

```r
ggplot() + stat_dots(aes(x = factor(1:10)))
```
![image](https://user-images.githubusercontent.com/6345019/203915344-d143cc50-1a20-4681-88b0-8afc520dfbb8.png)

workaround until fixed is to manually constrain max binwidth to 1 for factors:

```r
ggplot() + stat_dots(aes(x = factor(1:10)), binwidth = c(0,1))
```
![image](https://user-images.githubusercontent.com/6345019/203915458-0ed51590-950a-4aa2-bf8c-ddfe945ab5c0.png)
",TRUE,,FALSE,bug,2022-11-25 06:32:01,2022-12-24 04:02:50,,,CLOSED,2022-12-24 04:02:50,NA,,I_kwDOEBBtO85XRFqU
158,https://github.com/mjskay/ggdist/issues/158,https://github.com/mjskay/ggdist/issues/158,mjskay,Error with rvar and curve_interval,"Issue with rvar and curve_interval to investigate...

---

_Originally posted by @mattansb in https://github.com/vincentarelbundock/marginaleffects/issues/539#issuecomment-1317013858_:
      
        This should also work, I think, but I'm getting an error? @mjskay, do you know what I'm doing wrong?

```R
mod <- brm(Species ~ ., 
           data = iris,
           family = categorical(), 
           backend = ""cmdstanr"", cores = 4)


predictions(mod, newdata = datagrid(Sepal.length = 4:5)) |>
  posteriordraws(""rvar"") |> 
  curve_interval(rvar, .along = c(""Sepal.length"", ""group""))
#> Error in apply(draws, 2, halfspace_depth) : 
#>   dim(X) must have a positive length
#> In addition: Warning message:
#> Some of the variable names are missing from the model data: Sepal.length
```

",TRUE,"----------------------------
mjskay:

This should be fixed now --- let me know if there are any other issues you run into with curve_interval / rvar. Thanks!

----------------------------
mattansb:

Thanks!

```R
library(brms)
library(marginaleffects)
library(ggdist)
library(ggplot2)

mod <- brm(Species ~ ., 
  data = iris,
  family = categorical(), 
  backend = ""cmdstanr"", cores = 4, iter = 300
)

predictions(mod, newdata = datagrid(Sepal.Width = seq(2, 4.5, len = 50))) |> 
  posteriordraws(shape = ""rvar"") |> 
  curve_interval(rvar, .along = c(""Sepal.Width"", ""group"")) |> 
  ggplot(aes(Sepal.Width, estimate, color = group)) + 
  facet_grid(~group) + 
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = group), 
              color = NA, alpha = 0.4) + 
  geom_line()
```

![image](https://user-images.githubusercontent.com/35330040/215262949-fae7dea5-9c2d-46e1-a5ce-72c5acb1b912.png)


----------------------------
mjskay:

looks right (ish? bit of a weird model...) though to actually use the curve_interval output you'd want `rvar`, `.lower`, and `.upper` instead of `estimate`, `conf.low`, and `conf.high` in the ggplot spec

----------------------------
mattansb:

Ah right.

(Yes, the model is crap - just playing around with functions 🤓)",TRUE,bug,2022-11-17 22:34:29,2023-01-27 06:34:09,,,CLOSED,2023-01-28 20:50:26,NA,,I_kwDOEBBtO85Wq8zS
157,https://github.com/mjskay/ggdist/issues/157,https://github.com/mjskay/ggdist/issues/157,DominiqueMakowski,dodged stat_gradientinterval() with thinner thickness: how to dodge without space between groups?,"Hi! I had a tiny question, with dodged gradients, I reduced the thickness, but then the dodging create space in between each ""group"". I can reduce it by fiddling with `position_dodge(width)`, but it's tough to automatize (so that there is no space regardless of the range of `x`). Is there a possibility to dodge it so that the 3 colors below remain ""collated"" together? 
Any pointers are welcome, and sorry if I missed something obvious!

``` r
library(tidyverse)
library(ggdist)

dat <- data.frame(y = rnorm(1000),
                  x = rep_len(1:8, 1000),
                  g = rep_len(c(""A"", ""B"", ""C""), 1000))

# How to reduce the space in each x-group between the 3 colors?
dat |> 
  ggplot(aes(x = x, y = y)) + 
  ggdist::stat_gradientinterval(
    aes(fill = g),
    geom = ""slab"",
    thickness = stat(thickness(0.5)),
    position = position_dodge(width = 0.7)
  )
```

![](https://i.imgur.com/1v0jkrc.png)

<sup>Created on 2022-11-17 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>
",TRUE,"----------------------------
mjskay:

Ah yup, understandable that figuring it out is a pain, there are a number of different parameters at play here. This diagram of parameters from the [slabinterval vignette](https://mjskay.github.io/ggdist/articles/slabinterval.html) is supposed to help but I can see how it might not be clear:

![slabinterval parameters](https://mjskay.github.io/ggdist/articles/slabinterval_files/figure-html/slabinterval_components-1.png)

The space between slabs is governed by the `scale` parameter (default `0.9`), which is the proportion of the geometry's `height` (or `width` --- I should add that to the diagram) taken up by the slab.

So in your case, I'd start with `scale = 1`:

```r
dat |> 
  ggplot(aes(x = x, y = y)) + 
  ggdist::stat_gradientinterval(
    aes(fill = g),
    geom = ""slab"",
    position = ""dodge"",
    scale = 1
  )
```
![image](https://user-images.githubusercontent.com/6345019/202583801-852f13a6-ca70-4fa3-90b5-13bcddb92c0c.png)

Then, to reduce the amount of space taken up by the geoms, reduce their `width` --- but do this for the geom, not just as a parameter to dodge (if you just do it for the dodge, the geoms will overlap because the dodging will be less than their width. If you do it for the geom, the geom's width is used automatically in the dodge):

```r
dat |> 
  ggplot(aes(x = x, y = y)) + 
  ggdist::stat_gradientinterval(
    aes(fill = g),
    geom = ""slab"",
    position = ""dodge"",
    width = 0.5,
    scale = 1
  )
```
![image](https://user-images.githubusercontent.com/6345019/202584045-712211f8-1514-4d34-a883-acefbeb90a15.png)

```

----------------------------
DominiqueMakowski:

turns out to be so simple 🙈 thanks a lot!

----------------------------
mjskay:

no prob!",TRUE,help,2022-11-17 10:25:49,2022-11-17 23:48:59,,,CLOSED,2022-11-17 23:57:00,NA,,I_kwDOEBBtO85WnGoB
156,https://github.com/mjskay/ggdist/issues/156,https://github.com/mjskay/ggdist/issues/156,mjskay,change default stat_slabinterval size mapping from .width to level,i.e. use `size = stat(level)` instead of `size = stat(-.width)` in AbstractStatSlabinterval?,FALSE,,FALSE,refactor,2022-11-09 04:43:20,NA,,,OPEN,2022-11-09 04:43:20,NA,,I_kwDOEBBtO85V6YSX
155,https://github.com/mjskay/ggdist/issues/155,https://github.com/mjskay/ggdist/issues/155,damonbayer,`geom_interval`s overlaid in the different orders within the same plot,"In some instances, it is possible for two `geom_interval`s in the same plot to overlaid in different orders, within the same plot. I'm not sure if this is a more general `ggplot2` bug (or if I have simply misunderstood how things are supposed to work), but I've only been able to reproduce it with `geom_interval`.

I think this is not supposed to happen, but, if it is, can someone explain how to avoid it?

Here I create some data and plot it. The plot looks as I expected, with consistent overlapping order in each of the two y values.

``` r
library(ggplot2)
library(ggdist)

dat <-
  data.frame(
    x = c(2, 2, 2, 2),
    y = c(0, 1, 0, 1),
    xmin = c(1, 1, 0, 0),
    xmax = c(4, 4, 3, 3),
    color = c(""a"", ""a"", ""b"", ""b"")
  )

dat |>
  ggplot(aes(x = x, y = y, xmin = xmin, xmax = xmax, color = color)) +
  geom_interval(alpha = 0.5)
```

![](https://i.imgur.com/0DTiaz0.png)

If I slightly perturb the data, changing one value by `3.3e-16`, everything still looks as good.

``` r

dat |>
  transform(xmin = xmin + c(0, 3.3e-16, 0, 0)) |>
  ggplot(aes(x = x, y = y, xmin = xmin, xmax = xmax, color = color)) +
  geom_interval()
```

![](https://i.imgur.com/ecQWlf0.png)

However, If I slightly perturb the data a bit more, changing one value by `3.4e-16`, the overlapping for `y = 1` changes so that the the intervals at each level no longer have the same overlapping color. I'm not sure why this would ever happen, and I especially don't understand why changing one value by `3.4e-16` would cause it to happen.

``` r

dat |>
  transform(xmin = xmin + c(0, 3.4e-16, 0, 0)) |>
  ggplot(aes(x = x, y = y, xmin = xmin, xmax = xmax, color = color)) +
  geom_interval()
```

![](https://i.imgur.com/PFN7hnB.png)

Here's my session info:

``` r

sessionInfo()
#> R version 4.2.1 (2022-06-23)
#> Platform: aarch64-apple-darwin20 (64-bit)
#> Running under: macOS Monterey 12.6
#> 
#> Matrix products: default
#> LAPACK: /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRlapack.dylib
#> 
#> locale:
#> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
#> 
#> attached base packages:
#> [1] stats     graphics  grDevices utils     datasets  methods   base     
#> 
#> other attached packages:
#> [1] ggdist_3.2.0  ggplot2_3.3.6
#> 
#> loaded via a namespace (and not attached):
#>  [1] pillar_1.8.1         compiler_4.2.1       highr_0.9           
#>  [4] R.methodsS3_1.8.2    R.utils_2.12.0       tools_4.2.1         
#>  [7] digest_0.6.30        evaluate_0.17        lifecycle_1.0.3     
#> [10] tibble_3.1.8         gtable_0.3.1         R.cache_0.16.0      
#> [13] pkgconfig_2.0.3      rlang_1.0.6          reprex_2.0.2        
#> [16] DBI_1.1.3            cli_3.4.1            rstudioapi_0.14     
#> [19] yaml_2.3.5           xfun_0.33            fastmap_1.1.0       
#> [22] dplyr_1.0.10         withr_2.5.0          styler_1.7.0        
#> [25] stringr_1.4.1        knitr_1.40           generics_0.1.3      
#> [28] fs_1.5.2             vctrs_0.5.0          tidyselect_1.2.0    
#> [31] grid_4.2.1           glue_1.6.2           R6_2.5.1            
#> [34] fansi_1.0.3          distributional_0.3.1 rmarkdown_2.17      
#> [37] farver_2.1.1         purrr_0.3.5          magrittr_2.0.3      
#> [40] scales_1.2.1         htmltools_0.5.3      assertthat_0.2.1    
#> [43] colorspace_2.0-3     labeling_0.4.2       utf8_1.2.2          
#> [46] stringi_1.7.8        munsell_0.5.0        R.oo_1.25.0
```

<sup>Created on 2022-10-27 with [reprex v2.0.2](https://reprex.tidyverse.org)</sup>

",TRUE,"----------------------------
mjskay:

Yeah, this is intended behavior --- geom_interval reorders intervals so that larger ones are towards the back. This is a bit of a weird hack, I admit, but it ensures that typical use cases (nested intervals) are drawn correctly. It also helps make overlapping sets of intervals from different groups with varying `alpha` levels more legible. e.g. this example from the [tidybayes vignette](https://mjskay.github.io/tidybayes/articles/tidy-brms.html#ordinal-models) (using geom_lineribbon, but geom_interval shares the same code) works because of it:

![image](https://user-images.githubusercontent.com/6345019/215373195-3a93c1cb-4b1a-4ee2-8384-dcbd17b21394.png)

If geom_interval isn't working for your use case, I'd give the less specialized `ggplot2::geom_linerange()` a try. It should not reorder intervals.",TRUE,help,2022-10-28 06:05:01,2023-01-30 02:14:12,,,CLOSED,2023-01-30 02:14:12,NA,,I_kwDOEBBtO85VCjZB
154,https://github.com/mjskay/ggdist/issues/154,https://github.com/mjskay/ggdist/issues/154,tjmahr,median_qi() slow compared summarise(median_qi()),"`median_qi()` will compute summary statistics for each group in a grouped dataframe. Alternatively, we can have `median_qi()` run and return a dataframe separately on each group and have the results combined by using `summarise(data, median_qi())`.  

This second approach is much much faster (on my machine). Maybe there is some vctrs magic that makes the dplyr version super fast compared to creating list-columns? 

``` r
library(tidyverse)
library(tidybayes)
library(ggdist)
library(brms)
#> Loading required package: Rcpp
#> Loading 'brms' package (version 2.18.0). Useful instructions
#> can be found by typing help('brms'). A more detailed introduction
#> to the package is available through vignette('brms_overview').
#> 
#> Attaching package: 'brms'
#> The following objects are masked from 'package:ggdist':
#> 
#>     dstudent_t, pstudent_t, qstudent_t, rstudent_t
#> The following objects are masked from 'package:tidybayes':
#> 
#>     dstudent_t, pstudent_t, qstudent_t, rstudent_t
#> The following object is masked from 'package:stats':
#> 
#>     ar
m_mpg <- brm(
  mpg ~ hp * cyl,
  data = mtcars,
  chains = 1,
  iter = 500,
  backend = ""cmdstanr""
)
#> Start sampling
#> Running MCMC with 1 chain...
#> 
#> Chain 1 Iteration:   1 / 500 [  0%]  (Warmup) 
#> Chain 1 Iteration: 100 / 500 [ 20%]  (Warmup) 
#> Chain 1 Iteration: 200 / 500 [ 40%]  (Warmup) 
#> Chain 1 Iteration: 251 / 500 [ 50%]  (Sampling) 
#> Chain 1 Iteration: 350 / 500 [ 70%]  (Sampling) 
#> Chain 1 Iteration: 450 / 500 [ 90%]  (Sampling) 
#> Chain 1 Iteration: 500 / 500 [100%]  (Sampling) 
#> Chain 1 finished in 0.2 seconds.

draws <- mtcars |>
  group_by(cyl) |>
  modelr::data_grid(hp = modelr::seq_range(hp, n = 101)) |>
  add_epred_draws(m_mpg)

results <- bench::mark(
  median_qi(draws, .epred),
  draws |>
    summarise(median_qi(.epred)) |>
    # So that the output of each are exactly the same
    rename(.epred = y, .lower = ymin, .upper = ymax) |> 
    ungroup(),
  iterations = 5, 
  check = FALSE
)
#> `summarise()` has grouped output by 'cyl', 'hp'. You can override using the
#> `.groups` argument.
#> `summarise()` has grouped output by 'cyl', 'hp'. You can override using the
#> `.groups` argument.
#> `summarise()` has grouped output by 'cyl', 'hp'. You can override using the
#> `.groups` argument.
#> `summarise()` has grouped output by 'cyl', 'hp'. You can override using the
#> `.groups` argument.
#> `summarise()` has grouped output by 'cyl', 'hp'. You can override using the
#> `.groups` argument.
#> `summarise()` has grouped output by 'cyl', 'hp'. You can override using the
#> `.groups` argument.
#> Warning: Some expressions had a GC in every iteration; so filtering is disabled.

glimpse(results)
#> Rows: 2
#> Columns: 13
#> $ expression <bch:expr> <median_qi(draws, .epred)>, <ungroup(rename(summarise(…
#> $ min        <bch:tm> 12.8s, 208.8ms
#> $ median     <bch:tm> 13s, 212ms
#> $ `itr/sec`  <dbl> 0.07678654, 4.60527964
#> $ mem_alloc  <bch:byt> 25.4MB, 4.37MB
#> $ `gc/sec`   <dbl> 1.888949, 1.842112
#> $ n_itr      <int> 5, 5
#> $ n_gc       <dbl> 123, 2
#> $ total_time <bch:tm> 1.08m, 1.09s
#> $ result     <list> <NULL>, <NULL>
#> $ memory     <list> [<Rprofmem[69477 x 3]>], [<Rprofmem[3443 x 3]>]
#> $ time       <list> <12.8s, 13.3s, 13.3s, 12.8s, 13s>, <212ms, 236ms, 209ms,…
#> $ gc         <list> [<tbl_df[5 x 3]>], [<tbl_df[5 x 3]>]
```

<sup>Created on 2022-10-13 with [reprex v2.0.2](https://reprex.tidyverse.org)</sup>

<details style=""margin-bottom:10px;"">
<summary>
Session info
</summary>

``` r
sessioninfo::session_info()
#> ─ Session info ───────────────────────────────────────────────────────────────
#>  setting  value
#>  version  R version 4.2.1 (2022-06-23 ucrt)
#>  os       Windows 10 x64 (build 22621)
#>  system   x86_64, mingw32
#>  ui       RTerm
#>  language (EN)
#>  collate  English_United States.utf8
#>  ctype    English_United States.utf8
#>  tz       America/Chicago
#>  date     2022-10-13
#>  pandoc   2.18 @ C:/Program Files/RStudio/bin/quarto/bin/tools/ (via rmarkdown)
#> 
#> ─ Packages ───────────────────────────────────────────────────────────────────
#>  ! package        * version date (UTC) lib source
#>    abind            1.4-5   2016-07-21 [1] CRAN (R 4.2.0)
#>    arrayhelpers     1.1-0   2020-02-04 [1] CRAN (R 4.2.0)
#>    assertthat       0.2.1   2019-03-21 [1] CRAN (R 4.2.0)
#>    backports        1.4.1   2021-12-13 [1] CRAN (R 4.2.0)
#>    base64enc        0.1-3   2015-07-28 [1] CRAN (R 4.2.0)
#>    bayesplot        1.9.0   2022-03-10 [1] CRAN (R 4.2.0)
#>    bench            1.1.2   2021-11-30 [1] CRAN (R 4.2.1)
#>    bridgesampling   1.1-2   2021-04-16 [1] CRAN (R 4.2.0)
#>    brms           * 2.18.0  2022-09-19 [1] CRAN (R 4.2.1)
#>    Brobdingnag      1.2-7   2022-02-03 [1] CRAN (R 4.2.0)
#>    broom            1.0.1   2022-08-29 [1] CRAN (R 4.2.1)
#>    callr            3.7.2   2022-08-22 [1] CRAN (R 4.2.1)
#>    cellranger       1.1.0   2016-07-27 [1] CRAN (R 4.2.0)
#>    checkmate        2.1.0   2022-04-21 [1] CRAN (R 4.2.0)
#>    cli              3.3.0   2022-04-25 [1] CRAN (R 4.2.0)
#>    cmdstanr         0.5.3   2022-08-01 [1] local
#>    coda             0.19-4  2020-09-30 [1] CRAN (R 4.2.0)
#>    codetools        0.2-18  2020-11-04 [2] CRAN (R 4.2.1)
#>    colorspace       2.0-3   2022-02-21 [1] CRAN (R 4.2.0)
#>    colourpicker     1.1.1   2021-10-04 [1] CRAN (R 4.2.0)
#>    crayon           1.5.2   2022-09-29 [1] CRAN (R 4.2.1)
#>    crosstalk        1.2.0   2021-11-04 [1] CRAN (R 4.2.0)
#>    curl             4.3.3   2022-10-06 [1] CRAN (R 4.2.1)
#>    data.table       1.14.2  2021-09-27 [1] CRAN (R 4.2.0)
#>    DBI              1.1.3   2022-06-18 [1] CRAN (R 4.2.0)
#>    dbplyr           2.2.1   2022-06-27 [1] CRAN (R 4.2.0)
#>    digest           0.6.29  2021-12-01 [1] CRAN (R 4.2.0)
#>    distributional   0.3.1   2022-09-02 [1] CRAN (R 4.2.1)
#>    dplyr          * 1.0.10  2022-09-01 [1] CRAN (R 4.2.1)
#>    DT               0.25    2022-09-12 [1] CRAN (R 4.2.1)
#>    dygraphs         1.1.1.6 2018-07-11 [1] CRAN (R 4.2.0)
#>    ellipsis         0.3.2   2021-04-29 [1] CRAN (R 4.2.0)
#>    emmeans          1.8.1-1 2022-09-08 [1] CRAN (R 4.2.1)
#>    estimability     1.4.1   2022-08-05 [1] CRAN (R 4.2.1)
#>    evaluate         0.17    2022-10-07 [1] CRAN (R 4.2.1)
#>    fansi            1.0.3   2022-03-24 [1] CRAN (R 4.2.0)
#>    farver           2.1.1   2022-07-06 [1] CRAN (R 4.2.1)
#>    fastmap          1.1.0   2021-01-25 [1] CRAN (R 4.2.0)
#>    forcats        * 0.5.2   2022-08-19 [1] CRAN (R 4.2.1)
#>    fs               1.5.2   2021-12-08 [1] CRAN (R 4.2.0)
#>    gargle           1.2.1   2022-09-08 [1] CRAN (R 4.2.1)
#>    generics         0.1.3   2022-07-05 [1] CRAN (R 4.2.1)
#>    ggdist         * 3.2.0   2022-07-19 [1] CRAN (R 4.2.1)
#>    ggplot2        * 3.3.6   2022-05-03 [1] CRAN (R 4.2.0)
#>    ggridges         0.5.4   2022-09-26 [1] CRAN (R 4.2.1)
#>    glue             1.6.2   2022-02-24 [1] CRAN (R 4.2.0)
#>    googledrive      2.0.0   2021-07-08 [1] CRAN (R 4.2.0)
#>    googlesheets4    1.0.1   2022-08-13 [1] CRAN (R 4.2.1)
#>    gridExtra        2.3     2017-09-09 [1] CRAN (R 4.2.0)
#>    gtable           0.3.1   2022-09-01 [1] CRAN (R 4.2.1)
#>    gtools           3.9.3   2022-07-11 [1] CRAN (R 4.2.1)
#>    haven            2.5.1   2022-08-22 [1] CRAN (R 4.2.1)
#>    highr            0.9     2021-04-16 [1] CRAN (R 4.2.0)
#>    hms              1.1.2   2022-08-19 [1] CRAN (R 4.2.1)
#>    htmltools        0.5.3   2022-07-18 [1] CRAN (R 4.2.1)
#>    htmlwidgets      1.5.4   2021-09-08 [1] CRAN (R 4.2.0)
#>    httpuv           1.6.6   2022-09-08 [1] CRAN (R 4.2.1)
#>    httr             1.4.4   2022-08-17 [1] CRAN (R 4.2.1)
#>    igraph           1.3.5   2022-09-22 [1] CRAN (R 4.2.1)
#>    inline           0.3.19  2021-05-31 [1] CRAN (R 4.2.0)
#>    jsonlite         1.8.2   2022-10-02 [1] CRAN (R 4.2.1)
#>    knitr            1.40    2022-08-24 [1] CRAN (R 4.2.1)
#>    later            1.3.0   2021-08-18 [1] CRAN (R 4.2.0)
#>    lattice          0.20-45 2021-09-22 [2] CRAN (R 4.2.1)
#>    lifecycle        1.0.3   2022-10-07 [1] CRAN (R 4.2.1)
#>    loo              2.5.1   2022-03-24 [1] CRAN (R 4.2.0)
#>    lubridate        1.8.0   2021-10-07 [1] CRAN (R 4.2.0)
#>    magrittr         2.0.3   2022-03-30 [1] CRAN (R 4.2.0)
#>    markdown         1.1     2019-08-07 [1] CRAN (R 4.2.0)
#>    MASS             7.3-57  2022-04-22 [2] CRAN (R 4.2.1)
#>    Matrix           1.5-1   2022-09-13 [1] CRAN (R 4.2.1)
#>    matrixStats      0.62.0  2022-04-19 [1] CRAN (R 4.2.0)
#>    mime             0.12    2021-09-28 [1] CRAN (R 4.2.0)
#>    miniUI           0.1.1.1 2018-05-18 [1] CRAN (R 4.2.0)
#>    modelr           0.1.9   2022-08-19 [1] CRAN (R 4.2.1)
#>    multcomp         1.4-20  2022-08-07 [1] CRAN (R 4.2.1)
#>    munsell          0.5.0   2018-06-12 [1] CRAN (R 4.2.0)
#>    mvtnorm          1.1-3   2021-10-08 [1] CRAN (R 4.2.0)
#>    nlme             3.1-157 2022-03-25 [2] CRAN (R 4.2.1)
#>    pillar           1.8.1   2022-08-19 [1] CRAN (R 4.2.1)
#>    pkgbuild         1.3.1   2021-12-20 [1] CRAN (R 4.2.0)
#>    pkgconfig        2.0.3   2019-09-22 [1] CRAN (R 4.2.0)
#>    plyr             1.8.7   2022-03-24 [1] CRAN (R 4.2.0)
#>    posterior        1.3.1   2022-09-06 [1] CRAN (R 4.2.1)
#>    prettyunits      1.1.1   2020-01-24 [1] CRAN (R 4.2.0)
#>    processx         3.7.0   2022-07-07 [1] CRAN (R 4.2.1)
#>    profmem          0.6.0   2020-12-13 [1] CRAN (R 4.2.1)
#>    promises         1.2.0.1 2021-02-11 [1] CRAN (R 4.2.0)
#>    ps               1.7.1   2022-06-18 [1] CRAN (R 4.2.0)
#>    purrr          * 0.3.5   2022-10-06 [1] CRAN (R 4.2.1)
#>    R.cache          0.16.0  2022-07-21 [1] CRAN (R 4.2.1)
#>    R.methodsS3      1.8.2   2022-06-13 [1] CRAN (R 4.2.0)
#>    R.oo             1.25.0  2022-06-12 [1] CRAN (R 4.2.0)
#>    R.utils          2.12.0  2022-06-28 [1] CRAN (R 4.2.0)
#>    R6               2.5.1   2021-08-19 [1] CRAN (R 4.2.0)
#>    Rcpp           * 1.0.9   2022-07-08 [1] CRAN (R 4.2.1)
#>  D RcppParallel     5.1.5   2022-01-05 [1] CRAN (R 4.2.0)
#>    readr          * 2.1.3   2022-10-01 [1] CRAN (R 4.2.1)
#>    readxl           1.4.1   2022-08-17 [1] CRAN (R 4.2.1)
#>    reprex           2.0.2   2022-08-17 [1] CRAN (R 4.2.1)
#>    reshape2         1.4.4   2020-04-09 [1] CRAN (R 4.2.0)
#>    rlang            1.0.6   2022-09-24 [1] CRAN (R 4.2.1)
#>    rmarkdown        2.17    2022-10-07 [1] CRAN (R 4.2.1)
#>    rstan            2.26.13 2022-06-25 [1] local
#>    rstantools       2.2.0   2022-04-08 [1] CRAN (R 4.2.0)
#>    rstudioapi       0.14    2022-08-22 [1] CRAN (R 4.2.1)
#>    rvest            1.0.3   2022-08-19 [1] CRAN (R 4.2.1)
#>    sandwich         3.0-2   2022-06-15 [1] CRAN (R 4.2.0)
#>    scales           1.2.1   2022-08-20 [1] CRAN (R 4.2.1)
#>    sessioninfo      1.2.2   2021-12-06 [1] CRAN (R 4.2.0)
#>    shiny            1.7.2   2022-07-19 [1] CRAN (R 4.2.1)
#>    shinyjs          2.1.0   2021-12-23 [1] CRAN (R 4.2.0)
#>    shinystan        2.6.0   2022-03-03 [1] CRAN (R 4.2.0)
#>    shinythemes      1.2.0   2021-01-25 [1] CRAN (R 4.2.0)
#>    StanHeaders      2.26.13 2022-06-25 [1] local
#>    stringi          1.7.8   2022-07-11 [1] CRAN (R 4.2.1)
#>    stringr        * 1.4.1   2022-08-20 [1] CRAN (R 4.2.1)
#>    styler           1.7.0   2022-03-13 [1] CRAN (R 4.2.0)
#>    survival         3.3-1   2022-03-03 [2] CRAN (R 4.2.1)
#>    svUnit           1.0.6   2021-04-19 [1] CRAN (R 4.2.0)
#>    tensorA          0.36.2  2020-11-19 [1] CRAN (R 4.2.0)
#>    TH.data          1.1-1   2022-04-26 [1] CRAN (R 4.2.0)
#>    threejs          0.3.3   2020-01-21 [1] CRAN (R 4.2.0)
#>    tibble         * 3.1.8   2022-07-22 [1] CRAN (R 4.2.1)
#>    tidybayes      * 3.0.2   2022-01-05 [1] CRAN (R 4.2.0)
#>    tidyr          * 1.2.1   2022-09-08 [1] CRAN (R 4.2.1)
#>    tidyselect       1.2.0   2022-10-10 [1] CRAN (R 4.2.1)
#>    tidyverse      * 1.3.2   2022-07-18 [1] CRAN (R 4.2.1)
#>    tzdb             0.3.0   2022-03-28 [1] CRAN (R 4.2.0)
#>    utf8             1.2.2   2021-07-24 [1] CRAN (R 4.2.0)
#>    V8               4.2.1   2022-08-07 [1] CRAN (R 4.2.1)
#>    vctrs            0.4.2   2022-09-29 [1] CRAN (R 4.2.1)
#>    withr            2.5.0   2022-03-03 [1] CRAN (R 4.2.0)
#>    xfun             0.33    2022-09-12 [1] CRAN (R 4.2.1)
#>    xml2             1.3.3   2021-11-30 [1] CRAN (R 4.2.0)
#>    xtable           1.8-4   2019-04-21 [1] CRAN (R 4.2.0)
#>    xts              0.12.1  2020-09-09 [1] CRAN (R 4.2.0)
#>    yaml             2.3.5   2022-02-21 [1] CRAN (R 4.2.0)
#>    zoo              1.8-11  2022-09-17 [1] CRAN (R 4.2.1)
#> 
#>  [1] C:/Users/trist/AppData/Local/R/win-library/4.2
#>  [2] C:/Program Files/R/R-4.2.1/library
#> 
#>  D ── DLL MD5 mismatch, broken installation.
#> 
#> ──────────────────────────────────────────────────────────────────────────────
```

</details>
",TRUE,"----------------------------
mjskay:

Thanks for this --- finally got around to it. Fix incoming. On your example:

```r
bench::mark(
  median_qi = median_qi(draws, .epred),
  summarise = draws |>
    summarise(median_qi(.epred)) |>
    # So that the output of each are exactly the same
    rename(.epred = y, .lower = ymin, .upper = ymax) |> 
    ungroup(),
  check = FALSE
)
#> # A tibble: 2 × 6
#>   expression      min   median `itr/sec` mem_alloc `gc/sec`
#>   <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>
#> 1 median_qi    33.5ms   35.7ms      28.1     475KB     2.16
#> 2 summarise      38ms   39.9ms      24.9     438KB     2.07
```
",TRUE,performance,2022-10-13 17:27:41,2023-01-05 06:25:04,,,CLOSED,2023-01-05 06:25:04,NA,,I_kwDOEBBtO85T7xEz
153,https://github.com/mjskay/ggdist/issues/153,https://github.com/mjskay/ggdist/issues/153,ShacharHochman,Help with stacking dots with categorical variables,"Hi, and thank you for developing this fantastic package.

I am trying to add stacked dots to the margins of a plot, but it doesn't really work for me. 


```{r}
library(stats)
library(emmeans)
library(tidyverse)
library(ggdist)

set.seed(123)
DF <- data.frame(Y = rbinom(50,1,0.3),
                 Var1 = sample(size = 50,c(""A"",""B""),replace = T),
                 Var2 = sample(size = 50,c(""C"",""D""),replace = T))

Model <- glm(data = DF, Y~Var1*Var2,family = binomial)

Data4Plot <- emmeans(Model,~Var1*Var2, type = ""response"") %>% as.data.frame()


ggplot(Data4Plot, aes(x = Var1, colour = Var2, y = prob))+
  geom_errorbar(aes(ymax = asymp.UCL, ymin = asymp.LCL),
                position = position_dodge(0.3),width = 0.2) +
  geom_point(size = 1.5,position = position_dodge(0.3))+
  stat_dots(data = DF,layout = ""bin"",
            aes(y = Y,
                side = ifelse(Y == 0, ""top"", ""bottom""),
                color = Var2,
                x = Var1),     
            side = ""bottomright"",
            position = position_dodge(0.3))

```

What I am getting is this:

![PlotGit](https://user-images.githubusercontent.com/58937060/194704258-600284f6-05dc-45d5-8a38-484dbe73a79f.jpg)

I hoped the dots would be stacked under each line or at least won't overlap like this. 

I'd appreciate any tips and insights.
",TRUE,"----------------------------
mjskay:

Yeah, this one's a bit tricky.

I'm not 100% sure what you're looking for, so here are two things that might be close. The first one is simpler: if you want the stacks running horizontally but not overlapping, I would pick the side based on `Var1`; something like this:

```r
ggplot(Data4Plot, aes(x = Var1, colour = Var2, y = prob))+
  geom_errorbar(aes(ymax = asymp.UCL, ymin = asymp.LCL),
                position = position_dodge(0.3),width = 0.2) +
  geom_point(size = 1.5,position = position_dodge(0.3))+
  geom_dots(data = DF,layout = ""bin"",
            aes(y = Y,
                side = ifelse(Var2 == ""C"", ""left"", ""right""),
                color = Var2,
                x = Var1),
            shape = 19,
            scale = 0.5
    )
```
![image](https://user-images.githubusercontent.com/6345019/194722318-ec0022dc-2389-4380-9ead-c89b2aa59598.png)

If you want them vertical, it's a bit trickier. You have to override the orientation detection and change the geom orientation to `""horizontal""` (horizontal here meaning the direction of the base of the dots, thus ""horizontal"" instead of ""vertical""). Unfortunately you can't use `position_dodge` here because it will dodge in the opposite direction of what you want, so we have to manually calculate the dodge by adjusting the `x` aesthetic mapping. It gets pretty ugly:

```r
library(stats)
library(emmeans)
library(tidyverse)
library(ggdist)

set.seed(123)
DF <- data.frame(Y = rbinom(50,1,0.3),
                 Var1 = sample(size = 50,c(""A"",""B""),replace = T),
                 Var2 = sample(size = 50,c(""C"",""D""),replace = T))

Model <- glm(data = DF, Y~Var1*Var2,family = binomial)

Data4Plot <- emmeans(Model,~Var1*Var2, type = ""response"") %>% as.data.frame()


ggplot(Data4Plot, aes(x = Var1, colour = Var2, y = prob))+
  geom_errorbar(aes(ymax = asymp.UCL, ymin = asymp.LCL),
                position = position_dodge(0.3),width = 0.2) +
  geom_point(size = 1.5,position = position_dodge(0.3))+
  geom_dots(data = DF,layout = ""bin"",
            aes(y = Y,
                side = ifelse(Y == 0, ""top"", ""bottom""),
                color = Var2,
                x = as.numeric(factor(Var1)) + (Var2 == ""D"") * 0.3 - 0.15),
            shape = 19,
            scale = 0.2,
            orientation = ""horizontal""
    )
```
![image](https://user-images.githubusercontent.com/6345019/194722446-5140a468-0c7a-4fa6-9730-ee6c15ed3d49.png)


----------------------------
ShacharHochman:

Dear Matthew,

Thank you so much for helping me with it. 

I hoped that where there are quite a few dots (e.g., the bottom side), there would be a pile of dots rather than a line of them (or at the very least that they won’t overlap, but this you solved!).

Maybe giving the dots random values that fit the y-axis would make it work?

Thanks again,

Shachar

----------------------------
mjskay:

> I hoped that where there are quite a few dots (e.g., the bottom side), there would be a pile of dots rather than a line of them (or at the very least that they won’t overlap, but this you solved!).

If I understand what you're asking, currently something like that does require manually adding offsets to create the pile (randomly, as you suggest, or perhaps via an evenly-spaced grid). In the future, I do plan to support something like this; see #100. For now, I'll close this issue since there's a workaround and future support will happen via that other issue. Thanks!",TRUE,"help,enhancement",2022-10-08 11:04:32,2022-10-16 01:42:25,,,CLOSED,2022-10-16 01:42:25,NA,,I_kwDOEBBtO85Tj3ZY
152,https://github.com/mjskay/ggdist/issues/152,https://github.com/mjskay/ggdist/issues/152,rcalinjageman,Possible to set interval_size while also showing multiple interval lengths?,"I'm guessing this is not possible, but I'm wondering if there is a way to be able to use .width to plot multiple intervals while also setting interval_size?  Currently, if you use .width then ggdist automatically scales each interval to a different line thickness (plots the 90% CI thicker than the 95% CI, etc).  But if you set interval_size this goes away -- each interval in .width is plotted at the same thickness, so the longest one obscures the others.  Is it possible to make it so that interval_size just sets the starting point for the automatic adjustments done for each value in .width?

Here's what I've been using to plot 90 and 95% CIs together with .width

```
  myplot <- myplot + ggdist::stat_dist_halfeye(
    data = gdata,
    orientation = 'vertical',
    ggplot2::aes(
      x = x_value,
      y = y_value,
      dist = distributional::dist_student_t(
        df = df,
        mu = y_value,
        sigma = SE
      )
    ),
  .width = c(0.9,0.95),
  normalize = 'groups'
  )
```

When I add interval_size both 90% and 95% CIs take on the value, so the 90% CI is masked:

```
  myplot <- myplot + ggdist::stat_dist_halfeye(
    data = gdata,
    orientation = 'vertical',
    ggplot2::aes(
      x = x_value,
      y = y_value,
      dist = distributional::dist_student_t(
        df = df,
        mu = y_value,
        sigma = SE
      )
    ),
  .width = c(0.9,0.95),
  invterval_size = 3,
  normalize = 'groups'
  )
```

For the moment, I'm working around this by manually adding in the 90% CI... but figured I'd ask in case I'd missed something or if it might be something that could be tweaked in future releases.  

As usual, thanks -- this package is amazing.  ",TRUE,"----------------------------
mjskay:

Sorry, not sure exactly what you're looking for --- do you want to increase the width of both intervals proportionately? So both still have different widths, but they are thicker? 

By default stat_halfeye() is setting the `size` aesthetic for you by mapping `.width` onto it. The problem is that by setting interval_size outside of `aes()`, you are setting it to a constant value for both intervals. Instead, you need to adjust the range of sizes that are used for the intervals. One way to do this is using the `interval_size_range` parameter, which determines the min and max width of the intervals:

```r
library(distributional)
library(ggplot2)
library(ggdist)

data.frame(x = dist_normal()) |>
  ggplot(aes(xdist = x)) + 
  stat_halfeye(interval_size_range = c(2, 4))
```
![image](https://user-images.githubusercontent.com/6345019/190445652-f69432c0-8489-4647-92a4-7f0722474b53.png)

is that the kind of thing you're looking for?

----------------------------
rcalinjageman:

Oh, yeah - that's it -- thanks.

----------------------------
mjskay:

Great! happy to help.",TRUE,help,2022-09-15 15:23:03,2022-09-15 16:26:58,,,CLOSED,2022-09-15 16:26:58,NA,,I_kwDOEBBtO85R8Ftc
151,https://github.com/mjskay/ggdist/issues/151,https://github.com/mjskay/ggdist/issues/151,avehtari,dotplot support for counts,"I really like dotplots, and when presenting plots for both continuous and count data, I would like to be able to use the ggdist dotplots to have the same visual style, but also be able to take into account that count is special. 

For example taking the data used in https://dansblog.netlify.app/posts/2022-09-04-everybodys-got-something-to-hide-except-me-and-my-monkey/everybodys-got-something-to-hide-except-me-and-my-monkey.html

and I can control the bin placement in histogram
```
ggplot(data=activity_20minms80_scaled,aes(x=active_bins))+geom_histogram(center=0,bins=80)
```
![image](https://user-images.githubusercontent.com/6705400/190088126-f9827cfe-0dc0-45ea-be45-110377060858.png)

but I would prefer dots instead of bars.

I could use geom_dotplot 
```
ggplot(data=activity_20minms80,aes(x=active_bins))+geom_dotplot(binwidth=1)
```
![image](https://user-images.githubusercontent.com/6705400/190088429-7949a403-02d1-47ce-89e5-03f59b190d81.png)

but it doesn't look as nice as ggdist dotplots, and it has strange scaling issues like
```
ggplot(data=activity_20minms80,aes(x=active_bins))+geom_dotplot(binwidth=4)
```
![image](https://user-images.githubusercontent.com/6705400/190088662-99c8151f-78ea-4f2a-bf7f-8d742aacd06e.png)

geom_dots looks nice with default options
```
ggplot(data=activity_20minms80,aes(x=active_bins))+geom_dots()
```

but it's difficult to ask for a dot plot that would correspond to histogram with a bin at each count value. For bigger data, it could be useful to be state how many consecutive count values are presented with one column of dots, like in histogram you could use `geom_histogram(center=0.5,bins=40)`

Another example with count data (maybe a bit extreme on having a low number of counts)
```
ggplot(data=activity_2mins,aes(x=active_bins))+geom_dots()
```
![image](https://user-images.githubusercontent.com/6705400/190091015-33f66f68-f5b1-42e1-a752-959ce9f1747f.png)


It would be nice to be able to control the number of dots, but keep them on x axis on the integer values. Now trying to control the number of dots with
```
ggplot(data=activity_2mins,aes(x=active_bins))+stat_dots(quantiles=100)
```
is a bit awkward but also produces dots not at the integer values
![image](https://user-images.githubusercontent.com/6705400/190091463-7c077c61-2115-4e57-a31d-b965cdba792f.png)

I'm also fine if you tell that I shouldn't use dotplots for count data.",TRUE,"----------------------------
mjskay:

This is a great list of use cases! You absolutely should be able to use dots for count data, and it's been on my list but I haven't gotten around to it :). This is very helpful for thinking through the set of things we need to support.

Two related issues:
- one on aligning bins #101
- one on an alternative to dealing with bins that are too tall in discrete data that would be to put multiple columns within a bin: #100

As for when: could be relatively soon on my list, since I've also been playing with blurry dotplots for mcse recently (so I'm already in a ""dotplot mood""), but ""relatively soon"" is not well defined since the quarter just started ;) 

----------------------------
mjskay:

Some updates on this on the dev branch:

### Re: applying quantiles but respecting integer bins

This should be possible now if you let ggplot know that the input data is discrete, e.g. by making it a factor:

```r
ggplot(activity_2mins, aes(x = factor(active_bins))) + 
  stat_dots(aes(group = NA), quantiles = 100)
```
![image](https://user-images.githubusercontent.com/6345019/209418400-951dd812-8e91-413c-b22b-41b4f1421e76.png)

It's a bit awkward because you also have to set the `group` to `NA`, as otherwise ggplot automatically sets `group` to all combinations of discrete variables (including `x` in this case), which would lead quantiles to be calculated separately within each bin.

If you want to avoid having to make the x scale discrete, you can also (in dev version) wrap the dist in an rvar, and `stat_dots()` will handle it correctly so long as the original data type is `integer` and not `numeric`:

```r
ggplot() +
  aes(xdist = posterior::rvar(activity_2mins$active_bins)) + 
  stat_dots(quantiles = 100)
```
![image](https://user-images.githubusercontent.com/6345019/209418445-1b19d5e3-9930-40a5-a769-e21677245250.png)

### Other solutions to large count data

The new dotplot smoothing (in dev version) could also help here, by allowing you to plot all the dots without needing to summarize them to a smaller number using `smooth = ""discrete""` or `smooth = ""bar""`. e.g.:

```r
ggplot(activity_2mins, aes(x = active_bins)) + 
  geom_dots(smooth = ""bar"")
```
![image](https://user-images.githubusercontent.com/6345019/209418522-4394fea2-53a9-4fac-8e5d-61601c7fda1c.png)


Does that help? If that addresses everything here (except centering/aligning bins, which is in #101), I might close this.

----------------------------
avehtari:

Looks great!

----------------------------
mjskay:

Great, thanks! ",TRUE,enhancement,2022-09-14 07:41:18,2022-12-28 05:45:42,,,CLOSED,2022-12-28 05:45:42,Next next release,,I_kwDOEBBtO85RzuRm
150,https://github.com/mjskay/ggdist/issues/150,https://github.com/mjskay/ggdist/issues/150,japhir,allow slab subgroups to have different widths,"I have some data where I average many y-values together over a large range of x-values, and I want to be able to draw a gradient that spans the range of x-values. 

As a workaround I have been able to just set a very large `width` and then post-process the gradients in Inkscape. 

I have also tried passing the variable as a width aesthetic, but this still remained the same for each bin.

Here's an image illustrating the desired outcome after specifying either the `width` or an `xmin` and `xmax` as aesthetics:
![ggdist_gradient](https://user-images.githubusercontent.com/10659193/189389071-8bb0c89b-4e1f-4c2f-aa60-16ee6663dba0.png)
",FALSE,"----------------------------
mjskay:

Hmm yeah, this doesn't really work at the moment because slabinterval enforces each subgroup to have the same width. E.g. this is the closest I could get (notice only one group correctly covers the data points along the x axis):

```r
set.seed(1234)

data.frame(
  g = c(""a"",""b""), 
  var1 = rnorm(1000, 1:2), 
  var2 = rnorm(1000)
) |>
  ggplot(aes(
    x = ave(var1, g, FUN = min),
    y = var2, 
    fill = g,
    width = ave(var1, g, FUN = \(x) diff(range(x)))
  )) +
  stat_gradientinterval(scale = 1, side = ""right"", justification = 0, fill_type = ""gradient"", color = NA)  + 
  geom_point(aes(x = var1), pch = 21, alpha = 0.5)
```
![image](https://user-images.githubusercontent.com/6345019/189449852-d62d7d76-dcfa-47d6-a9d0-37519d6481c4.png)


I'm not entirely sure it would be straightforward to relax that constraint on equal widths, as it is used to ensure dodging works properly (unless I'm misremembering), but I can look into it... it's possible I can allow it to be overridden if it's set manually.

----------------------------
japhir:

I'm happy you were able to parse my vague issue into a reprex that precisely reflects my intended outcome, thanks for the effort. For now resolving this does not have priority for me, I'll just tweak the figure manually if needed. But let's leave the issue open to see if there's further interest---or otherwise close it and explain that it may be beyond the scope of the package for now ;-).

----------------------------
mjskay:

:)

I don't mind leaving it open; I might take a stab at fixing it eventually or maybe someone will wander along who's interested.",TRUE,enhancement,2022-09-09 15:42:22,NA,,,OPEN,2022-10-16 01:44:40,NA,,I_kwDOEBBtO85RiiWU
148,https://github.com/mjskay/ggdist/issues/148,https://github.com/mjskay/ggdist/issues/148,davidgohel,gdtools dependency/suggests no more needed,"Hello,

The package suggests and use gdtools because it uses vdiffr, vdiffr is not using gdtools anymore, I think it should be removed.

(I can PR if you agree)

KR
David",TRUE,"----------------------------
mjskay:

oh yeah, please do, thanks!",TRUE,cleanup,2022-09-03 13:25:04,2022-12-23 01:29:46,,,CLOSED,2022-12-23 01:29:46,NA,,I_kwDOEBBtO85RHQhb
147,https://github.com/mjskay/ggdist/issues/147,https://github.com/mjskay/ggdist/issues/147,Dallak,Displaying certain levels in the legend,"Dear all,

I'm having a little issue with the following code. For some reason `Level` in the legend shows other intervals that I didn't specify. I would expect `Level` to display only the specified intervals/quantiles 50% & 95% `.width = c(.5,.95)`. Am I doing something wrong?

Your help is highly appreciated!
Thank you in advance for your time and help!

Here is my code so far.
```

doto  %>% 
  ggplot(aes(.value,  contrast,fill = stat(abs(x) < 0.1))) +
  annotate(""rect"", xmin = -0.1, xmax =0.1, ymin = -Inf, ymax = Inf, alpha = 0.5) +
  stat_halfeye(scale = 0.6, .width = c(.5,.95), show.legend = T) +
  geom_vline(xintercept = 0) +
  geom_vline(xintercept = c(-0.1, 0.1), linetype = ""dashed"")  +
  scale_x_continuous(limits = c(-1.5, 0.7))+
  scale_fill_manual(values = c(""#85c446"", ""#f65a5b""), guide = guide_legend(override.aes = list(interval_size = NA)))+
  scale_color_brewer(palette = ""Dark2"") +
  labs(
    x = ""Differences in F0 onset (SD)"",
    y = element_blank(),
    fill = ""ROPE"",
    size = ""Level"") +  
  theme_bw()+ 
  theme(panel.grid.minor = element_blank()) + theme(text = element_text(size = 13)) 

```

Here is the output.
![Rplot09](https://user-images.githubusercontent.com/47871346/187852660-fca3998e-1dd1-4e2c-a8ab-eea56bc55be3.png)

And here is a test data.


````

doto <- structure(list(contrast = c("" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd"", "" vd -  vd"", 
                                    "" vd -  vd""), .chain = c(NA_integer_, NA_integer_, 
                                                                                   NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_, 
                                                                                   NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_, 
                                                                                   NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_, 
                                                                                   NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_, 
                                                                                   NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_, 
                                                                                   NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_, 
                                                                                   NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_, 
                                                                                   NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_, 
                                                                                   NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_, 
                                                                                   NA_integer_, NA_integer_, NA_integer_), .iteration = c(NA_integer_, 
                                                                                                                                          NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_, 
                                                                                                                                          NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_, 
                                                                                                                                          NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_, 
                                                                                                                                          NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_, 
                                                                                                                                          NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_, 
                                                                                                                                          NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_, 
                                                                                                                                          NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_, 
                                                                                                                                          NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_, 
                                                                                                                                          NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_, 
                                                                                                                                          NA_integer_, NA_integer_, NA_integer_, NA_integer_), .draw = 1:50, 
                       .value = c(0.0174705, 0.0247773, 0.0518621, 0.0471315, 0.1192594, 
                                  -0.062037, 0.1815496, 0.178802, 0.1171299, 0.00421750000000001, 
                                  0.0519203, 0.0100567, 0.0692605999999999, 0.011851, 0.1922884, 
                                  0.0604772, 0.0846947, -0.1609557, -0.1340191, -0.1321877, 
                                  0.1748753, 0.0590828, 0.04812998, 0.0562057, 0.0739188, 0.09274055, 
                                  0.1104683, 0.02650481, -0.01885289, 0.12043568, 0.15456346, 
                                  0.1523477, 0.2193773, 0.15264287, 0.06269871, 0.1398391, 
                                  0.248438, 0.1922545, 0.0546065, 0.0987612000000001, 0.2044553, 
                                  0.0502813, 0.1769909, -0.10835596, 0.2111383, 0.224733707, 
                                  0.24926101, 0.1027173, 0.0906055, 0.0433283)), class = c(""grouped_df"", 
                                                                                           ""tbl_df"", ""tbl"", ""data.frame""), row.names = c(NA, -50L), groups = structure(list(
                                                                                             contrast = "" vd -  vd"", .rows = structure(list(
                                                                                               1:50), ptype = integer(0), class = c(""vctrs_list_of"", 
                                                                                                                                    ""vctrs_vctr"", ""list""))), class = c(""tbl_df"", ""tbl"", ""data.frame""
                                                                                                                                    ), row.names = c(NA, -1L), .drop = TRUE))

```

",TRUE,"----------------------------
mjskay:

Ah yup, the default mapping is continuous instead of discrete for historical reasons (which might actually be fixable now that I think about it). The short answer is to use the `level` computed variable. See this Twitter thread: https://twitter.com/mjskay/status/1559988385665671169?t=qEtAefaUF1U_re7zkxLQFw&s=19

Does that help? 

----------------------------
Dallak:

Awesome! It worked.
Many thanks! 

----------------------------
mjskay:

You're welcome, glad to help! ",TRUE,help,2022-09-01 07:15:16,2022-09-07 19:17:48,,,CLOSED,2022-09-07 19:30:27,NA,,I_kwDOEBBtO85Q9xOg
146,https://github.com/mjskay/ggdist/issues/146,https://github.com/mjskay/ggdist/issues/146,alexdeng,distributional::dist_inflated doesn't work with stat_slabinterval,"Two issues: 
1. distributional::dist_inflated doesn't work with stat_slabinterval
2. halfeye/slab plot is not showing mixture of continuous and discrete distribution correctly. 
To replicate
```
# two zero inflated distributions, they should be equivalent
d1 = dist_mixture(dist_normal(0,0),dist_normal(0,1), weights = c(0.5,0.5))
d2 = dist_inflated(dist_normal(0,1),0.5,x=0)


df = tibble(
  name = c(""d1"", ""d2""),
  dist = c(d1, d2)
)

# this works, but the inflated 0 is not properly shown
ggplot(df[1,], aes(y = name)) +stat_interval(aes(dist = dist)) + stat_halfeye(aes(dist = dist))

# this errors
ggplot(df[2,], aes(y = name)) +stat_interval(aes(dist = dist)) + stat_halfeye(aes(dist = dist))

#>
#>: Computation failed in `stat_slabinterval()`:
#> the condition has length > 1 
```",FALSE,"----------------------------
mjskay:

(setting aside issue 2 for a moment; it is simply a bug and needs to be fixed)

I think fundamentally the issue with density plots in either case here is that the density is infinite at 0. Consequently it is kind of hard to plot as a single slab function. Some other solutions might be:

1. Plotting it as a histogram. Currently stat_histinterval won't work here because it defaults to densities for analytical distributions unless they are determined to be discrete. Could adjust so that it can generate histograms as needed, or at least for discrete/continuous mixtures. Picking the binwidth will be a bit of an issue possibly best left to users, as the spike can be made arbitrarily tall with an arbitrarily small binwidth...
2. Plotting the continuous and discrete portions of the distribution separately. This is probably a more accurate depiction of the distribution, but will require some finagling. Not sure the best way --- maybe a helper function to get the discrete and continuous portions of a mixture and allow those to be plotted on their own.

Probably either solution is useful in some cases, so a good ""meta"" solution might be to implement both of the above and when faced with discrete/continuous mixtures might be to raise a warning or error and point folks in the direction of either solution.

----------------------------
alexdeng:

Yeah. i was thinking for mixture of pointmass with continuous distribution, maybe we need to sample from it first. ",TRUE,"enhancement,formalism",2022-08-22 19:53:01,NA,,,OPEN,2022-10-16 01:45:53,Next next release,,I_kwDOEBBtO85QSCYY
145,https://github.com/mjskay/ggdist/issues/145,https://github.com/mjskay/ggdist/issues/145,Dallak,Legend customization ,"Hi,

Is there a way to customize the legend and remove the black horizontal line that comes with `fill = stat(abs(x) < 0.1))`? Circled in red. It seems a bit distracting but I am sure that there is some way to fix it that I have not figured it out yet. 

Also, it is possible to capitalize the label `level` so it looks similar to `Rope`?

![Rplot05](https://user-images.githubusercontent.com/47871346/184523270-f1b7d397-4ea4-49fa-b6f1-a1c1a507cec7.png)


Many thanks in advance!",TRUE,"----------------------------
Dallak:

Here is my code in case it matters.

```
vot_1_p %>% filter(.variable %in% c(""vd"",""ini"",""med"",""/aː/"")) %>% 
  ggplot(aes(.value, .variable,fill = stat(abs(x) < 0.1))) +
  annotate(""rect"", xmin = -0.1, xmax =0.1, ymin = -Inf, ymax = Inf, alpha = 0.5) +
  stat_halfeye( scale = 0.5) +
  geom_vline(xintercept = 0) +
  
  geom_vline(xintercept = c(-0.1, 0.1), linetype = ""dashed"") +
  scale_x_continuous(limits = c(-1.2, 1.2))+theme_bw()+
  
  scale_fill_manual(values = c(""gray80"", ""skyblue""))+
  stat_interval(position = position_nudge(y = -0.2), size = 2)+
  scale_color_brewer() +
  #scale_x_continuous(breaks = seq(150, 50, 200)) +
  #scale_y_discrete(labels = c(""Speech rate (ctrd)"", ""Polish × voiced"", ""Italian × voiced"", ""Polish"", ""Italian"", ""C2 voicing = voiced"")) +
  labs(
    x = ""Difference ..."",
    y = element_blank(),
    fill = ""Rope""
  ) +
  theme(panel.grid.minor = element_blank()) + theme(text = element_text(size = 15)) 
```

----------------------------
mjskay:

Ah yeah --- because you are setting `size = 2` on the call to `stat_interval()`, then the legend for `fill` has `size = 2` applied to it, which means it gets a sub-geometry for the interval, which is the black line you are seeing. You can override aesthetics for a specific legend using the `override.aes` argument to `guide_legend()`. In your case, this means adding something like:

`guide = guide_legend(override.aes = list(interval_size = NA))`

to the call to your fill scale function (in this case `scale_fill_manual()`) so that the size of the interval is set to `NA` for the legend and the black line is not drawn.

Re: the title of ""level"", this is just an automatic `color` scale, so you can change it the same way you change other scale titles, e.g. by passing `color = ""Level""` to the `labs()` function.

An example with both changes:

```r
data.frame(x = rnorm(1000), var = c(""a"",""b"")) %>% 
  ggplot(aes(x, var, fill = stat(abs(x) < 1.5))) + 
  stat_halfeye(scale = 0.5) +
  stat_interval(position = position_nudge(y = -0.2), size = 2)+
  scale_fill_manual(values = c(""gray80"", ""skyblue""), guide = guide_legend(override.aes = list(interval_size = NA))) +
  scale_color_brewer() +
  labs(
    fill = ""Rope"",
    color = ""Level""
  )
```
![image](https://user-images.githubusercontent.com/6345019/184558169-96232b1f-d796-46d5-9fcd-848de6424de4.png)
",TRUE,help,2022-08-14 04:55:45,2022-08-14 23:07:43,,,CLOSED,2022-08-14 23:07:43,NA,,I_kwDOEBBtO85PwlDn
144,https://github.com/mjskay/ggdist/issues/144,https://github.com/mjskay/ggdist/issues/144,avehtari,Strange right edge behavior in dot plots,"The dot plot is not symmetric, and for both x or -x as input the rightmost column of dots is too short. I would expect the plot with -x to be mirror image of plot with x (at least almost).
```
library(ggplot2)
library(ggdist)
library(patchwork)

set.seed(1)
ru=runif(4000)

p1=data.frame(x=ru) |> ggplot(aes(x=x)) +  stat_dotsinterval(quantiles=4000)
p2=data.frame(x=-ru) |> ggplot(aes(x=x)) + stat_dotsinterval(quantiles=4000)
p1/p2

p1=data.frame(x=ru) |> ggplot(aes(x=x)) +  stat_dotsinterval(quantiles=400)
p2=data.frame(x=-ru) |> ggplot(aes(x=x)) + stat_dotsinterval(quantiles=400)
p1/p2
```
![image](https://user-images.githubusercontent.com/6705400/184311044-9bec117e-6fd4-4c84-bf6d-2d849f19b9f9.png)
![image](https://user-images.githubusercontent.com/6705400/184311085-36f81d58-f0a5-4042-a6eb-767a56ebaefd.png)

I tried to look at the code, but could in a few minutes to find the relevant place which would cause this artefact.

The bounded range is difficult and histogram has also edge effects, but the edge effect is symmetric
```
p1=data.frame(x=ru) |> ggplot(aes(x=x)) +  geom_histogram(bins=40)
p2=data.frame(x=ru) |> ggplot(aes(x=-x)) + geom_histogram(bins=40)
p1/p2
```
![image](https://user-images.githubusercontent.com/6705400/184311774-27ac459c-738e-47e4-ae03-aa54be407949.png)

It may be that I just don't understand the dots plot algorithm and the reason for non-symmetric behavior, and maybe this doesn't need fixing, but I hope this issue makes it easier to discuss this",TRUE,"----------------------------
avehtari:

Adding that with layout='weave', the same artefact is visible, and with layout='swarm' the plots look more symmetric (with symmetric edge effect as in histogram, which is fine when the bounds are unknown)

----------------------------
mjskay:

Yeah, this is a result of the binning algorithm starting from the left edge of the data. Basically, the idea is to:

1. start at the smallest value, say x
2. combine all data points <= x + binwidth into a bin
3. place those values in a stack of dots centered on the midpoint of the range of that bin
4. repeat with x = the next largest datapoint above the last bin 

This differs from histogram binning in that it allows bins with only one datapoint to be placed ""exactly"" (in the sense that the dot is centered on that datapoint).

Alternatives include binning from the right, binning from the center outwards (which is currently done automatically only in cases with theoretical distributions that are exactly symmetrical, as it can cause artifacts otherwise), or using a histogram binning algorithm (which does not allow bins with single dots to be placed ""exactly""). 

Not sure the best solution. Currently all but the histogram algorithm are implemented internally, but not exposed to the user. An ""easy"" solution would be to allow finer control over the layout algorithm by selecting among these. I say ""easy"" because it might be preferable to have something that works well automatically without manual tweaking. Perhaps at least exposing this choice would be a good start, and improvements to automatic bin method selection can be made later.

----------------------------
mjskay:

Okay, I thought about this more and I think I've got a robust solution now on the [dev](https://github.com/mjskay/ggdist/tree/dev) branch. It should correct the edge effect (has done so on everything I've tried). It doesn't guarantee mirrored data gives a mirrored layout, but I think it should be close enough. On your example:

```r
set.seed(1)
ru=runif(4000)

p1=data.frame(x=ru) |> ggplot(aes(x=x)) +  stat_dotsinterval(quantiles=4000)
p2=data.frame(x=-ru) |> ggplot(aes(x=x)) + stat_dotsinterval(quantiles=4000)
p1/p2
```
![image](https://user-images.githubusercontent.com/6345019/208559095-4bda0bbf-c17c-42ae-bf9e-b796fc1241e1.png)

```r
p1=data.frame(x=ru) |> ggplot(aes(x=x)) +  stat_dotsinterval(quantiles=400)
p2=data.frame(x=-ru) |> ggplot(aes(x=x)) + stat_dotsinterval(quantiles=400)
p1/p2
```
![image](https://user-images.githubusercontent.com/6345019/208559147-65e3b1bb-fd18-4573-a772-d76ef13fc39b.png)





----------------------------
avehtari:

Great!",TRUE,enhancement,2022-08-12 08:07:41,2022-12-27 02:47:18,,,CLOSED,2022-12-27 02:47:18,NA,,I_kwDOEBBtO85Pr1JN
143,https://github.com/mjskay/ggdist/issues/143,https://github.com/mjskay/ggdist/issues/143,DominiqueMakowski,geom_dots: sort the stacking by color,"Hi! I have a case similar to the following:

``` r
library(ggplot2)
library(ggdist)

data <- iris
data$color <- cut(data$Petal.Length, 3, labels = c(""red"", ""blue"", ""green""))
data$Sepal.Length <- round(data$Sepal.Length, 0)
data$y <- ifelse(data$Petal.Width > mean(data$Petal.Width), 1, 0)
data$side <- ifelse(data$y == 1, ""bottom"", ""top"")

ggplot(data) +
  geom_dots(
    aes(x = Sepal.Length, y = y, group = Petal.Width, side = side), 
    fill = data$color, color = NA
    ) 
```

![](https://i.imgur.com/8oJEOFM.png)

<sup>Created on 2022-08-03 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>

I am stacking dots (for a binomial model, hence the y-axis is 0-1 with dots on the top and bottom). These dots are filled with some other value (in my case, it's not passed via an aesthetic). I wonder if it's possible to stack the dots by color (for instance, red first, then blue etc.)

I tried arranging the data but this actually changes the color, which I'm not exactly sure why 🤔 

``` r
ggplot(data) +
  geom_dots(
    data = dplyr::arrange(data, color),
    aes(x = Sepal.Length, y = y, group = Petal.Width, side = side), 
    fill = data$color, color = NA
    ) 
```

![](https://i.imgur.com/jku43wO.png)

<sup>Created on 2022-08-03 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>
",TRUE,"----------------------------
mjskay:

Should be doable as of the recently-released version 3.2 --- I added an `order` aesthetic which determines the sort order of elements in the bins. See the second example under *Varying discrete aesthetics within dot groups* here: https://mjskay.github.io/ggdist/articles/dotsinterval.html#varying-discrete-aesthetics-within-dot-groups

Does that help?

----------------------------
DominiqueMakowski:

Sorry I missed that! It looks like exactly what I'd need but it doesn't seem to work (I reinstalled the latest GH version) - see the green dot in between the blue ones. Maybe I misspecified something? I tried with `fill` being outside and inside aesthetics

``` r
library(ggplot2)
library(ggdist)

data <- iris
data$color <- cut(data$Petal.Length, 3, labels = c(""red"", ""green"", ""blue""))
data$Sepal.Length <- round(data$Sepal.Length, 0)
data$y <- ifelse(data$Petal.Width > mean(data$Petal.Width), 1, 0)
data$side <- ifelse(data$y == 1, ""bottom"", ""top"")

ggplot(data) +
  geom_dots(
    aes(x = Sepal.Length, y = y, group = Petal.Width, side = side, fill=color, order = color)
  ) 
```

![](https://i.imgur.com/8SQKzSx.png)



<sup>Created on 2022-08-03 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>



----------------------------
DominiqueMakowski:

Found! it was messing with the group aesthetic, once I removed it it works :) thanks a lot!

``` r
library(ggplot2)
library(ggdist)

data <- iris
data$color <- cut(data$Petal.Length, 3, labels = c(""red"", ""green"", ""blue""))
data$Sepal.Length <- round(data$Sepal.Length, 0)
data$y <- ifelse(data$Petal.Width > mean(data$Petal.Width), 1, 0)
data$side <- ifelse(data$y == 1, ""bottom"", ""top"")

ggplot(data) +
  geom_dots(
    aes(x = Sepal.Length, y = y, side = side, order = color),
    fill=data$color
  ) 
```

![](https://i.imgur.com/6xruBsr.png)

<sup>Created on 2022-08-03 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>


----------------------------
mjskay:

No prob!

Aside: I believe the ""canonical"" way to pass through specific values to an aesthetic without having them adjusted by the scale function (as you are doing with `fill`) is to wrap them in `I()`. Something like this:

```r
ggplot(data) +
  geom_dots(
    aes(x = Sepal.Length, y = y, side = side, fill = I(color), order = color)
  )
```

----------------------------
DominiqueMakowski:

Thanks for the hint :)

it's too beautiful now 🥲
 
![image](https://user-images.githubusercontent.com/8875533/182518978-a6993c21-ca1e-4667-a776-3566cc96ae0b.png)




----------------------------
mjskay:

wow! pretty :)

----------------------------
DominiqueMakowski:

(wrapping inside `I()` doesn't seem to work though, but I'll look into that once I stop marvelling at my plots) 

----------------------------
DominiqueMakowski:

Another minor remark, I try setting up order as an interaction with `side` to have for instance the red dots always on the ""top"", but it doesn't seem to be taken into account as well:

Here, the blue dots are always close to the bottom or top (depending on side) regardless of the interaction:

``` r
library(ggplot2)
library(ggdist)

data <- iris
data$color <- cut(data$Sepal.Width, 3, labels = c(""red"", ""green"", ""blue""))
data$x <- as.numeric(cut(data$Sepal.Length, 4, labels = 1:4))
data$y <- ifelse(data$Petal.Width > mean(data$Petal.Width), 1, 0)
data$side <- ifelse(data$y == 1, ""bottom"", ""top"")

ggplot(data) +
  geom_dots(
    aes(x = x, y = y, side = side, order = interaction(color, side)),
    fill=data$color
  ) 
```

![](https://i.imgur.com/QUKdNOQ.png)

``` r
# Same as:

ggplot(data) +
  geom_dots(
    aes(x = x, y = y, side = side, order = color),
    fill=data$color
  ) 
```

![](https://i.imgur.com/dXmIEny.png)

``` r
ﬀƴ
#> Error in eval(expr, envir, enclos): object 'ﬀƴ' not found
```

<sup>Created on 2022-08-03 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>


----------------------------
mjskay:

You seem to have overlapping dots because your y value is numeric and not a factor (so ggplot doesn't automatically group by y, which means you actually have multiple dotplots at each y position). This is making it hard to see what the chart is doing --- one easy solution is to add a `group = y` aesthetic.

Then you can adjust the order of colors for different sides by reversing its order within one group (e.g. by multiplying it by -1). Something like this:

```r
ggplot(data) + 
  geom_dots(aes(
    x = x, y = y, side = side, 
    order = as.numeric(color) * ifelse(y == 1, 1, -1), 
    group = y, 
    fill = I(color)
  ),
  scale = 0.75
)
```
![image](https://user-images.githubusercontent.com/6345019/182535379-c3b0024c-6c1f-4fad-9ba3-b71f4a52e985.png)

Is that what you were looking for?",TRUE,help,2022-08-03 03:20:36,2022-08-03 03:33:33,,,CLOSED,2022-08-03 06:02:00,NA,,I_kwDOEBBtO85PErK5
142,https://github.com/mjskay/ggdist/issues/142,https://github.com/mjskay/ggdist/issues/142,mjskay,Add a scale_side_mirrored for making logit dotplots,Should make it a bit easier ,TRUE,,FALSE,"enhancement,formalism",2022-07-28 23:22:50,2023-01-09 04:55:41,,,CLOSED,2023-01-09 04:55:41,NA,,I_kwDOEBBtO85OxdYj
141,https://github.com/mjskay/ggdist/issues/141,https://github.com/mjskay/ggdist/issues/141,mjskay,Thickness todos,"Before I forget:

- [x] Fix that casting bug (missing exports)
- [x] use thickness() in cdf stat
",TRUE,,FALSE,bug,2022-07-18 06:02:58,2022-07-18 20:31:20,,,CLOSED,2022-07-18 20:31:20,NA,,I_kwDOEBBtO85N7geS
140,https://github.com/mjskay/ggdist/issues/140,https://github.com/mjskay/ggdist/issues/140,mjskay,variant of vline / hline with ribbon,Might be nice to have a version of lineribbon / pointinterval that acts like geom_vline / geom_hline plus a ribbon. See e.g. https://twitter.com/SolomonKurz/status/1546241985597546497?s=20&t=ezZYkV4REc7LfdfFvYAPOg,FALSE,"----------------------------
mjskay:

Name is one question... seems odd to have a geom_hlineribbon and geom_vlineribbon in this modern orientation-aware ggplot landscape. Maybe geom_hvlineribbon? Feels awkward.

----------------------------
mjskay:

looking at some related words and synonyms there's stuff like: axis-aligned, parallel, flat, flush, rule, ...

no great names, and vlineribbon / hlineribbon are probably the most discoverable. So maybe use those names as aliases for each other / hvlineribbon and let orientation detection do its work.

----------------------------
mjskay:

also a vribbon and hribbon variant probably

----------------------------
mjskay:

Also consider: should this have a gradient variant that allows mapping pdf/cdf? Would actually work easily here unlike with lineribbon. 

----------------------------
mjskay:

more thoughts: the gradient pdf/cdf thing isn't really worth it atm.

This should be doable by making sure geom_lineribbon works with infinite bounds. So I'd say the simple version of this is something like:

- [ ] add a `stat_vlineribbon()` and `stat_hlineribbon()` that just generate the necessary `c(-Inf, Inf)` x/y values to get a vertical ribbon
- [ ] maybe add a `stat_ablineribbon()` which takes a 2d dist in the `dist` aesthetic giving the joint dist over slope and intercept and generates a line from it. Might move that to another issue.",TRUE,enhancement,2022-07-10 21:54:37,NA,,,OPEN,2023-03-24 05:07:27,NA,,I_kwDOEBBtO85NfNEX
139,https://github.com/mjskay/ggdist/issues/139,https://github.com/mjskay/ggdist/issues/139,qdread,Is it possible to automatically color quantile dotplots by the quantile?,"I am curious whether the color or fill aesthetic for quantile dotplots can be automatically mapped to the quantiles themselves, for instance if I do a 100-quantile dotplot and would like to color the 1st and 100th dots differently than the other ones, within each group. 

For example, how would I color the 1st and 100th points from each of these two groups' quantile dotplots a different color than the others?

`ggplot(data = data.frame(x = rnorm(2000, mean=c(0,2)), g = c('a','b')), aes(x=x,y=g)) + stat_dotsinterval(quantiles=100)`

Thanks for the great package!",TRUE,"----------------------------
mjskay:

Good question! In future versions this will be easier because I am planning to include the `cdf` computed variable for dotplots, so you would have access to the `cdf` variable from which you can determine the quantile associated with each data point.

In the mean time, you can use the (undocumented) fact that a `dist` column is generated containing a list of [distributional](https://pkg.mitchelloharawild.com/distributional/) objects associated with each distribution that is visualized. While this feature is not documented, I don't expect it to go away any time soon. It does make for a bit of a hackier solution, as it being a list column means you have to use `mapply()` to get the quantiles (i.e. you can't do `quantile(dist, 0.1)` you have to do `mapply(quantile, dist, 0.1)`). This makes for an ugly but workable solution:

```r
data.frame(x = rnorm(2000, mean=c(0,2)), g = c('a','b')) |>
  ggplot(aes(x = x, y = g)) +
  stat_dotsinterval(aes(fill = stat(mapply(quantile, dist, .01) < x & x < mapply(quantile, dist, .99))), quantiles = 100) +
  labs(fill = ""q01 < x < q99"")
```
![image](https://user-images.githubusercontent.com/6345019/177872448-9d283d6b-ab53-4005-9683-2716015e23a5.png)

As I said, future versions will make this a lot easier, but for now the above solution should work.

----------------------------
qdread:

This is amazingly helpful, thanks a bunch! I look forward to the shiny new version 😀 

----------------------------
mjskay:

You're welcome! ",TRUE,"help,enhancement",2022-07-07 19:51:46,2022-07-08 05:44:57,,,CLOSED,2022-07-08 05:45:11,NA,,I_kwDOEBBtO85NXhrf
138,https://github.com/mjskay/ggdist/issues/138,https://github.com/mjskay/ggdist/issues/138,mjskay,Add new linewidth aes,"See here: https://twitter.com/thomasp85/status/1537024892293599235?t=FEzmrpgT2HymjRMp8Fn2uQ&s=19

This is probably going to involve some disentangling (and deprecating) of things like point_size and interval_size and such. ",TRUE,"----------------------------
mjskay:

Might also be an opportunity to change the default mapping in pointinterval to use `level` instead of `.width` so that legends are more sensible by default. Have to double check if warnings are generated though (hopefully not for ordinal variables?). See #147. 

----------------------------
mjskay:

- [x] add new scales
   - [x] `slab_linewidth`
- ~~[ ] deprecate old scales~~ -> #164 
   - ~~[ ] `slab_size` -> `slab_linewidth`~~
   - ~~[ ] `interval_size` -> `linewidth`~~

----------------------------
mjskay:

- [x] `stat()` -> `after_stat()`

----------------------------
mjskay:

- [x] update vignette diagrams

----------------------------
psychelzh:

Yes! Currently, say `stat_dotsinterval()` will give warning after {ggplot2} upgraded to 3.4.0.

```bash
Warning: Using the `size` aesthietic with geom_segment was deprecated in ggplot2 3.4.0. Please use the `linewidth` aesthetic instead.
```

----------------------------
mjskay:

Yup, see the ggplot34 branch of ggdist for a mostly complete fix (still needs a bit of polish): https://github.com/mjskay/ggdist/tree/ggplot3.4",FALSE,formalism,2022-06-15 14:52:39,2022-12-27 02:47:36,,,CLOSED,2022-12-27 02:47:36,NA,,I_kwDOEBBtO85L1qIW
137,https://github.com/mjskay/ggdist/issues/137,https://github.com/mjskay/ggdist/issues/137,Dallak,Modify 'abs' label in `fill = stat(abs(x))`,"Dear @mjskay,

Thanks for this impressive visualization tool!

I am wondering if it is possible to modify the `abs` label in `fill = stat(abs(x))` to another (informative?) label. If so, could you please provide some guidance?

Thanks in advance!
 ",TRUE,"----------------------------
mjskay:

You should be able to modify the label as with other labels in ggplot2, using `ggplot2::labs()` (see [here](https://ggplot2.tidyverse.org/reference/labs.html)).

e.g. something like `+ labs(fill = ""some label"")`",TRUE,help,2022-06-15 00:49:23,2022-06-15 01:27:51,,,CLOSED,2022-06-15 01:27:51,NA,,I_kwDOEBBtO85LyebK
136,https://github.com/mjskay/ggdist/issues/136,https://github.com/mjskay/ggdist/issues/136,arthur-albuquerque,Shortest Probability Interval support,"Hi Matthew, 

Do you plan to support the Shortest Probability Interval (further details [here](https://easystats.github.io/bayestestR/reference/spi.html)) with functions like ggdist::median_spi?

Thanks!",FALSE,"----------------------------
mjskay:

Ah at the moment I probably don't have time to investigate it, though I don't in principle object if it is a better variant of HDIs. How does it differ from `hdci()`? 

----------------------------
arthur-albuquerque:

[This thread](https://github.com/easystats/bayestestR/issues/521) by @bwiernik seems relevant.

----------------------------
mjskay:

Ah hrm. So it's also based on density estimators? I guess I'm not sure the advantage without doing more comparison (or seeing comparisons others have done if there are some). One nice property of hdci is that it doesn't require a density estimator.

----------------------------
bwiernik:

The major advantage of SPI over HDI is reduced Monte Carlo error error. https://doi.org/10.1007/s11222-015-9563-8

Both HDI via empirical shortest distance algorithm and SPI via the method linked above are implemented in *bayetestR* if you wanted to swap in that for *HPDInterval*

----------------------------
mjskay:

Yeah the reason I'm interested specifically in comparisons of SPI to HDCI (not HDI) is that HDCI uses the CDF approach from HDInterval, so if those two methods are similar I can (lazily) just leave things as they are ;)

----------------------------
bwiernik:

What's HDCI stand for?

----------------------------
bwiernik:

@DominiqueMakowski I think you had some simulation code for comparing intervals set up? Could you compare 80% and 95% intervals for HDI, HDCI, and SPI?

----------------------------
arthur-albuquerque:

""hdci yields the highest-density continuous interval"" https://mjskay.github.io/ggdist/reference/point_interval.html

----------------------------
mjskay:

I should probably state more clearly what hdci is in the docs. It uses the algorithm for a continuous interval from HDInterval, which basically uses the ECDF to find the smallest interval of the specified mass: https://github.com/mikemeredith/HDInterval/blob/main/R/hdiVector.R

It is nice because it is simple, fast, and does not rely on picking a density estimator. But if the SPI algorithm has lower error maybe I'd switch it to that. Or a better option might be for me to make sure `point_interval(.interval = ...)` is compatible with the interval functions in bayestestR.

----------------------------
DominiqueMakowski:

> I think you had some simulation code for comparing intervals set up?

I can't seem to find it, but it was basically a big loop generating various distributions of different sizes and computing the different types of CIs. I'm not sure how we can reliably assess the ""error"" 🤔 

Unless it already exists, it would be quite interesting to create a gist/vignette/paper that would 1) describe and explain the advantages/caveats of each interval method, 2) provide clean, community-contributed, R code to compute them (that could be re-used in other packages), and 3) provide some benchmarking on efficiency & behavior 

<sub>(PS: I will be co-editing a special issue in *Mathematics* on Advances in Statistical Computing and I'm pretty sure such work would be a great fit...)</sub>
 

----------------------------
mjskay:

> Unless it already exists, it would be quite interesting to create a gist/vignette/paper that would 1) describe and explain the advantages/caveats of each interval method, 2) provide clean, community-contributed, R code to compute them (that could be re-used in other packages), and 3) provide some benchmarking on efficiency & behavior

This is a great idea! I would be happy to help with something like this but don't really have the time to lead it. Maybe I could see if one of my students is interested...

----------------------------
DominiqueMakowski:

> Maybe I could see if one of my students is interested...

good idea! also tagging ~@easystats/maintainers~ (oops that doesn't work outside of the org) @strengejacke @mattansb  

----------------------------
mattansb:

Sounds great! I'm in (:

----------------------------
mattansb:

Doesn't the current implementation of `bayestestR::hdi()` actually return HDCI (and doesn't estimate any densities, a-la Kruschke), i.e. always a single interval is returned?
I'm still not clear how this isn't the same as PSI...?

----------------------------
mattansb:

Ah, I see this is a different algo to estimate the same thing as HDCI. Cool!

----------------------------
strengejacke:

Yeah, I'm interested in supporting a paper, too!

----------------------------
DominiqueMakowski:

Just need someone that actually does the job now 😁 

----------------------------
mjskay:

Alright I started playing with this for my own curiosity. Some comparisons here: https://github.com/mjskay/interval-estimators/blob/main/interval-estimators.md (source Rmd in same repo).

I can see three broad classes worth investigating:
- equi-tailed intervals, for which the usual estimator is the quantile interval (which could come in several forms; e.g. `quantile()` has 9 different quantile estimators). `ggdist::qi()` and `bayestestR::eti()` are examples
- shortest intervals, for which there is the empirical shortest interval based on quantiles (which could come in as many forms as the equi-tailed intervals); I believe `ggdist::hdci()` and `bayestestR::hdi()` are examples; then there is the ""Spin"" algorithm implemented as `bayestestR::spi()`; I also added a rough implementation of a variant that can use any of the 9 different quantile estimators in `quantile()` to the above document (see the function `quantile_shortest_interval()`.
- highest-density intervals, which unlike the other two may consist of multiple intervals. Implementations include `ggdist::hdi()` / `HDInterval::hdi(density(x))`, `hdrcde::hdr()`, and `distributional::hdr()`

I have been looking at a few quantities of interest:
- root mean squared error of the lower and upper ends of the intervals
- mean percentage overlap of the estimated interval with the true interval
- coverage (probability mass of the true distribution contained by the interval)
- variance (sd) of the endpoints of the intervals

Also to look at: bias. 

One intriguing thing so far is that SPI doesn't perform much differently on these metrics compared to the empirical shortest interval implementations (with the exception of having coverage closer to nominal), which is surprising as the SPI paper says SPI should have lower error than HDCI. I'm not sure if that's an implementation issue or what.

The other thing I've found so far is that amongst HDI algorithms, `distributional::hdr()` is looking the best. In particular it has lower variance than others, performing consistently down near quantile intervals in terms of variance. All the other algorithms for HDIs or HDCIs tend to have higher variance than quantile intervals, which is why I have tended to recommend against HDIs and HDCIs. But changing the underlying implementation of HDIs to the one in distributional might reduce that concern for cases when HDIs are desired (so long as multiple intervals are acceptable). 

See e.g. this chart: these are 80% ribbons; there are 100 groups along the x axis, each a sample of size 10,000 from N(0,1). As far as I'm concerned qi and (barely) hdr are the only two with acceptable variance here. The other three are different algorithms for shortest intervals. Given that 10,000 tends to be the upper end of effective sample sizes people tend to generate from MCMC, unless there's a better algorithm out there for shortest intervals we aren't aware of, I'm not sure I'd recommend using them...

![image](https://user-images.githubusercontent.com/6345019/177066267-64dbd266-d9b5-43db-99dd-d6933e242c02.png)


----------------------------
mattansb:

I find it very surprising that even with 500 samples the methods don't differ that much (and that SPI seems to have relatively larger variance, if ever so slightly...).

Would it be interesting to compare these methods with [`ggdist::curve_interval()`](https://mjskay.github.io/ggdist/reference/curve_interval.html) in the context of interval-bands? Or is that too different of an approach?

----------------------------
mjskay:

> Would it be interesting to compare these methods with [ggdist::curve_interval()](https://mjskay.github.io/ggdist/reference/curve_interval.html) in the context of interval-bands? Or is that too different of an approach

I think the comparison could make sense for single distributions. For multiple distributions, `curve_interval()` is not really looking at the same thing.",TRUE,enhancement,2022-05-15 02:08:50,NA,,,OPEN,2022-07-09 18:56:58,NA,,I_kwDOEBBtO85JrmKR
135,https://github.com/mjskay/ggdist/issues/135,https://github.com/mjskay/ggdist/issues/135,bwiernik,"Add ""missing"" bare slab stats","Most of the slab stats (slab, dots, etc.) have both bare and +interval versions. 4 don't (hist, gradient, cdf, ccdf). Do you think it would be possible to add versions of these 4 without the point and interval included? This would be useful to be able to control the positioning of each part separately. The main one I'm currently interested in hist.",TRUE,"----------------------------
mjskay:

Hmmm I've been trying to limit some of the shortcuts since (in theory) they can all be recreated from `stat_slabinterval()` or `geom_slabinterval()`. The documentation now attempts to make this clearer with auto-generated code chunks at the top of each geom/stat page giving the options used to create the corresponding shortcut geom, under ""Roughly equivalent to:"".

e.g. if you look at the options used to create `stat_slab()` at the top of its [doc page](https://mjskay.github.io/ggdist/reference/stat_slab.html) probably the simplest way to get rid of the intervals with the stat forms is something like `stat_histinterval(geom = ""slab"")`. You could also do something like `stat_histinterval(color = NA)`, or go the other way and start from `stat_slab()` and pass it the options used to create the histogram listed at the top of the [stat_histinterval() doc page](https://mjskay.github.io/ggdist/reference/stat_histinterval.html), which might be something like `stat_slab(slab_type = ""histogram"")`.

That said, I'm not necessarily opposed to creating these shortcuts, I just want to be cautious about creating infrequently-used ones. The idea behind the shortcuts was mostly to cover frequently-used combinations that might be hard to remember. Maybe it would help me to understand what your use case is for them?

----------------------------
bwiernik:

The main one I'm interested in is hist. I'm coming to prefer histograms over densities at least in some situations. I usually like to dodge the intervals a bit separately from the slab (like in the vignette example), so being able to do that easily with hist would be really useful for me 

Edit: I didn't realize that stat_slab could modify the type of slab with stat_slab(slab_type = ""histogram""). That totally works for me

----------------------------
mjskay:

Ah k cool! Yeah, there are really only three geoms/stats in ggdist: lineribbon, slabinterval, and dotsinterval. Everything else is just shortcuts for options that can be recombined as you want. ",TRUE,enhancement,2022-04-27 04:38:50,2022-05-17 01:16:29,,,CLOSED,2022-05-17 02:04:38,NA,,I_kwDOEBBtO85IhqE-
134,https://github.com/mjskay/ggdist/issues/134,https://github.com/mjskay/ggdist/issues/134,Ari04T,base ggplot2 key glyphs don't know about aesthetic overrides,"Hello

ggplot2 seems to allow the modification of the key glyph by using the `key_glyph` parameter inside a geom or stat. 

An example is:
```R
p <- ggplot(economics, aes(date, psavert, color = ""savings rate""))
# key glyphs can be specified by their name
p + geom_line(key_glyph = ""timeseries"")
```
![](https://ggplot2.tidyverse.org/reference/draw_key-1.png)

If I try to do this with ggdist, I get an error.
```R
mtcars %>% 
    ggplot(aes(x = mpg, y = as.factor(cyl))) +
    stat_slab(aes(fill = as.factor(cyl)),
              key_glyph = ""timeseries"")
Error in check.length(""col"") : 'gpar' element 'col' must not be length 0
```
I'm guessing this means that the default ""col"" parameter is missing from the layer and the key_glyph parameter throws an error. Is there a way to add default parameters to the layer?

Thanks",FALSE,"----------------------------
mjskay:

Hmmm this is because of how {ggdist} handles override aesthetics (like `slab_color` for `color`) internally. The `alpha` and `linetype` aesthetics are not being set for the key unless they are set explicitly, so that ggdist keys for composite geometries (like halfeye) can detect which sub-geometries actually have aesthetics set for them. The ggdist key functions know how to retrieve the default values of these aesthetics from the geometry, but the base ggplot2 key functions don't.

A workaround is to specify them manually; e.g.:

```r
mtcars %>% 
    ggplot(aes(x = mpg, y = as.factor(cyl))) +
    stat_slab(aes(fill = as.factor(cyl)), alpha = 1, linetype = ""solid"", key_glyph = ""timeseries"")
```
![image](https://user-images.githubusercontent.com/6345019/164136019-5d407003-8e53-4f90-9331-fc256eb442fd.png)

I'll leave this open to see if I can find a better way to detect usage of aesthetics on sub-geometries that plays more nicely with base ggplot2 key functions.

----------------------------
Ari04T:

Alright, that makes sense. In that case, it becomes necessary to create a second geom/stat in order to play with for example the alpha value right? Something like this:
```R
mtcars %>% 
    mutate(cyl = as.factor(cyl)) %>% 
    ggplot(aes(x = mpg, y = cyl)) +
    stat_slab(aes(color = cyl, slab_fill = after_scale(alpha(color, 0.5)))) +
    stat_slab(aes(fill = cyl), alpha = 0, linetype = ""solid"", key_glyph = ""timeseries"") +
    guides(
        color = ""none"",
        fill = guide_legend(override.aes = list(alpha = 1)),
        slab_fill = ""none""
    )
```
![](https://i.imgur.com/TuBwjyS.png)

----------------------------
mjskay:

Yeah I can't think of another way to manipulate the alpha of the fill separately from the outline in this case.",TRUE,"help,enhancement",2022-04-20 02:15:42,NA,,,OPEN,2022-04-20 03:47:30,NA,,I_kwDOEBBtO85IEQvY
133,https://github.com/mjskay/ggdist/issues/133,https://github.com/mjskay/ggdist/issues/133,Bisaloo,Should level layers be interwoven between groups?,"```r
library(ggdist)
library(tidyverse)

set.seed(1234)
n = 5000

df = tibble(
  .draw = 1:n,
  intercept = rnorm(n, 3, 1),
  slope = rnorm(n, 1, 0.25),
  x = list(-4:5),
  y = map2(intercept, slope, ~ .x + .y * -4:5)
) %>%
  unnest(c(x, y))

df_3groups = rbind(
  mutate(df, g = ""a""),
  mutate(df, g = ""b"", y = (y - 2) * 0.5),
  mutate(df, g = ""c"", y = (-y + 3) * runif(n)) 
)

df_3groups %>%
  ggplot(aes(x = x, y = y, fill = g)) +
  stat_lineribbon(aes(fill_ramp = stat(level)))
```

![image](https://user-images.githubusercontent.com/10783929/162934015-d11d5ee2-68a7-415e-9f1d-2f6185eaa201.png)

The order in which layers are applied to the plot make it somewhat difficult to read IMO. 

I'm not sure I have a good alternative suggestion since it we grouped level layers by groups, it would require a way to decide which group is behind and which group is above, which might be tricky and arbitrary.

I'm opening an issue here hoping you'll have a better solution than me.",TRUE,"----------------------------
mjskay:

This is a deliberate hack so that overlapping levels are easier to read when using alpha blending. Something like this:

``` r
library(ggdist)
library(tidyverse)

set.seed(1234)
n = 5000

df = tibble(
  .draw = 1:n,
  intercept = rnorm(n, 3, 1),
  slope = rnorm(n, 1, 0.25),
  x = list(-4:5),
  y = map2(intercept, slope, ~ .x + .y * -4:5)
) %>%
  unnest(c(x, y))

df_3groups = rbind(
  mutate(df, g = ""a""),
  mutate(df, g = ""b"", y = (y - 2) * 0.5),
  mutate(df, g = ""c"", y = (-y + 3) * runif(n)) 
)

df_3groups %>%
  ggplot(aes(x = x, y = y, fill = g)) +
  stat_lineribbon(alpha = 0.25) +
  theme_ggdist()
```

![](https://i.imgur.com/JDkrpPN.png)

<sup>Created on 2022-04-12 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>

With full opacity this style of chart is not really readable if there is any overlap, so for that use case I don't think it really matters what order they are drawn in (since it's just not a workable idea anyway). Hence, the current solution.

In the future (after R 4.2 comes out, with support for blend modes), the other solution to this will be to use multiply blending, which is independent of the draw order of layers. There is an implementation of this on the experimental ggdist branch called ""blend"", but I still haven't nailed down the API so I don't recommend using it for real code just yet. You can see some examples of what you will be able to do when the next version of ggdist comes out post-R 4.2 [here](https://twitter.com/mjskay/status/1490055889050607629?s=20&t=445UiE1-bWxkhYQAmqSkPQ).
",TRUE,"help,enhancement",2022-04-12 09:59:07,2022-04-12 16:00:11,,,CLOSED,2022-04-12 16:00:11,NA,,I_kwDOEBBtO85HnqVV
132,https://github.com/mjskay/ggdist/issues/132,https://github.com/mjskay/ggdist/issues/132,Ari04T,Arrange dots when group is NA,"Hello!

I'm having a bit of an issue here. I want to do a plot such as the one shown below, but I want the colors to be organized—meaning all the green dots should be at the bottom and all the orange ones should be at the top.

![plot](https://mjskay.github.io/ggdist/articles/dotsinterval_files/figure-html/beeswarm_shape_color_together-1.png)

I've tried to do this by setting the color/fill as an ordered factor, but the dots still seem to show up in random fashion. Is there a way to order the color of the dots?

Thanks!",TRUE,"----------------------------
mjskay:

Good question! In the released version, the dots are ordered by the data values (e.g. by the y values above), hence the seemingly-random order.

Being able to order them to create a ""stacking"" effect is a good idea. I just created a modification that supports this by mapping a variable onto an optional `order` aesthetic, which will determine the order of the dots within each bin. You can try it by installing the development version (`remotes::install_github(""mjskay/ggdist"")`). It looks like this:

```r
abcc_df %>%
  ggplot(aes(y = value, x = abc, shape = abc, color = hi, group = NA, order = hi)) +
  geom_dots() +
  scale_color_brewer(palette = ""Dark2"")
```
![image](https://user-images.githubusercontent.com/6345019/162359460-5507dbd3-efe3-41cd-b3c1-4a1eae4a2788.png)

Does that help?

----------------------------
Ari04T:

Awesome, exactly what I was looking for. Thanks man.

----------------------------
mjskay:

No problem! ",TRUE,enhancement,2022-04-06 09:37:36,2022-04-08 04:05:15,,,CLOSED,2022-04-08 14:20:02,NA,,I_kwDOEBBtO85HMENl
131,https://github.com/mjskay/ggdist/issues/131,https://github.com/mjskay/ggdist/issues/131,zacksteel,stat_lineribbon missing parameters?,"Thanks for the great package(s)

I'd like adjust individual line or ribbon aesthetics for the line or ribbon components of this function similar to what is possible with e.g., geom_pointinterval (e.g., interval_alpha & point_alpha). Something like this:

m_mpg = brm(
  mpg ~ hp * cyl, 
  data = mtcars, 
  
  file = ""models/tidy-brms_m_mpg.rds""  # cache model (can be removed)
)

mtcars %>%
  group_by(cyl) %>%
  data_grid(hp = seq_range(hp, n = 51)) %>%
  add_epred_draws(m_mpg) %>%
  ggplot(aes(x = hp, y = mpg, color = ordered(cyl))) +
  stat_lineribbon(aes(y = .epred), ribbon_alpha = 0.5) + ## note change from tutorial here
  geom_point(data = mtcars) +
  scale_fill_brewer(palette = ""Greys"") +
  scale_color_brewer(palette = ""Set2"")

But this gives a warning
Warning message:
Ignoring unknown parameters: ribbon_alpha 

Is it possible to add this flexibility or am I just mis-specifying the function?

Thanks,
Zack",TRUE,"----------------------------
mjskay:

Yeah --- currently lineribbon does not have sub-geometry-specific aesthetics like slabinterval does, though it is on my todo list. See #40 and some workarounds discussed there.

----------------------------
zacksteel:

ok thanks for pointing me toward the workarounds and thanks again for the great package",TRUE,"help,enhancement",2022-03-24 19:04:04,2022-03-25 04:37:28,duplicate,,CLOSED,2022-03-25 15:53:03,NA,,I_kwDOEBBtO85GVEQM
129,https://github.com/mjskay/ggdist/issues/129,https://github.com/mjskay/ggdist/issues/129,teunbrand,Zeroes and `NA`s in the `thickness` aesthetic,"Hi Matthew,

This is a follow-up of [this SO question](https://stackoverflow.com/q/71421713/11374827), wherein was discussed if 0-thickness points could be dropped even when `expand = TRUE`. You mentioned that there might be a better way to handle `NA`s, which I didn't understand completely. I think the `NA`-hacking to omit datapoints  from plotting, as shown in the question, can be circumvented.

This is just an idea, but if the `expand` argument could take a `logical(2)` for the lower and upper limits respectively, that would be sufficient for the purposes of the SO question. I'm not terribly familiar with {ggdist}'s  source code, but I think the relevant bits live in this logic block: https://github.com/mjskay/ggdist/blob/01ab170e07a5fd015774bbc078bae12deb4bec9e/R/stat_slabinterval.R#L229

If you agree with the above and are open to it, I could try to prepare a PR for you to review.

Best,
Teun",TRUE,"----------------------------
mjskay:

Oh, I like that idea! A PR would be very welcome.

I think I'll still need to fix some `NA` handling for other puposes, but I'll deal with that in a different issue. 

----------------------------
mjskay:

FYI, I fixed the problems with `NA` handling in `thickness` that this issue exposed, because they should be fixed regardless of whether there are any changes to `expand`. So if you use the latest version from github (`devtools::install_github(""mjskay/ggdist"")`) you can now employ the solution you attempted on stackoverflow:

```r
set.seed(1234)

df <- data.frame(
    x = rep(c(""A"", ""B""), each = 10),
    y = c(rnorm(20, mean = rep(c(5, 7), each = 10)))
)

ggplot(df, aes(x, y)) +
  stat_ccdfinterval(
    geom = ""slab"", 
    # use lag(f) == 0 instead of f == 0 if you want the
    # outline to go down to all the way to the right
    aes(thickness = after_stat(ifelse(f == 0, NA, f))),
    color = ""black"",
    size = 1
  ) +
  lims(y = c(0, NA))
```
![image](https://user-images.githubusercontent.com/6345019/158102978-1c280729-d4a5-48b9-82e8-d2170a5069dd.png)

Still happy to accept a PR to change `expand` if you'd like to do that.",TRUE,bug,2022-03-13 12:03:47,2022-03-15 19:43:49,,,CLOSED,2022-03-15 19:43:49,NA,,I_kwDOEBBtO85Fl5E2
128,https://github.com/mjskay/ggdist/issues/128,https://github.com/mjskay/ggdist/issues/128,dmphillippo,Plot stats no longer work without loading the package,"Prior to the 3.1.0 release, you could call a ggdist stat without loading the package, e.g.
```r
library(ggplot2)
ggplot(data.frame(x = rnorm(1000), y = ""Test""), aes(x = x, y = y)) + ggdist::stat_halfeye()
```

However, as of 3.1.0 the above now fails with the following warning:
```r
> Warning message:
> Computation failed in `stat_slabinterval()`:
> object 'median_qi' of mode 'function' was not found 
```

I think this is due to a change in the default value for the `point_interval` argument. Previously this was `median_qi`, which got picked up from the package namespace correctly; now this is `""median_qi""`, and the corresponding function then does not get found unless the package is loaded.

The only way to get the above to work without loading the package is
```r
ggplot(data.frame(x = rnorm(1000), y = ""Test""), aes(x = x, y = y)) + ggdist::stat_halfeye(point_interval = ggdist::median_qi)
```

Some wider context: this seems to break packages which rely on ggdist and have ggdist in Imports but not Depends (since the package is not loaded), and construct plots with `ggdist::stat_*`.

Huge thanks for all your work on ggdist, it is really excellent!",TRUE,"----------------------------
mjskay:

Ah shoot, yeah that is problematic. Need to reconstruct why I made that change; there is probably a better solution.

----------------------------
mjskay:

Yeah, this is related to the new codegen stuff. I should be able to put together a fix it just might be a little hairy.

----------------------------
mjskay:

Can you test it on master (`remotes::install_github(""mjskay/ggdist"")`) and see if it is fixed for you now? Thanks!

----------------------------
dmphillippo:

Looks good to me! Working both with the simple reprex above and within a package that relies on ggdist.

This actually works even better than before now. Previously you could only leave `point_inteval` at its default value without loading ggdist (or passing something like `ggdist::mean_qi`), but now using a string argument to `point_interval` works all the time (ggdist loaded or not).

Thanks!

----------------------------
mjskay:

Oh yeah, that's great! Well there's a test for that now so that behavior should be permanent ;)

Thanks again!

----------------------------
mjskay:

FYI: this fix is now on cran

----------------------------
dmphillippo:

Brilliant, thanks so much!",TRUE,bug,2022-02-23 16:20:50,2022-02-24 16:53:19,,,CLOSED,2022-02-28 08:35:03,NA,,I_kwDOEBBtO85EcbPn
127,https://github.com/mjskay/ggdist/issues/127,https://github.com/mjskay/ggdist/issues/127,Bisaloo,Allow missing `y` aesthetic in `geom_lineribbon()`,"There are cases where the input data is missing a central tendency (be it mean, median, etc.).

Yet, `geom_lineribbon()` makes the `y` mandatory and if it's filled with `NA` values, the entire row is dropped and no ribbon is displayed.

It would be good in these cases if ribbons could be displayed without the line. `geom_ribbon()` doesn't work well either in these cases because:

1. I want to use this inside a function and there will be case when the central tendency is present and cases when it's absent
2. Even when the central tendency is missing, there might be multiple quantiles and thus a need for multiple overlapped ribbons.

Opened as part of https://github.com/epiforecasts/scoringutils/issues/174.",TRUE,"----------------------------
mjskay:

Hmmm makes sense, seems a good use case to support.

In the short term, a workaround that works with the CRAN version of {ggdist} is to set `y` to a constant non-`NA` value but suppress the line by setting `color` or `size` to `NA`. Something like:

```r
data.frame(x = 1:10, y = 1:10) %>%
  ggplot(aes(x = x, ymin = y - 1, ymax = y + 1)) +
  geom_lineribbon(y = 0, color = NA)
```
![image](https://user-images.githubusercontent.com/6345019/152282585-8c124234-dfd4-492e-8dde-f9bf6a73511b.png)

A better long-term solution I can see is that if I make the off-axis positional aesthetic non-required `geom_lineribbon()` will work as-is and the line won't be drawn if you omit the `y` mapping. If you install the `dev` branch (`devtools::install_github(""mjskay/ggdist@dev"")`) I just implemented that solution; in which case something like this should work:

```r
data.frame(x = 1:10, y = 1:10) %>%
    ggplot(aes(x = x, ymin = y - 1, ymax = y + 1)) +
    geom_lineribbon()
```
![image](https://user-images.githubusercontent.com/6345019/152282585-8c124234-dfd4-492e-8dde-f9bf6a73511b.png)

Let me know if that works for what you need. Hopefully this version should be on CRAN soon since I am in the midst of preparing a release anyway.

----------------------------
Bisaloo:

Thanks for your quick answer and changes. This is very helpful!",TRUE,bug,2022-02-02 16:01:15,2022-02-03 05:40:29,,,CLOSED,2022-02-03 17:21:36,NA,,I_kwDOEBBtO85C4f4S
126,https://github.com/mjskay/ggdist/issues/126,https://github.com/mjskay/ggdist/issues/126,mjskay,Store docstrings for aes and params in geoms,"Rather than having separate functions for docgen for slabinterval, lineribbon, etc, store the docstrings in the class defs so we can selectively override docstrings in subclasses more easily and simplify the docgen logic. ",TRUE,,FALSE,refactor,2022-01-21 10:12:31,2023-01-09 04:28:37,,,CLOSED,2023-01-09 04:28:37,Next next release,,I_kwDOEBBtO85CLa33
125,https://github.com/mjskay/ggdist/issues/125,https://github.com/mjskay/ggdist/issues/125,arthur-albuquerque,"fill_type = ""gradient"" in stat_halfeye()","Hi Matthew, 

Inspired by your vignette [""Highlighting and other combinations""](https://mjskay.github.io/ggdist/articles/slabinterval.html), I was trying to apply the argument fill_type = ""gradient"" to ggdist::stat_halfeye(). 

While your vignette works on my PC, the stat_halfeye() ignores the fill_type argument (not sure if the reprex below will be able to show the proper output).

Am I doing something wrong or the fill_type argument simply doesn't work with stat_halfeye()? If so, would it be possible to add this functionality?

Thanks!

``` r
library(ggdist)
library(tidyverse)

priors = tribble(
  ~ dist,      ~ args,
  ""norm"",      list(0, 1),
  ""student_t"", list(3, 0, 1)
) 

# Works
priors %>%
  ggplot(aes(y = dist, dist = dist, args = args)) +
  stat_dist_eye(aes(slab_alpha = stat(f), fill = stat(x > 1)), fill_type = ""gradient"") +
  scale_fill_manual(values = c(""gray75"", ""skyblue"")) +
  theme_ggdist()
```

![](https://i.imgur.com/wSAeUgL.png)

``` r
# Doesn't work
tibble(x = rnorm(10e4, 0, 1)) |> 
  ggplot(aes(x,  fill = stat(x > 0))) +
  stat_halfeye(fill_type = ""gradient"") +
  scale_fill_manual(values = c(""gray75"", ""skyblue"")) +
  theme_ggdist()
```

![](https://i.imgur.com/Cj4Fr5z.png)

``` r
sessionInfo()
#> R version 4.1.2 (2021-11-01)
#> Platform: x86_64-apple-darwin17.0 (64-bit)
#> Running under: macOS Catalina 10.15.7
#> 
#> Matrix products: default
#> BLAS:   /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib
#> LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib
#> 
#> locale:
#> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
#> 
#> attached base packages:
#> [1] stats     graphics  grDevices utils     datasets  methods   base     
#> 
#> other attached packages:
#>  [1] forcats_0.5.1   stringr_1.4.0   dplyr_1.0.7     purrr_0.3.4    
#>  [5] readr_2.1.0     tidyr_1.1.4     tibble_3.1.6    ggplot2_3.3.5  
#>  [9] tidyverse_1.3.1 ggdist_3.0.0   
#> 
#> loaded via a namespace (and not attached):
#>  [1] Rcpp_1.0.8           lubridate_1.8.0      assertthat_0.2.1    
#>  [4] digest_0.6.29        utf8_1.2.2           R6_2.5.1            
#>  [7] cellranger_1.1.0     backports_1.4.1      reprex_2.0.1        
#> [10] evaluate_0.14        httr_1.4.2           highr_0.9           
#> [13] pillar_1.6.4         rlang_0.4.12         readxl_1.3.1        
#> [16] rstudioapi_0.13      rmarkdown_2.11       labeling_0.4.2      
#> [19] munsell_0.5.0        broom_0.7.10         compiler_4.1.2      
#> [22] modelr_0.1.8         xfun_0.28            pkgconfig_2.0.3     
#> [25] htmltools_0.5.2      tidyselect_1.1.1     fansi_0.5.0         
#> [28] crayon_1.4.2         tzdb_0.2.0           dbplyr_2.1.1        
#> [31] withr_2.4.3          grid_4.1.2           distributional_0.2.2
#> [34] jsonlite_1.7.2       gtable_0.3.0         lifecycle_1.0.1     
#> [37] DBI_1.1.1            magrittr_2.0.1       scales_1.1.1        
#> [40] cli_3.1.0            stringi_1.7.5        farver_2.1.0        
#> [43] fs_1.5.0             xml2_1.3.2           ellipsis_0.3.2      
#> [46] generics_0.1.1       vctrs_0.3.8          tools_4.1.2         
#> [49] glue_1.6.0           hms_1.1.1            fastmap_1.1.0       
#> [52] yaml_2.2.1           colorspace_2.0-2     rvest_1.0.2         
#> [55] knitr_1.36           haven_2.4.3
```

<sup>Created on 2022-01-16 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>",TRUE,"----------------------------
arthur-albuquerque:

Oh well, that was quick. I managed to do it with stat_halfeye:

```
tibble(x = rnorm(10e4, 0, 1)) |> 
  ggplot(aes(x,  fill = stat(x > 0),
             slab_alpha = stat(x))) +
  stat_halfeye(fill_type = ""gradient"") +
  scale_fill_manual(values = c(""gray75"", ""skyblue"")) +
  theme_ggdist()
```",TRUE,help,2022-01-16 15:39:47,2022-01-16 15:46:42,,,CLOSED,2022-01-16 15:46:42,NA,,I_kwDOEBBtO85B3kGw
124,https://github.com/mjskay/ggdist/issues/124,https://github.com/mjskay/ggdist/issues/124,mjskay,Create a stat_spike that mimics the thickness calculations of slabinterval,"Basically, something that mimics the scaling and whatnot of slabinterval but calculates slab functions conditional on a provided x value. Could be useful for custom annotations with existing geoms.

(this might or might not work - compatibility with positions may be dubious for example; the alternative might be to create some geoms specifically for this like the other issue about making a geom_spike) ",TRUE,"----------------------------
mjskay:

this definitely goes along with #58 

----------------------------
mjskay:

e.g. a `stat_spike()` companion to `geom_spike()` with an `at` param (or maybe `at` aesthetic?) that can either be a function or a vector (or maybe a list of functions or vectors in the aesthetic case) giving the positions to evaluate the slab function at",TRUE,enhancement,2022-01-15 09:07:14,2023-01-28 20:04:40,,,CLOSED,2023-01-28 20:04:40,NA,,I_kwDOEBBtO85B15h4
123,https://github.com/mjskay/ggdist/issues/123,https://github.com/mjskay/ggdist/issues/123,mjskay,Make separate docs for the dotsinterval stats/geoms,"split them into 4 and give them custom aesthetic override docs, as for lineribbon",TRUE,,FALSE,docs,2022-01-15 06:47:37,2023-01-08 23:18:35,documentation,,CLOSED,2023-01-08 23:18:35,Next next release,,I_kwDOEBBtO85B1hxc
122,https://github.com/mjskay/ggdist/issues/122,https://github.com/mjskay/ggdist/issues/122,SchmidtPaul,Dot plot with `aes(color = )` and `position_dodge()`?,"Hi and thanks for the great package!
I took inspiration from [this blogpost](https://solomonkurz.netlify.app/post/2021-09-22-sexy-up-your-logistic-regression-model-with-logit-dotplots/#:~:text=stat_dots(data%20%3D%20bechdel%20%25%3E%25%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20mutate(binary%20%3D%20factor(binary%2C%20levels%20%3D%20c(%22PASS%22%2C%20%22FAIL%22)))%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20aes(y%20%3D%20pass%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20side%20%3D%20ifelse(pass%20%3D%3D%200%2C%20%22top%22%2C%20%22bottom%22)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20color%20%3D%20binary)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20scale%20%3D%200.4%2C%20shape%20%3D%2019)) and was able to create a similar plot:

``` r
library(ggdist)
library(tidyverse)

dat <- tibble::tribble(
  ~pass, ~year, ~grp,
     1L, 2020L,    ""A"",
     1L, 2021L,    ""A"",
     1L, 2022L,    ""A"",
     0L, 2020L,    ""A"",
     1L, 2021L,    ""A"",
     0L, 2022L,    ""A"",
     0L, 2020L,    ""B"",
     0L, 2021L,    ""B"",
     0L, 2022L,    ""B"",
     0L, 2020L,    ""B"",
     0L, 2021L,    ""B"",
     1L, 2022L,    ""B""
  ) %>% 
  mutate_if(is.character, as.factor)

ggplot() +
  stat_dots(
    data = dat,
    aes(
      x = year,
      y = pass,
      side = ifelse(pass == 0, ""top"", ""bottom"")
    ),
    position = ""identity"",
    orientation = ""horizontal"",
    shape = 19,
    scale = 0.1
  )
```

![](https://i.imgur.com/vlUQRPP.png)

<sup>Created on 2022-01-12 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>

However, I then tried adding `color = grp` and get an unexpected outcome: some dots are missing. 

``` r
ggplot() +
  geom_dots(
    data = dat,
    aes(
      x = year,
      y = pass,
      side = ifelse(pass == 0, ""top"", ""bottom""),
      color = grp
    ),
    position = ""identity"", # dodge?!
    orientation = ""horizontal"",
    shape = 19,
    scale = 0.1
  )
```

![](https://i.imgur.com/ebcw1R3.png)

<sup>Created on 2022-01-12 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>

Also, even if it did show all dots, I thought about using something like `position = ""dodge""` in order to get the dots per year and side arranged like shown below. Is this possible?
![image](https://user-images.githubusercontent.com/31928213/149138437-dc5aadb4-3859-469d-9c92-6d0f6422cba7.png)",TRUE,"----------------------------
mjskay:

Good questions.

Re: dots disappearing: they are drawn, but overlapping. If you add alpha values (and a mapping onto shape) you can see how they overlap more easily:

```r
ggplot() +
  geom_dots(
    data = dat,
    aes(
      x = year,
      y = pass,
      side = ifelse(pass == 0, ""top"", ""bottom""),
      color = grp,
      shape = grp
    ),
    position = ""identity"", # dodge?!
    orientation = ""horizontal"",
    # shape = 19,
    scale = 0.1,
    alpha = 0.5
  )
```
![image](https://user-images.githubusercontent.com/6345019/149206063-0f2cb7c6-2213-4bf5-a130-926e2ec1c582.png)

If you set `group` to `NA` they will be stacked together instead (this overrides the fact that setting `color` to a discrete variable automatically sets `group` to group by that variable as well):

```r
ggplot() +
  geom_dots(
    data = dat,
    aes(
      x = year,
      y = pass,
      side = ifelse(pass == 0, ""top"", ""bottom""),
      color = grp,
      group = NA
    ),
    position = ""identity"", # dodge?!
    orientation = ""horizontal"",
    shape = 19,
    scale = 0.1
  )
```
![image](https://user-images.githubusercontent.com/6345019/149206251-2e6f253b-7120-4076-a2b3-ca3a7fbb0349.png)


This doesn't quite do what you're looking for though with your second question. Unfortunately `position = ""dodge""` won't either, as it is designed for dodging perpendicular to the orientation of the geometry rather than applying as offset along the same axis.

In your case, with discrete data, you could hack together a rough version of what you want by manually adding values to the x variable conditional on the group. This will be brittle in that it will be sensitive to the size and aspect ratio of the chart (which influences the algorithm that determines the size of the dots), but if you have fixed data and chart parameters it shouldn't be too hard to pick a reasonable offset. For example, something like this:

```r
ggplot() +
  geom_dots(
    data = dat,
    aes(
      x = year + 0.1 * (grp == ""A""),
      y = pass,
      side = ifelse(pass == 0, ""top"", ""bottom""),
      color = grp
    ),
    position = ""identity"", # dodge?!
    orientation = ""horizontal"",
    shape = 19,
    scale = 0.1
  )
```
![image](https://user-images.githubusercontent.com/6345019/149206767-1551a53a-433a-4ba7-82e7-0f53d1b91e07.png)

Sadly not as elegant as I'd like, but hopefully gets the job done?





----------------------------
SchmidtPaul:

Good enough, thanks a lot!",TRUE,help,2022-01-12 12:19:40,2022-01-13 09:02:12,,,CLOSED,2022-01-13 09:02:12,NA,,I_kwDOEBBtO85BlN7B
121,https://github.com/mjskay/ggdist/issues/121,https://github.com/mjskay/ggdist/issues/121,mjskay,Get coverage to 100%,"Should be possible after:

- [x] #116
- [ ] #87 ",TRUE,,FALSE,cleanup,2021-12-29 23:13:35,2022-01-14 02:19:54,,,CLOSED,2022-01-14 02:19:54,NA,,I_kwDOEBBtO85BBCQp
120,https://github.com/mjskay/ggdist/issues/120,https://github.com/mjskay/ggdist/issues/120,mjskay,Make a vignette for dotsinterval,"It really is a whole subfamily of slabinterval unto itself, so it's worth expanding out the docs on it (then we can also include more recent / complex examples of dotplots, such as those from [this blog post](https://blog.mjskay.com/2021/07/15/tidybayes-ggdist-3-0/))",TRUE,,FALSE,docs,2021-12-15 19:38:33,2022-01-15 22:37:49,documentation,,CLOSED,2022-01-15 22:37:49,Next release ,,I_kwDOEBBtO85AdXq8
119,https://github.com/mjskay/ggdist/issues/119,https://github.com/mjskay/ggdist/issues/119,mjskay,Use new @examplesIf tag in roxygen examples,"For conditional examples (e.g. ones depending on suggested packages), switch to using `@examplesIf`",TRUE,,FALSE,cleanup,2021-12-15 02:21:25,2021-12-30 23:38:20,documentation,,CLOSED,2021-12-30 23:38:20,NA,,I_kwDOEBBtO85AZvQl
118,https://github.com/mjskay/ggdist/issues/118,https://github.com/mjskay/ggdist/issues/118,mjskay,Easier control over histogram binning,"Pulling this out as its own issue (original comment from @steveharoz below)

It would be nice to be able to do things like specify things like `center`, `binwidth`, etc (similar to things that `geom_histogram()` supports) instead of `breaks`. Whatever is chosen here should match up with parameters used for #101. Probably this will happen after #113, since that will introduce a mechanism for custom density estimators that would include histograms and allow an expanded set of parameters for those things.

---

Here's a related quirk and feature request:
It'd be great to be able to specify the bin width (not the breaks) for all of the histograms, so it's visually consistent. It would somewhat solve the above problem too.

```
set.seed(1234)
tribble(
  ~group, ~value,
  ""b"",    rnorm(1000, mean = 6, sd = 3),
  ""c"",    rnorm(1000, mean = 8, sd = 2),
  ""d"",    rnorm(1000, mean = 10),
) %>%
  unnest(value)  %>%
  ggplot() +
  aes(y = group, x = value) +
  stat_histinterval(slab_type = ""histogram"") +
  theme_ggdist()
```

![image](https://user-images.githubusercontent.com/2257540/98964433-14460a80-2509-11eb-951d-efd362424ed0.png)
 
It'd be nice if there were a parameter to specify fixed bin sizes for all histograms. Like `bindwidth = 0.5, binstart=-0.25`. And then all bins would be [ -0.25 + 0.5n, -0.25 + 0.5(n+1) )

_Originally posted by @steveharoz in https://github.com/mjskay/ggdist/issues/32#issuecomment-726175101_",FALSE,,TRUE,enhancement,2021-12-06 01:38:01,NA,,,OPEN,2022-02-04 04:29:38,Next next release,,I_kwDOEBBtO84_399e
117,https://github.com/mjskay/ggdist/issues/117,https://github.com/mjskay/ggdist/issues/117,mjskay,automatic fallback when no lineargradient support in R >= 4.2,"in R >= 4.2 we will be able to test for linearGradient support using something like `""LinearGradient"" %in% dev.capabilities()$patterns`. This means we can:

- [ ] change the default of `fill_type` to be `""gradient""` for `stat_gradientinterval` (conditional on R being >= 4.2)
- [ ] when `fill_type == ""gradient""`, fall back to `fill_type = ""segments""` automatically when R >= 4.2 and linearGradients are not supported by the current graphics device (possibly with a warning?). That, or make a new option for `fill_type` that selects ""segments"" on R < 4.2 and selects `""gradient""` on R >= 4.2. if gradients are supported (but `""segments""` otherwise).",TRUE,,FALSE,cleanup,2021-12-02 06:17:53,2022-01-16 18:05:25,,,CLOSED,2022-01-16 18:05:25,Next release ,,I_kwDOEBBtO84_ukZ_
116,https://github.com/mjskay/ggdist/issues/116,https://github.com/mjskay/ggdist/issues/116,mjskay,clean out compatibility code for distributional < 0.2.2.9000,"Once the new version of distributional hits CRAN, add a dependency on it and clean out the codepaths that are only needed for compatibility with the old version.",TRUE,,FALSE,cleanup,2021-11-30 04:54:57,2022-01-12 18:32:57,,,CLOSED,2022-01-12 18:32:57,Next release ,,I_kwDOEBBtO84_lfBu
115,https://github.com/mjskay/ggdist/issues/115,https://github.com/mjskay/ggdist/issues/115,mjskay,add examples of new trim / expand parameters,"probably to vignette, some kind of ridgeplot-ish thing",TRUE,,FALSE,docs,2021-11-25 03:27:42,2021-12-06 02:27:42,documentation,,CLOSED,2021-12-06 02:27:42,Next release ,,I_kwDOEBBtO84_Xe7H
114,https://github.com/mjskay/ggdist/issues/114,https://github.com/mjskay/ggdist/issues/114,mjskay,qi() should pass na.rm down to quantile for dist objects (when that is fixed),"When https://github.com/mitchelloharawild/distributional/issues/72 is fixed, pass na.rm down to `quantile()` for distribution objects in `qi()`

and also down to median (when distributional > 0.2.2 is released)

- [x] fix usages of `median()`
- [ ] fix usages of `quantile()` (waiting on next release of distributional after 0.3.0)",FALSE,,FALSE,cleanup,2021-11-24 03:34:51,NA,,,OPEN,2022-01-14 04:42:37,Next next release,,I_kwDOEBBtO84_TDvX
113,https://github.com/mjskay/ggdist/issues/113,https://github.com/mjskay/ggdist/issues/113,mjskay,Allow custom density estimators in slabinterval,"Basic idea would be to create a family of functions for use with stat_slabinterval in a similar style to the approach used for stats/geoms/positions in ggplot for handling different types of density estimators. E.g. things like `density = ""kde""` or `density = ""histogram""` or `density = ""bounded""` or `density = density_bounded(some_options =...)`.

This would replace the current `slab_type = ""pdf""` / `slab_type = ""histogram""` sometime after #83 is done.

- [x] allow custom density estimators with `density = `
- ~~[ ] -> replace `slab_type = ""histogram""` with `density = ""histogram""`~~ #165",TRUE,"----------------------------
tomicapretto:

I've uploaded code about KDEs and bandwidth estimators to this gist https://gist.github.com/tomicapretto/74f90f3ad026f397fa11f2797eb7a954. Let me know if anything there looks helpful.

Happy to help you if there's something you want to adapt, or if you have any questions, or whatever that can help with this issue.",FALSE,enhancement,2021-11-23 05:11:31,2022-12-27 02:48:41,,,CLOSED,2022-12-27 02:48:41,NA,,I_kwDOEBBtO84_OzqT
112,https://github.com/mjskay/ggdist/issues/112,https://github.com/mjskay/ggdist/issues/112,mjskay,"in dist aesthetics, replace all numerics, rvars, and strings on the way in with dists",This will probably be post the next version of `distributional`,TRUE,,FALSE,refactor,2021-11-23 02:59:59,2022-07-19 17:05:10,,,CLOSED,2022-07-19 17:05:11,Next next release,,I_kwDOEBBtO84_OlTJ
111,https://github.com/mjskay/ggdist/issues/111,https://github.com/mjskay/ggdist/issues/111,mjskay,Support multidimensional dists / rvars in point_interval,"Pinging off of https://github.com/mjskay/ggdist/issues/14#issuecomment-973729841

Probably add a column for the index",FALSE,"----------------------------
mitchelloharawild:

I've pushed an update to `{fabletools}` onto CRAN yesterday which prepares for the next release of `{distributional}`. It doesn't use `{ggdist}` for the graphics yet as the existing functionality being replaced supports multivariate distributions. If you'd like to push `{ggdist}` to CRAN soon, then I can send `{distributional}` to CRAN.

I think this is the last issue preventing `{fabletools}` from using `{ggdist}`, and removing the `{ggplot2}` import from `{distributional}`. If it could be included in the next release that would allow me to swap over to `{ggdist}` sooner, but if not I still think releasing the updates to `{ggdist}` and `{distributional}` is worthwhile now.

----------------------------
mjskay:

Cool sounds good, I'll push a minor release of {ggdist} soon to ensure forward compatibility with {distributional} and then prioritize this issue in the next major release.

----------------------------
mjskay:

@mitchelloharawild ggdist 3.0.1, which *should* be forward-compatible with the new {distributional}, is on its way to cran. Please let me know if you run into any issues with it and I will push a new version.

----------------------------
mjskay:

@mitchelloharawild I'm working through some last issues in prep for a new release and I want to make sure I hit the couple of things you need, including this one. Is there anything else not on [this milestone](https://github.com/mjskay/ggdist/milestone/4) that would be helpful?

----------------------------
mjskay:

@mitchelloharawild a potential solution to this is now on master: the `point_interval()` family of functions will now produce a `.index` column for multivariate distribution objects and rvars. Example:

``` r
library(ggplot2)
library(dplyr)
library(distributional)
library(ggdist)

tibble(
  x = c(
    dist_multivariate_normal(list(c(1:4)), list(diag(4))),
    dist_normal()
  ),
  y = c(""a"",""b"")
) %>%
  median_qi(x, .width = c(.66, .95))
#> # A tibble: 10 x 8
#>        x y     .index  .lower .upper .width .point .interval
#>    <dbl> <chr>  <int>   <dbl>  <dbl>  <dbl> <chr>  <chr>    
#>  1     1 a          1  0.0458  1.95    0.66 median qi       
#>  2     2 a          2  1.05    2.95    0.66 median qi       
#>  3     3 a          3  2.05    3.95    0.66 median qi       
#>  4     4 a          4  3.05    4.95    0.66 median qi       
#>  5     0 b         NA -0.954   0.954   0.66 median qi       
#>  6     1 a          1 -0.960   2.96    0.95 median qi       
#>  7     2 a          2  0.0400  3.96    0.95 median qi       
#>  8     3 a          3  1.04    4.96    0.95 median qi       
#>  9     4 a          4  2.04    5.96    0.95 median qi       
#> 10     0 b         NA -1.96    1.96    0.95 median qi
```

<sup>Created on 2022-01-16 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>

This can be used with (e.g.) `geom_pointinterval()` by mapping `.index` to something:

``` r
tibble(
  x = dist_multivariate_normal(list(c(1:4)), list(diag(4))),
  y = c(""a"",""b"")
) %>%
  median_qi(x, .width = c(.66, .95)) %>%
  ggplot(aes(x, xmin = .lower, xmax = .upper, y = .index)) +
  geom_pointinterval()
```

![](https://i.imgur.com/kFUZWRE.png)

<sup>Created on 2022-01-16 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>

Or since `stat_pointinterval()` uses the `point_interval()` functions internally, it also generates an `.index` column that can be mapped after stats are calculated:

``` r
tibble(
  x = c(
    dist_multivariate_normal(list(c(1:4)), list(diag(4))),
    dist_normal()
  ),
  y = c(""a"",""b"")
) %>%
  ggplot(aes(xdist = x, y = y, group = stat(.index))) +
  stat_pointinterval(position = ""dodge"")
```

![](https://i.imgur.com/FqNcZEU.png)

<sup>Created on 2022-01-16 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>

**Some limitations**: 
- currently this only works with intervals; it can't calculate CDFs or densities from multivariate distributions. That is enough that stat/geom_lineribbon, stat/geom_pointinterval, and stat/geom_interval should work at least.
- only quantile intervals currently work for this, not HDIs.

Let me know if this is sufficient for what you need. I think this is the last issue before I draft a new release.",TRUE,enhancement,2021-11-19 04:43:07,NA,high priority,,OPEN,2022-01-17 04:25:53,Next release ,,I_kwDOEBBtO84_Ecgz
110,https://github.com/mjskay/ggdist/issues/110,https://github.com/mjskay/ggdist/issues/110,mjskay,Support blend modes in R 4.2,"Might be worth considering support for blend modes for fills when R 4.2 hits. Lineribbons might be a good candidate for the ""multiply"" blend mode to deal with ribbons from separate groups overlapping, for example (the current hackish approach of interleaving them mostly works but not perfectly).

(slabinterval might also be useful to having multiply blending for making stacked cumulative bar charts...)

See https://www.stat.auckland.ac.nz/~paul/Reports/GraphicsEngine/groups/groups.html",TRUE,"----------------------------
mjskay:

I think I've decided {ggblend} is the right way to do this, closing this.",FALSE,enhancement,2021-11-19 04:16:18,2022-07-21 02:02:12,,,CLOSED,2022-07-21 02:02:12,NA,,I_kwDOEBBtO84_EYcZ
109,https://github.com/mjskay/ggdist/issues/109,https://github.com/mjskay/ggdist/issues/109,mjskay,Geom/stat for uncertainty in stacked / cumulative proportions,"Maybe something for bars and/or areas. See this twitter thread w/ @ASKurz @bwiernik on bars and things: https://twitter.com/SolomonKurz/status/1372632774285348864?s=20 ... which might be doable using a stat combined with geom_slabinterval.

And this from @tjmahr on areas: https://twitter.com/tjmahr/status/1456278108311625728?s=20 ... which is more difficult. The ideal version might be a gradient approach, maybe something backed by geom_raster. That or think if there's a lineribbon generalization for this... (maybe the trick is an analog to median_qi for cumulative probabilities with one-sided intervals?)",FALSE,"----------------------------
mjskay:

Okay I hacked something together for the continuous case based on the example in the tidy-brms vignette:

```r
probs = ppoints(21)

mtcars_clean %>%
  data_grid(mpg = seq_range(mpg, n = 150)) %>%
  add_epred_draws(m_cyl, value = ""P(cyl == c | mpg)"", category = ""cyl"") %>%
  arrange(cyl) %>%
  group_by(.draw, .row, mpg) %>%
  mutate(
    `P(cyl <= c | mpg)` = cumsum(`P(cyl == c | mpg)`),
    `P(cyl < c | mpg)` = `P(cyl <= c | mpg)` - `P(cyl == c | mpg)`
  ) %>%
  group_by(cyl, mpg, .row) %>%
  summarise(
    across(c(`P(cyl <= c | mpg)`, `P(cyl < c | mpg)`), quantile, probs = probs),
    .prob = probs,
    .groups = ""drop_last""
  ) %>%
  ggplot(aes(x = mpg, ymin = `P(cyl < c | mpg)`, ymax = `P(cyl <= c | mpg)`)) +
  geom_lineribbon(aes(fill = cyl, group = interaction(.prob, cyl), y= 0), alpha = .1, color = NA) +
  # using ribbon instead of lineribbon will ""work"" (in the sense a plot is drawn)
  # but because of the draw order of the ribbons is biased towards higher values of
  # cyl so the gradients don't appear centered on the median; geom_lineribbon
  # addresses this by interleaving the ribbons
  # geom_ribbon(aes(fill = cyl, group = interaction(.prob, cyl), y= 0), alpha = .1, color = NA) +
  geom_line(aes(group = cyl, y = `P(cyl <= c | mpg)`), data = . %>% filter(.prob == 0.5, cyl != levels(cyl)[nlevels(cyl)])) +
  scale_fill_brewer(palette = ""Set2"")
```
![image](https://user-images.githubusercontent.com/6345019/140659622-9ec04721-8857-4568-822a-5e17ceb13c39.png)

Simple next step would be to add this to that vignette. Possibly more useful would be to think about the categorical case, mock that up, then try to generalize something useful for both cases (which might be an analog to point_interval for cumulative data and/or stats to go with this).


----------------------------
ASKurz:

I wonder if this or something similar could be applied to nominal models. Consider my facetted plot at the end of [Section 22.3.3.1](https://bookdown.org/content/3686/nominal-predicted-variable.html#softmax-model.), which is based on a **brms** model for which `family = categorical(link = logit)`. For that visualization, I just used the posterior means for the background fill. It would be great if there was a principled way to insert uncertainty.

----------------------------
mjskay:

Yeah I think this could also be used for nominal models. That faceted plot (and the Twitter conversation that led to it) was part of the impetus for this issue 🙂

----------------------------
ASKurz:

Then you've got one hot vignette in the works. I'll probably end up revising some of my [Chapter 22](https://bookdown.org/content/3686/nominal-predicted-variable.html#softmax-model.) to showcase your efforts.",TRUE,enhancement,2021-11-05 05:35:51,NA,,,OPEN,2021-11-07 23:32:21,NA,,I_kwDOEBBtO84-UJKY
108,https://github.com/mjskay/ggdist/issues/108,https://github.com/mjskay/ggdist/issues/108,mjskay,ensure ggdist works with non-numeric distributions,"e.g. dist_bernoulli (logical), dist_categorical, rvar_factor

Probably going to have to internally apply the x scale for the variable and require that it matches up, since otherwise mistakes will happen when translating logical dists (where TRUE / FALSE converted via a factor become  1 / 2 instead of 0 / 1) and character / factor dists (which depend on order of levels for correctness)

- [x] on slabinterval
  - [x] `rvar(<integer>)`
  - [x] `rvar_factor`
  - [x] `rvar_ordered`
  - [x] raw factors, strings
  - [x] dist_bernoulli
  - [x] dist_categorical
  - [x] dist_sample
    - [x] integer
    - [x] character / factor / ordered (initial support but won't really work until density() works on non-integer dist_sample)
- [x] on dotsinterval
  - [x] `rvar(<integer>)`
  - [x] `rvar_factor`
  - [x] `rvar_ordered`
  - [x] raw factors, strings
  - [x] dist_bernoulli
  - [x] dist_categorical
  - [x] dist_sample
    - [x] integer
    - [x] character / factor / ordered (initial support but won't really work until quantile() works on non-integer dist_sample)
- [x] tests",TRUE,,FALSE,enhancement,2021-11-04 03:35:54,2022-12-27 02:49:10,,,CLOSED,2022-12-27 02:49:10,Next next release,,I_kwDOEBBtO84-Pzhf
107,https://github.com/mjskay/ggdist/issues/107,https://github.com/mjskay/ggdist/issues/107,mjskay,add comprehensive aesthetics docs to lineribbon,similar to the slabinterval aesthetics docs,TRUE,,FALSE,docs,2021-10-25 23:38:46,2022-01-15 19:34:45,documentation,,CLOSED,2022-01-15 19:34:45,Next release ,,I_kwDOEBBtO849uwdi
106,https://github.com/mjskay/ggdist/issues/106,https://github.com/mjskay/ggdist/issues/106,mjskay,Use code generation for stat/geom boilerplate,"Should be able to generate the `stat_XXX` and `geom_XXX` functions from corresponding `StatXxx` / `GeomXxx`.

- [x] make sure to include deprecation warnings
- [x] stats
- [x] geoms
- [x] Note to self: bquote with splice wasn't added until like R 4, gonna need to switch to expr probably for backwards compatibility",TRUE,,FALSE,refactor,2021-10-24 04:08:16,2021-12-06 00:15:25,,,CLOSED,2021-12-06 00:15:25,Next release ,,I_kwDOEBBtO849pnS8
105,https://github.com/mjskay/ggdist/issues/105,https://github.com/mjskay/ggdist/issues/105,arthur-albuquerque,How to highlight an asymmetrical interval?,"Hi Matthew, 

I was looking into [ggdist's documentation](https://mjskay.github.io/ggdist/articles/slabinterval.html), more specifically the ""Highlighting and other combinations"" topic. I want to do that, but with an asymmetrical interval, let's say between 1/1.1 and 1.1. 

Is it possible with ggdist? I couldn't find any compatible code.

Best,

Arthur",TRUE,"----------------------------
mjskay:

Hi - you can define any arbitrary logical condition to determine what is highlighted. Depending on what the rest of your code looks like something like `aes(fill = stat(1 < x & x < 1.1))` would do what you want. If that doesn't work if you give me a [reprex](https://reprex.tidyverse.org/) of what you have so far I can give more specific advice. 

----------------------------
arthur-albuquerque:

Oh, nice! Your code works perfectly.

I was trying with `fill_ramp = stat(1/1.1 > x & x < 1.1)`. Why doesn't this work, since I would like to highlight the values between 1/1.1 and 1.1? 

It looks like this instead:

``` r
library(tidyverse)
library(tidybayes)
library(rcartocolor)

set.seed(123)
N = 1000

dplyr::tibble(x1 = rnorm(N, 0, 0.3),
              x2 = rnorm(N, 0, 0.31),
              x3 = rnorm(N, 0, 0.32)) %>% 
  tidyr::pivot_longer(1:3) %>% 
      
  ggplot(aes(x = exp(value), 
             y = name,
             fill = name,
             fill_ramp = stat(1/1.1 > x & x < 1.1))) +
  tidybayes::stat_halfeye(.width = 0.95) +
  ggdist::scale_fill_ramp_discrete(from = ""gray85"", range = c(0,1)) +
  rcartocolor::scale_fill_carto_d(palette = ""SunsetDark"", direction = -1) +
  geom_vline(xintercept = c(1/1.1, 1.1), linetype = 2) +
  coord_cartesian(x = c(0.5, 2))
```

![](https://i.imgur.com/BgKADdn.png)

<sup>Created on 2021-10-21 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>

----------------------------
mjskay:

I think your first `>` should be a `<`; ie `1/1.1 < x & x < 1.1`

----------------------------
arthur-albuquerque:

Yes, it works as you suggested in your previous comment. I am questioning *why* it works haha; I want to fill values greater than 1/1.1, not lower. 

These follow-up comments are just out of curiosity, given that the original issue is solved.

Thanks!

----------------------------
mjskay:

Ah I see! 

`1/1.1 < x` is `TRUE` when `1/1.1` is less than `x`, which is equivalent to writing `x > 1/1.1`, i.e. it will be `TRUE` when x is larger than 1/1.1. If you AND that (the `&` operator) with `x < 1.1`, which will be `TRUE` when x is less than 1.1, you have a condition that is `TRUE` when x is between `1/1.1` and `1.1` and `FALSE` otherwise. 

In other words, you could write `1/1.1 < x & x < 1.1` as `x > 1/1.1 & x < 1.1`, both statements are equivalent and get you the desired outcome. I prefer the first way because it is closer to how we'd typically write such intervals in mathematical shorthand, i.e. 1/1.1 < *x* < 1.1, which is not valid R syntax.

----------------------------
arthur-albuquerque:

Thank you SO much!",TRUE,help,2021-10-21 15:39:29,2021-10-21 21:56:23,,,CLOSED,2021-10-23 10:51:44,NA,,I_kwDOEBBtO849jO1h
104,https://github.com/mjskay/ggdist/issues/104,https://github.com/mjskay/ggdist/issues/104,mjskay,Allow x and y dist mappings simultaneously,"e.g. make the internal dist-based mapping get a directional component (xdist and ydist); dist is automatically rewritten to this depending on orientation. Would make it easier to make #43. 

Currently we just re-map the directional version to `dist` on the way in inside `setup_data()` / `compute_panel()`; need to change this to map `dist` to the appropriate directional version instead and then actually use the directional version elsewhere internally.",FALSE,,FALSE,"refactor,formalism",2021-10-18 01:31:07,NA,,,OPEN,2021-12-06 01:31:21,NA,,I_kwDOEBBtO849Te0l
103,https://github.com/mjskay/ggdist/issues/103,https://github.com/mjskay/ggdist/issues/103,mjskay,Make sure constant distributions are handled reliably in stat_dist,"currently the appearance depends on whether or not the input values align exactly with the constant value for densities (seeing Inf or nothing) and for CDFs (seeing a vertical line or a slanted one).

Better approach: detect constant distributions and tailor the function input values accordingly.

- [x] also fix #32 ",TRUE,"----------------------------
mjskay:

See this example:

```r
set.seed(1243)
data.frame(x = c(1,2), y = dist_sample(list(0,0.2))) %>% 
  ggplot(aes(x, dist=y)) + 
  stat_dist_halfeye(slab_color = ""blue"", orientation = ""vertical"") + 
  ylim(0,0.2)
```",TRUE,bug,2021-10-17 04:15:03,2021-12-06 01:46:34,,,CLOSED,2021-12-06 01:46:34,NA,,I_kwDOEBBtO849SUHW
102,https://github.com/mjskay/ggdist/issues/102,https://github.com/mjskay/ggdist/issues/102,steveharoz,document workarounds to incorrect orientation detection when x and y are both numeric,"For `geom_dots()`, using a numeric value for both x and y aesthetics causes a problem. However, if one is a factor or grouping is specified, it's fine.

That's what caused this [confusing bug](https://twitter.com/sharoz/status/1440809869586567178).

The solution is probably just to issue a warning when both x and y are numeric, and say to either use grouping (`group=y`) or that one should be a factor (`y=factor(y)`).

Example code:
```r
expand.grid(
  y=1:2,
  reps=1:30
) %>% 
  mutate(x = rnorm(n())) %>% 
  ggplot() +
  aes(x=x, y=y) +   # works fine if you use y=factor(y) or group=y
  ggdist::stat_dots(boundary = 0, binwidth=0.2)
```
![image](https://user-images.githubusercontent.com/2257540/134770923-d14d70d5-d06f-4a85-a50c-77e71bfd64cd.png)
",FALSE,"----------------------------
mjskay:

This is caused by the automatic orientation detection defaulting to a vertical orientation since when both x and y are numeric there's no way to tell what the orientation should be. So what you're looking at is a bunch of vertically-oriented dotplots.

This is why changing y to a discrete value fixes it, because then orientation detection correctly identifies y as the off-axis. I believe older versions of the ggplot orientation detection algorithm identified integer-like double axes which could help in this situation, though I'm reluctant to start maintaining a custom orientation detection algorithm within ggdist. 

In the absence of that I'm not sure there's a good solution to this really. Maybe an example in the docs or something. A warning / error is not appropriate because in some cases this will be the correct behavior. 

----------------------------
steveharoz:

Oh, that reminds me, setting the orientation is a third workaround.

I assumed ggdist did the orientation detection internally. If you're building off of ggplot's orientation, catching problems could be more difficult. I just wanted to put this issue down somewhere because someone else may run into the problem.",TRUE,docs,2021-09-25 12:07:56,NA,documentation,,OPEN,2021-12-06 03:11:55,NA,,I_kwDOEBBtO848Bqjz
101,https://github.com/mjskay/ggdist/issues/101,https://github.com/mjskay/ggdist/issues/101,steveharoz,feature request: align dot bins,"When there are multiple dot histograms shown, misalignment can really stand out. It'd help to have a bit more control over the bin placement.

```r
expand.grid(
  side=c(""top"", ""bottom""), 
  y=LETTERS[1:2], 
  reps=1:30, 
  stringsAsFactors = FALSE
) %>% 
  mutate(x = rnorm(n())) %>% 
  ggplot() +
  aes(x=x, y=y, side=side, fill=y) +
  ggdist::stat_dots(binwidth=0.2)
```
![image](https://user-images.githubusercontent.com/2257540/134770543-1237cc63-9c66-47ed-a45c-7e16971870c5.png)


`geom_histogram()` has a `boundary` parameter that sets the boundary of one bin, and the rest follow.

It'd be helpful to be able to use the same parameter to have more control over the binning: `stat_dots(binwidth=0.2, boundary=0)`",FALSE,"----------------------------
mjskay:

Yeah something like this would be useful. Not sure the best way to do it, as the wilkinson algorithm does not have regularly spaced bins, so just setting a boundary would not cause all bins to line up. Would either have to determine bin positions globally by applying the wilkinson algorithm to the combined data (enh) or to allow histogram binning (more likely). So maybe a `layout = ""histogram""` combined with something like the `center` and `boundary` parameters (would need to see if those can be made suitably generic... That brings back questions of what to do with the binning params for stat_histinterval which I would want to keep in sync with this before I start adding parameters willy nilly) ",TRUE,enhancement,2021-09-25 11:52:52,NA,,,OPEN,2021-09-25 13:37:50,NA,,I_kwDOEBBtO848Bpyy
100,https://github.com/mjskay/ggdist/issues/100,https://github.com/mjskay/ggdist/issues/100,mjskay,allow wide bins when bins are too tall in automatic bin width selection,"pinging off of stuff @steveharoz was playing with when making dotplots of discrete distributions, it would be good to have an automatic way for bins to be given multiple columns if the automatic binning would otherwise select a binwidth that leads to bins that are too tall. See this tweet: https://twitter.com/sharoz/status/1440920556958851073?s=20

Fortunately the code already detects this problem, see here: https://github.com/mjskay/ggdist/blob/89191588281ea4115d9195aadd61d3cad061ec80/R/binning_methods.R#L254-L261

just need a better solution",TRUE,"----------------------------
mjskay:

This should be addressed (in a slightly different way) by using `smooth = ""discrete""` or `smooth = ""bar""` in the next release. See #161 or the new section (in the next release) on discrete variables in `vignette(""dotsinterval"")`",TRUE,enhancement,2021-09-24 02:17:17,2022-12-23 01:15:28,,,CLOSED,2022-12-23 01:15:28,NA,,I_kwDOEBBtO8479nvU
99,https://github.com/mjskay/ggdist/issues/99,https://github.com/mjskay/ggdist/issues/99,rcalinjageman,Can position take a vector from position_nudge?,"I'd like to nudge distributions over on a graph depending on a data column/vector (e.g. position = position_nudge(c = (0.5, 0.5, 0)).  When I try this with ggdist I get some odd behavior-- two copies of each distribution are produced, one un-nudged and one nudged, and only the first value of the vector seems to matter.  For other geoms, like geom_point, using a vector with position_nudge gives the expected behavior.

I have a code example below-- the goal is to nudge the first two distributions over to make space for raw data but to leave the third row, which has no raw data, un-nudged.  It may be that I need a completely different approach.  I've tried position = ""dodge"" with no luck.  I guess another approach would be to first plot the group distributions with a constant nudge and then plot the difference without a nudge... but open to any suggestions.



Here's example code:

`# Libraries
library(ggplot2)
library(ggdist)
library(distributional)


# Population params for desired data
population <- data.frame(
  condition = c(""Group1"", ""Group2""),
  mu = c(100, 115),
  sigma = c(15, 15),
  n = c(50, 45)
)


# Simulate raw data and calculate summary data
raw_data <- NULL
summary_data <- NULL

for (i in 1:nrow(population)) {
  this_condition <- data.frame(
    condition = rep(population[i, ""condition""], times = population[i, ""n""]),
    outcome = rnorm(
      n = population[i, ""n""], 
      mean = population[i, ""mu""],
      sd = population[i, ""sigma""]
    )
  )

  summary_data <- rbind(
    summary_data,
    data.frame(
      condition = c(population[i, ""condition""]),
      mean = mean(this_condition$outcome),
      sd = sd(this_condition$outcome),
      se = sd(this_condition$outcome) / sqrt(nrow(this_condition)),
      n = nrow(this_condition),
      df = nrow(this_condition) - 1
    )
  )

  raw_data <- rbind(
    raw_data,
    this_condition
  )
}


# Difference between groups
diff_m <- summary_data[1, ""mean""] - summary_data[2, ""mean""]
diff_df <- sum(summary_data$df)
diff_se <- sqrt(sum(summary_data$sd^2 / summary_data$n))

summary_data[3, c(""mean"", ""se"", ""df"")] <- c(
  diff_m,
  diff_se,
  diff_df
)
summary_data[3, ""condition""] <- ""Difference""

summary_data$nudge <- c(0.3, 0.3, 0)



# Fix condition factor to ensure difference is plotted last
summary_data$condition <- factor(
  summary_data$condition, 
  levels = summary_data$condition
)
raw_data$condition <- factor(
  raw_data$condition,
  levels = summary_data$condition
)


# Now the plot
myplot <- ggplot2::ggplot(data = summary_data)

myplot <- myplot + ggdist::stat_dist_halfeye(
  data = summary_data,
  ggplot2::aes(
    x = condition, 
    y = mean,
    dist = distributional::dist_student_t(
      df = df, 
      mu = mean, 
      sigma = se
    )
  ),
  scale = 0.33,
  position = position_nudge(x = summary_data$nudge)
)

myplot <- myplot + ggplot2::geom_point(
  data = raw_data,
  aes(
    x = condition,
    y = outcome
  ),
  position = position_jitter(width = 0.2)
)

myplot
`",TRUE,"----------------------------
mjskay:

Yeah, the problem is that `position_nudge` gets applied after the `stat`s are. What's happening internally is that `stat_dist_halfeye()` is producing a data frame that contains density values and the points and intervals and this is being passed to `position_nudge()` (and then eventually to the underlying geometry).

This data frame will be (by default) 501 x number of groups + 2 x number of groups in length --- 501 values from each density plus one row per interval per group. What's happening is that your vector of 3 values is being recycled to cover those (501 + 2) * 3 = 1509 rows, but not in a way that lines up with the rows corresponding to each group. Instead, if you give a vector of `c(0.3, 0.3, 0)`, the values are interleaved, so you would end up with 2/3s of the density values for each group having a nudge of `0.3` and 1/3 having a nudge of `0`, hence the apparent duplication.

One (**bad and not recommended**) solution would be to give a nudge vector of length 1509:

```r
myplot <- ggplot2::ggplot(data = summary_data)

myplot <- myplot + ggdist::stat_dist_halfeye(
    data = summary_data,
    ggplot2::aes(
        x = condition,
        y = mean,
        dist = distributional::dist_student_t(
            df = df,
            mu = mean,
            sigma = se
        )
    ),
    scale = 0.33,
    position = position_nudge(x = c(rep(summary_data$nudge, each = 501), rep(summary_data$nudge, each = 2)))
)

myplot <- myplot + ggplot2::geom_point(
    data = raw_data,
    aes(
        x = condition,
        y = outcome
    ),
    position = position_jitter(width = 0.2)
)

myplot
```
![image](https://user-images.githubusercontent.com/6345019/132744830-3c119336-5a01-4414-bbdc-483558892582.png)

This is a bad solution because it relies on the order of rows in the internal dataframe not changing in future implementations of ggdist, which I cannot guarantee. So, while it works, I would not recommend it.

Some alternatives: one would be to use two different geoms to specify the nudges seperately. You can avoid code duplication by using a temporary function to do it:

```r
myplot <- ggplot2::ggplot(data = summary_data)

make_halfeye <- function(...) {
  ggdist::stat_dist_halfeye(
    ggplot2::aes(
        x = condition,
        y = mean,
        dist = distributional::dist_student_t(
            df = df,
            mu = mean,
            sigma = se
        )
    ),
    scale = 0.33,
    ...
  )
}

myplot <- myplot + 
  make_halfeye(data = filter(summary_data, condition != ""Difference""), position = position_nudge(x = 0.3)) +
  make_halfeye(data = filter(summary_data, condition == ""Difference""))

myplot <- myplot + ggplot2::geom_point(
    data = raw_data,
    aes(
        x = condition,
        y = outcome
    ),
    position = position_jitter(width = 0.2)
)

myplot
```
![image](https://user-images.githubusercontent.com/6345019/132746048-2b9b6032-c167-4880-bc13-ccc80fb62581.png)

The axis order is different, but you could re-order that by adding `scale_x_discrete(limits = c(""Group1"", ""Group2"", ""Difference""))` to the above.

A final option would be to apply the offsets directly to the x position values in the numeric space, by converting the factors to numeric first. This does require the use of `scale_x_discrete()`, otherwise you get an error:

```r
myplot <- ggplot2::ggplot(data = summary_data)

myplot <- myplot + ggdist::stat_dist_halfeye(
    data = summary_data,
    ggplot2::aes(
        x = as.numeric(condition) + nudge,
        y = mean,
        dist = distributional::dist_student_t(
            df = df,
            mu = mean,
            sigma = se
        )
    ),
    scale = 0.33
)

myplot <- myplot + ggplot2::geom_point(
    data = raw_data,
    aes(
        x = condition,
        y = outcome
    ),
    position = position_jitter(width = 0.2)
)

myplot + scale_x_discrete(limits = levels(summary_data$condition))
```
![image](https://user-images.githubusercontent.com/6345019/132746646-97fc7098-4340-40c5-b6e0-e9a680905745.png)


Hope that helps!

----------------------------
rcalinjageman:

Wow.  Thanks.  This is incredibly helpful.  
Also, it finally dawned on me that I could nudge the raw data by a constant rather than the summary data by a varying value.  :-)",TRUE,help,2021-09-09 14:30:31,2021-09-11 13:44:59,,,CLOSED,2021-09-11 13:44:59,NA,,MDU6SXNzdWU5OTIyOTk0MDA=
98,https://github.com/mjskay/ggdist/issues/98,https://github.com/mjskay/ggdist/issues/98,msenn,stat_halfeye should handle groups with a single data point,"The following data set has only a single observation for group ""a"":

```r
df <- tibble(group = letters[1:4],
             n = c(1, rep(100, 3))) %>% 
  uncount() %>% 
  mutate(x = rnorm(n()))
```

`stat_halfeye()` throws a warning (""Computation failed in `stat_sample_slabinterval()`:
need at least 2 points to select a bandwidth automatically "" and renders an empty plot:

```r
df %>% 
  ggplot(aes(x, group, fill = group)) +
  ggdist::stat_halfeye()
```

This looks to me like a special case of #55 and I would have hoped for the same behavior (i.e. no density but a point, throw a warning). ",TRUE,"----------------------------
mjskay:

Ah good point, thanks for catching it! Should be fixed on the github version now.

----------------------------
msenn:

Thanks for fixing!",TRUE,bug,2021-09-06 14:03:18,2021-09-07 05:48:18,,,CLOSED,2021-09-07 06:04:54,NA,,MDU6SXNzdWU5ODkyMDcwODQ=
97,https://github.com/mjskay/ggdist/issues/97,https://github.com/mjskay/ggdist/issues/97,arthur-albuquerque,fill_ramp not respecting the threshold value,"Hi Matthew,

In another issue (#71 ), you helped me to figure out how to use fill_ramp, and it works most of the time perfectly. Yet, there is one specific situation that it glitches, i.e., the function doesn't fill exactly according to the threshold I set (dashed line), as you can see here:

![image](https://user-images.githubusercontent.com/77208087/130297132-7e277fb5-f09f-4d9e-b4d1-07eb1773e4e6.png)

I could not replicate it with fake data, so I made my brms model available below. It is a random-effect meta-analysis with a couple of predictors (the data is public). 

I am having this problem whenever I try to generate predictive distributions in this meta-analysis.  Here is the code to replicate the figure above, and you will see that the filling pattern changes according to the seed. 

I have no idea what is going on here. I would love to hear what you think.

Best,

Arthur

```
library(brms)
library(tidybayes)
library(ggdist)
library(tidyverse)

# Load brms model (Stored in OSF)
m = url(""https://osf.io/dvs6y/download?version=1"")
m1 = readRDS(gzcon(m))

data_plot_function = function(seed){
  
  set.seed(seed)
  
  N = 10e4
  
  d = 
    m1 %>% 
    tidy_draws() %>% 
    summarise(""Simple oxygen only"" =
                rnorm(N, mean = (b_Intercept + b_oxygenlow), sd = sd_study__Intercept),
              ""Noninvasive ventilation"" =
                rnorm(N, mean = (b_Intercept + b_oxygenNIV), sd = sd_study__Intercept),
              ""Invasive mechanical ventilation"" =
                rnorm(N, mean = b_Intercept, sd = sd_study__Intercept)) %>% 
    pivot_longer(1:3) %>% 
    mutate(name = fct_rev(name))
  
  p = 
    d %>% 
    ggplot(aes(
      x = exp(value), # exp() to transform from log odds ratio to odds ratio
      fill = name,
      fill_ramp = stat(x < 0.85))
    ) +
    
    stat_halfeye(point_interval = median_qi,
                 .width = 0.95) +
    scale_fill_ramp_discrete(from = ""gray85"", range = c(0,1)) +
    scale_fill_manual(values = c(""#EECE9C"", # Simple oxygen
                                 ""#BE6376"", # Non-invasive
                                 ""#605A91"") # Invasive 
    ) +
    
    annotate(""rect"", xmin=0.85, xmax=1/0.85, ymin=-Inf, ymax=Inf,
             fill=""#D9D9D9"",  alpha=0.4) +
    geom_vline(xintercept = 1/0.85, linetype = 2, size = 0.4, alpha = 0.7) +
    geom_vline(xintercept = 0.85, linetype = 2, size = 0.4, alpha = 0.7) +
    labs(
      x = ""\nOdds Ratio"",
      y = "" ""
    ) +
    scale_x_continuous(breaks = seq(from = 0.2, to = 1.6, 0.2)) +
    coord_cartesian(xlim = c(0.2, 1.4)) +
    scale_y_discrete(expand = c(0, 0.5)) +
    facet_wrap(~ name, ncol = 1, scales = ""free_y"")
  
  print(p)

}

data_plot_function(123)
data_plot_function(200)
data_plot_function(1000)
```


 ",TRUE,"----------------------------
mjskay:

Ah yeah. The issue appears to be that the distributions you are plotting have some pretty large outliers, and the default settings for the kernel density estimator in stat_halfeye is to use only 501 points. You can see this most easily in the plot for `Noninvasive ventilation` --- there are actually only a few points being used to draw the shape of the density. Because of your use of coord_cartesian, most of the points used to approximate the density are outside the plot bounds.

One solution is to increase the number of points in the grid for the density estimator. Passing something like `n = 1000` or `n = 5000` to `stat_halfeye()` seems to work:

```r
library(brms)
library(tidybayes)
library(ggdist)
library(tidyverse)

# Load brms model (Stored in OSF)
m = url(""https://osf.io/dvs6y/download?version=1"")
m1 = readRDS(gzcon(m))

data_plot_function = function(seed){
  
  set.seed(seed)
  
  N = 10e4
  
  d = 
    m1 %>% 
    tidy_draws() %>% 
    summarise(""Simple oxygen only"" =
                rnorm(N, mean = (b_Intercept + b_oxygenlow), sd = sd_study__Intercept),
              ""Noninvasive ventilation"" =
                rnorm(N, mean = (b_Intercept + b_oxygenNIV), sd = sd_study__Intercept),
              ""Invasive mechanical ventilation"" =
                rnorm(N, mean = b_Intercept, sd = sd_study__Intercept)) %>% 
    pivot_longer(1:3) %>% 
    mutate(name = fct_rev(name))
  
  p = 
    d %>% 
    ggplot(aes(
      x = exp(value), # exp() to transform from log odds ratio to odds ratio
      fill = name,
      fill_ramp = stat(x < 0.85))
    ) +
    
    stat_halfeye(point_interval = median_qi,
                 .width = 0.95,
                 n = 5000
      ) +
    scale_fill_ramp_discrete(from = ""gray85"", range = c(0,1)) +
    scale_fill_manual(values = c(""#EECE9C"", # Simple oxygen
                                 ""#BE6376"", # Non-invasive
                                 ""#605A91"") # Invasive 
    ) +
    
    annotate(""rect"", xmin=0.85, xmax=1/0.85, ymin=-Inf, ymax=Inf,
             fill=""#D9D9D9"",  alpha=0.4) +
    geom_vline(xintercept = 1/0.85, linetype = 2, size = 0.4, alpha = 0.7) +
    geom_vline(xintercept = 0.85, linetype = 2, size = 0.4, alpha = 0.7) +
    labs(
      x = ""\nOdds Ratio"",
      y = "" ""
    ) +
    scale_x_continuous(breaks = seq(from = 0.2, to = 1.6, 0.2)) +
    coord_cartesian(xlim = c(0.2, 1.4)) +
    scale_y_discrete(expand = c(0, 0.5)) +
    facet_wrap(~ name, ncol = 1, scales = ""free_y"")
  
  print(p)

}

data_plot_function(123)
```
![image](https://user-images.githubusercontent.com/6345019/130310112-a44e1623-666e-4404-84a1-92633ed393f0.png)


As an aside, I'm pretty sure you can let brms do the coefficient munging for you to produce uncertainty intervals that incorporate between-study variance (which I think it what you're going for here?). Something like this:

```r
library(brms)
library(tidybayes)
library(ggdist)
library(tidyverse)

# Load brms model (Stored in OSF)
m = url(""https://osf.io/dvs6y/download?version=1"")
m1 = readRDS(gzcon(m))

data_plot_function = function(seed){
  
  set.seed(seed)
  
  # constructing d using add_epred_draws...
  d = 
    m1$data %>% 
    expand(oxygen, study = ""new"", sei = 0) %>%
    add_epred_draws(m1, allow_new_levels = TRUE, sample_new_levels = ""gaussian"") %>%
    rename(name = oxygen, value = .epred) %>%
    mutate(name = name %>%
      fct_relevel(""low"", ""NIV"", ""IMV"") %>%
      fct_recode(
        ""Simple oxygen only"" = ""low"",
        ""Invasive mechanical ventilation"" = ""IMV"",
        ""Noninvasive ventilation"" = ""NIV""
      )
    )
  
  p = 
    d %>% 
    ggplot(aes(
      x = exp(value), # exp() to transform from log odds ratio to odds ratio
      fill = name,
      fill_ramp = stat(x < 0.85))
    ) +
    
    stat_halfeye(point_interval = median_qi,
                 .width = 0.95,
                 n = 5000
      ) +
    scale_fill_ramp_discrete(from = ""gray85"", range = c(0,1)) +
    scale_fill_manual(values = c(""#EECE9C"", # Simple oxygen
                                 ""#BE6376"", # Non-invasive
                                 ""#605A91"") # Invasive 
    ) +
    
    annotate(""rect"", xmin=0.85, xmax=1/0.85, ymin=-Inf, ymax=Inf,
             fill=""#D9D9D9"",  alpha=0.4) +
    geom_vline(xintercept = 1/0.85, linetype = 2, size = 0.4, alpha = 0.7) +
    geom_vline(xintercept = 0.85, linetype = 2, size = 0.4, alpha = 0.7) +
    labs(
      x = ""\nOdds Ratio"",
      y = "" ""
    ) +
    scale_x_continuous(breaks = seq(from = 0.2, to = 1.6, 0.2)) +
    coord_cartesian(xlim = c(0.2, 1.4)) +
    scale_y_discrete(expand = c(0, 0.5)) +
    facet_wrap(~ name, ncol = 1, scales = ""free_y"")
  
  print(p)

}

data_plot_function(123)
```
![image](https://user-images.githubusercontent.com/6345019/130310375-641f3624-a9d8-4ce3-a02d-2e514ce4b383.png)

`add_epred_draws()` here is new as of tidybayes 3.0 but is analogous to the old `add_fitted_draws()` and just calls down to `brms::posterior_epred()`.

----------------------------
arthur-albuquerque:

Double awesome!! Thanks, Matthew. 

----------------------------
mjskay:

no prob!",TRUE,help,2021-08-20 21:58:01,2021-08-21 22:09:20,,,CLOSED,2021-08-21 22:09:20,NA,,MDU6SXNzdWU5NzU5NDU4MDE=
96,https://github.com/mjskay/ggdist/issues/96,https://github.com/mjskay/ggdist/issues/96,PythonCoderUnicorn,ggdist hexagon logo,"Hello ggdist team,

I noticed that there was no logo outside of the image of a plot, and so I made a hexagon logo using the colours used in the small logo in the image. My name is Zane Dax and design hexagon logos, trying to build a portfolio and want to share what I made. Hope that you like it, and if you want edits to it let me know.

Thanks.

![ggDist logo](https://user-images.githubusercontent.com/55933131/130291850-ea952d64-1ee6-4283-8926-3085e826c56b.png)
",TRUE,"----------------------------
mjskay:

Hi Zane --- thanks! I appreciate you offering your services. You may have missed that ggdist does have an existing logo (figures-source/logo.pdf). At the moment I am happy with the existing logo and plan to continue using it.",TRUE,docs,2021-08-20 20:49:52,2021-12-06 03:17:18,,,CLOSED,2021-12-06 03:17:18,NA,,MDU6SXNzdWU5NzU5MTI0MDU=
95,https://github.com/mjskay/ggdist/issues/95,https://github.com/mjskay/ggdist/issues/95,DominiqueMakowski,curve_interval: a numeric/dataframe method?,"Hi! We're currently trying to provide support for `curve_interval` in easystats (https://github.com/easystats/bayestestR/issues/455). Due to how our API is organized, it would be helpful to have a method that works on ""regular"" draws matrices (e.g., such as one from `as.data.frame(some_rstanarm_model)`), rather than grouped dataframes, since we don't have dplyr/tibble as dependencies. 

Is it something that is possible to implement? Here's a reproduction of the first example in https://mjskay.github.io/ggdist/reference/curve_interval.html, but using bayestestR's formats of inputs/outputs:

``` r
library(bayestestR)
library(ggplot2)
library(ggdist)
#> Attaching package: 'ggdist'
#> The following object is masked from 'package:bayestestR':
#> 
#>     hdi


# Generate data =============================================
k = 11 # number of curves (iterations)
n = 201 # number of rows
data <- data.frame(x = seq(-15,15,length.out = n))

# Simulate iterations as new columns
for(i in 1:k) {
  data[paste0(""iter_"", i)] <- dnorm(data$x, seq(-5,5, length.out = k)[i], 3)
}

# Note: first, we need to transpose the data to have iters as rows
iters <- datawizard::data_transpose(data[paste0(""iter_"", 1:k)])

# Compute Median
data$Median <- point_estimate(iters)[[""Median""]]

# Compute Credible Intervals ================================

# Compute ETI (default type of CI)
data[c(""ETI_low"", ""ETI_high"")] <- eti(iters, ci = 0.5)[c(""CI_low"", ""CI_high"")]

# Compute CWI
# ggdist::curve_interval(reshape_iterations(data), iter_value .width = c(.5))

# Visualization =============================================
ggplot(data, aes(x = x, y = Median)) +
  geom_ribbon(aes(ymin = ETI_low, ymax = ETI_high), fill = ""red"", alpha = 0.3) +
  geom_line(size = 1) +
  geom_line(data = reshape_iterations(data),
            aes(y = iter_value, group = iter_group),
            alpha = 0.3)
```

![](https://i.imgur.com/OaPXJTL.png)

<sup>Created on 2021-08-18 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>

I would like to compute the curvewise interval without, if possible, reshaping to long + grouping the iteration dataframe. As always, thanks :)",TRUE,"----------------------------
mjskay:

Yeah I think something like this is definitely doable. I was already thinking about making curve_interval generic so that posterior::rvar objects could be passed to it. Internally since rvars just wrap an array where the first dimension is draws any changes to support that would also make it easy to have an implementation of the generic for matrices.

----------------------------
mjskay:

I added a pretty simple implementation of `curve_interval()` for rvars and for matrices (for the latter, draws must be the first dimension). In that implementation, it assumes you want intervals for all variables joint with each other (i.e. you can't set `.along`), since if you want to set `.along` you might as well put it into a data frame format anyway. Not sure if you're still wanting to use this somewhere, but if you are and it doesn't work for you, let me know.",TRUE,enhancement,2021-08-18 02:52:19,2023-01-28 22:33:15,,,CLOSED,2023-01-28 22:36:17,NA,,MDU6SXNzdWU5NzMyMjMxNzE=
94,https://github.com/mjskay/ggdist/issues/94,https://github.com/mjskay/ggdist/issues/94,mjskay,implement curve_interval(<rvar>),"`curve_interval(<data.frame>, <rvar>)` works, but possibly (not sure?) it should be possible to do `curve_interval(<rvar>)`",TRUE,,FALSE,enhancement,2021-08-15 20:19:15,2023-01-30 01:34:46,,,CLOSED,2023-01-30 01:34:46,NA,,MDU6SXNzdWU5NzEyMTU3NTI=
93,https://github.com/mjskay/ggdist/issues/93,https://github.com/mjskay/ggdist/issues/93,ASKurz,space between slab and interval,"With some plots, particularly dots plots, it's nice to have a small space between the bottom of the distribution and the point interval. Here's my current method for doing so:

```{r}
library(tidyverse)
library(ggdist)

mtcars %>% 
  ggplot(aes(x = mpg, y = 0)) +
  stat_dots() +
  stat_pointinterval(position = position_nudge(y = -0.05))
```
<img width=""893"" alt=""Screen Shot 2021-08-10 at 1 52 22 PM"" src=""https://user-images.githubusercontent.com/19917004/128918341-b96b7b68-6780-4130-b73f-92d582157e3b.png"">

Is there a simpler way that doesn't involve separating what would have been a single `stat_dotsinterval()` line into one line for `stat_dots()` and a second line for `stat_pointinterval()`? ",TRUE,"----------------------------
mjskay:

In general this is the recommended approach --- once you start having stuff that targets different parts of a composite geom it's often easier to break them up. The composites are really meant as shortcuts for the two geoms used simultaneously, and I'm reluctant to add too many parameters targeting this that or the other sub-part since that is just duplicating the functionality you already get for free by breaking them up (with approximately equal code complexity but worse learnability since you have to learn new parameters).

That said, you can use a negative value of the justification parameter to achieve something similar, except that justification changes the position of the slab relative to the interval and not the interval relative to the slab:

```r
library(tidyverse)
library(ggdist)

mtcars %>% 
    ggplot(aes(x = mpg, y = 0)) +
    stat_dotsinterval(justification = -0.1)
```
![image](https://user-images.githubusercontent.com/6345019/128920244-e33b4403-5cda-469c-adae-5a327cfbf962.png)

This usage is not standard but is supported.

If you really wanted to you could apply a justification and a nudge to get back to something like what you have:

```r
library(tidyverse)
library(ggdist)

mtcars %>% 
    ggplot(aes(x = mpg, y = 0)) +
    stat_dotsinterval(justification = -1/9, position = position_nudge(y = -0.1))
```
![image](https://user-images.githubusercontent.com/6345019/128920686-90aaf654-8c5a-472d-9f73-0cc6be03dd03.png)

Note that the correct justification to exactly cancel out a nudge of `.1` is actually `-1/9` not `-.1`; this is because the justification is calculated relative to the slab `scale`, which defaults to `.9` (so the derivation is `justification = -0.1/0.9`). This ensures that with a justification of `0` the bottom edge of the slab touches the interval and with a justification of `1` the top edge touches no matter the value of `scale`. This is part of why I don't really recommend using negative justifications in this way; it's easier and clearer to separate the geoms.

----------------------------
ASKurz:

This is excellent. Thanks for the thorough answer, @mjskay!

----------------------------
mjskay:

oh! one thing I forgot to mention is that because the pointinterval still has a width of 1 centered on the interval (since its default `side` is `""both""`), your original code does have some extra space at the bottom. You can get rid of that by setting `side = ""top""` or `height = 0`:

```r
library(tidyverse)
library(ggdist)

mtcars %>% 
    ggplot(aes(x = mpg, y = 0)) +
    stat_dots() +
    stat_pointinterval(position = position_nudge(y = -0.05), side = ""top"")  # or height = 0
```
![image](https://user-images.githubusercontent.com/6345019/128935957-c02f095d-a1b2-426f-8bb5-e4f1947e9ac9.png)


----------------------------
ASKurz:

I didn't know that! You know, I've been futzing with `coord_cartesian(ylim = c(blah, blah))` for like forever with that issue. The `height = 0` trick is a major upgrade, for me. 

----------------------------
mjskay:

Yeah I have mixed feelings about it because it's not very discoverable... it makes dodging easier for pointintervals to have a default width (e.g. it makes their positioning consistent with other geoms if you want to line up multiple layers), but makes plot limits annoying at times. I dunno, hard to change it now 🤷. Probably I should just add an example to a vignette somewhere.

(I should say, if you are dodging them / lining them up with a slab or dots geom `side = ""top""` will generally work better than `height = 0`)",TRUE,help,2021-08-10 18:53:09,2021-08-10 19:19:47,,,CLOSED,2021-08-10 21:26:35,NA,,MDU6SXNzdWU5NjUyNTczNzI=
92,https://github.com/mjskay/ggdist/issues/92,https://github.com/mjskay/ggdist/issues/92,mjskay,Get rid of hackish child_params thing in slabinterval,Can probably use extra_params for this. See parameters implementation in geom base class,TRUE,"----------------------------
mjskay:

This is closed by #106 ",FALSE,refactor,2021-07-27 08:41:23,2021-10-26 07:07:53,,,CLOSED,2021-10-26 07:07:53,NA,,MDU6SXNzdWU5NTM2NDYzOTA=
91,https://github.com/mjskay/ggdist/issues/91,https://github.com/mjskay/ggdist/issues/91,mjskay,Fixes for new indexing in distributional,"Fix issues introduced by the indexing changes in distributional. See https://github.com/mitchelloharawild/distributional/issues/29 and https://github.com/mitchelloharawild/distributional/issues/52

- [x] fix stuff
- [x] ping back on distributional once this is fixed",TRUE,,FALSE,bug,2021-07-26 06:12:14,2021-10-12 03:18:21,,,CLOSED,2021-10-12 03:18:21,Next release ,,MDU6SXNzdWU5NTI1NDE5NzQ=
90,https://github.com/mjskay/ggdist/issues/90,https://github.com/mjskay/ggdist/issues/90,mjskay,deal with size = NA bug in geom_dots,size = 0 works fine but size = NA should probably not error,TRUE,#NAME?,FALSE,bug,2021-07-20 03:53:01,2021-07-21 04:14:34,,,CLOSED,2021-07-21 04:14:34,Summer,,MDU6SXNzdWU5NDgyMjI2MDA=
88,https://github.com/mjskay/ggdist/issues/88,https://github.com/mjskay/ggdist/issues/88,bwiernik,position_dodge() ordering,"Noticed one lingering issue with position_dodge(). The ordering of the dodged elements isn't consistent with the ggplot2 geoms. See the third model below:

``` r
library(ggplot2)
library(ggdist)
plot_data <- 
  tibble::tribble(
    ~Model, ~Parameter, ~Coefficient,  ~SE, ~CI_low, ~CI_high, ~df_error, ~linetype, ~nudge,
    ""A"",       ""MZ"",         0.41, 0.04,    0.33,     0.48,       530,  ""dashed"",   0.25,
    ""A"",     ""Full"",          0.4, 0.03,    0.35,     0.45,      1266, ""twodash"",   0.25,
    ""B"",       ""MZ"",         0.36, 0.04,    0.29,     0.44,       522,  ""dashed"",   0.25,
    ""B"",     ""Full"",         0.34, 0.03,    0.29,     0.39,      1256, ""twodash"",   0.25,
    ""C"",       ""MZ"",         0.34, 0.07,     0.2,     0.48,       Inf,  ""dashed"",   0.25,
    ""C"",     ""Ereg"",         0.28, 0.06,    0.16,     0.41,       Inf, ""twodash"",   0.25,
    ""C"",     ""AE-Beta"",      0.25, 0.06,    0.13,     0.38,       Inf,  ""solid"",    0.25,
    ""D"",       ""MZ"",         0.31, 0.08,    0.15,     0.46,       Inf,  ""dashed"",      0,
  ) |> 
  dplyr::mutate(dplyr::across(Model:Parameter, forcats::as_factor))

base_plot <- plot_data |>
  ggplot() +
  aes(x = forcats::fct_rev(Model), y = Coefficient, ymin = CI_low, ymax = CI_high,
      label = Parameter, color = Parameter,
      group = linetype,
      dist = distributional::dist_student_t(df = df_error, mu = Coefficient, sigma = SE)
  ) +
  theme_classic() +
  guides(color = ""none"", linetype = ""none"") +
  labs(x = NULL, y = NULL) +
  coord_flip()

base_plot +
  geom_line(
    aes(linetype = linetype, color = dplyr::recode(Parameter, Ereg = ""Full""), group = linetype),
    position = position_dodge(width = .5)
  ) +
  stat_dist_halfeye(
    aes(y = Coefficient, x = forcats::fct_rev(Model) ,
        fill = after_scale(colorspace::lighten(color, .1))),
    position = position_dodge(width = .5),
    slab_alpha = .25
  ) +
  geom_label(
    fill = ""white"",
    position = position_dodge(width = .5)
  )
```

![](https://i.imgur.com/91rnOvF.png)

<sup>Created on 2021-07-11 by the [reprex package](https://reprex.tidyverse.org) (v2.0.0)</sup>
 ",TRUE,#NAME?,TRUE,bug,2021-07-11 22:32:01,2021-07-12 00:56:25,,,CLOSED,2021-07-12 01:05:06,NA,,MDU6SXNzdWU5NDE1NDQyODg=
87,https://github.com/mjskay/ggdist/issues/87,https://github.com/mjskay/ggdist/issues/87,mjskay,add tests and examples for grouping and `.along` parameter of curve_interval,"add tests and examples for the interaction between grouping and the `.along` parameter, and maybe add parameters for specifying the joint variables and the draw index variables explicitly.",FALSE,,FALSE,docs,2021-07-07 04:19:21,NA,,,OPEN,2021-07-07 04:19:21,NA,,MDU6SXNzdWU5Mzg0NjU2Nzg=
86,https://github.com/mjskay/ggdist/issues/86,https://github.com/mjskay/ggdist/issues/86,bwiernik,Specify point geom?,"I'm wondering if it might be possible to allow the geom used for the point in the composite stats/geoms to be customized? Specifically, I'm interested in substituting a geom_label/geom_richtext in place of the default point (cf. https://github.com/mjskay/ggdist/issues/85). ",TRUE,"----------------------------
mjskay:

Interesting... I think probably if we can get #85 working that makes the most sense as a solution to this, as it will be more generic. My feeling about composite geoms is they are mostly useful as shortcuts; as soon as you want to start customizing individual pieces beyond simple customizations it's easier to just specify the two pieces as separate layers --- of course unless things don't line up, as you found :). 

If we can solve the justification problem, does that solve your issue here?

----------------------------
bwiernik:

Yep. Just wanted to raise the question.

----------------------------
mjskay:

Closed via #85 unless something else comes up :)",TRUE,enhancement,2021-07-01 01:39:04,2021-07-07 04:18:14,,,CLOSED,2021-07-07 04:18:15,NA,,MDU6SXNzdWU5MzQyNzUxMjU=
85,https://github.com/mjskay/ggdist/issues/85,https://github.com/mjskay/ggdist/issues/85,bwiernik,bug: position_dodge() adds a nudge to slab? ,"I'm trying to use `position_dodge()` with `stat_dist_halfeye()` as well as other geoms (line and label). For some reason, doing this is adding a nudge offset to the distribution geom. I need to counteract that with a manual tweak of the position to get everything to line up correctly. See an example below:

``` r
library(ggplot2)
library(ggdist)
plot_data <- 
  tibble::tribble(
    ~Model, ~Parameter, ~Coefficient,  ~SE, ~CI_low, ~CI_high, ~df_error, ~linetype, ~nudge,
    ""A"",       ""MZ"",         0.41, 0.04,    0.33,     0.48,       530,  ""dashed"",   0.25,
    ""A"",     ""Full"",          0.4, 0.03,    0.35,     0.45,      1266, ""twodash"",   0.25,
    ""B"",       ""MZ"",         0.36, 0.04,    0.29,     0.44,       522,  ""dashed"",   0.25,
    ""B"",     ""Full"",         0.34, 0.03,    0.29,     0.39,      1256, ""twodash"",   0.25,
    ""C"",       ""MZ"",         0.34, 0.07,     0.2,     0.48,       Inf,  ""dashed"",   0.25,
    ""C"",     ""Ereg"",         0.28, 0.06,    0.16,     0.41,       Inf, ""twodash"",   0.25,
    ""D"",       ""MZ"",         0.31, 0.08,    0.15,     0.46,       Inf,  ""dashed"",      0,
  ) |> 
  dplyr::mutate(dplyr::across(Model:Parameter, forcats::as_factor))

base_plot <- plot_data |>
  ggplot() +
  aes(x = forcats::fct_rev(Model), y = Coefficient, ymin = CI_low, ymax = CI_high,
      label = Parameter, color = Parameter,
      group = linetype,
      dist = distributional::dist_student_t(df = df_error, mu = Coefficient, sigma = SE)
  ) +
  theme_classic() +
  guides(color = ""none"", linetype = ""none"") +
  labs(x = NULL, y = NULL) +
  coord_flip()

# looks right, with nudge
base_plot +
  geom_line(
    aes(linetype = linetype, color = dplyr::recode(Parameter, Ereg = ""Full""), group = linetype),
    position = position_dodge(width = .5)
  ) +
  stat_dist_halfeye(
    aes(y = Coefficient, x = as.integer(forcats::fct_rev(Model)) + nudge,
        fill = after_scale(colorspace::lighten(color, .1))),
    position = position_dodge(width = .5),
    slab_alpha = .25
  ) +
  geom_label(
    fill = ""white"",
    position = position_dodge(width = .5)
  )
```

![](https://i.imgur.com/TGTQoxQ.png)

``` r
# looks wrong, no nudge
base_plot +
  geom_line(
    aes(linetype = linetype, color = dplyr::recode(Parameter, Ereg = ""Full""), group = linetype),
    position = position_dodge(width = .5)
  ) +
  stat_dist_halfeye(
    aes(y = Coefficient, x = forcats::fct_rev(Model) ,
        fill = after_scale(colorspace::lighten(color, .1))),
    position = position_dodge(width = .5),
    slab_alpha = .25
  ) +
  geom_label(
    fill = ""white"",
    position = position_dodge(width = .5)
  )
```

![](https://i.imgur.com/i8BaYm2.png)

<sup>Created on 2021-07-01 by the [reprex package](https://reprex.tidyverse.org) (v2.0.0)</sup>



Any idea if this could be fixed? 

(Also, last night, I was also having an issue at one point with the dodging going in the opposition direction with `stat_dist_halfeye()` as with `geom_line()` or `geom_label()` [I had to set `width = -.5` in `stat_dist_halfeye()`'s `position_dodge()`], but I'm not able to reproduce that now with this simple case--will look into some of the more complex plots I tried out.)",TRUE,"----------------------------
mjskay:

ggdist currently does some unorthodox things to correct the alignment of intervals and slabs in position_dodge, and it's definitely possible there is a better way to do it :). Happy to take a look, though your reprex has some errors in it currently, can you update it? Thanks!

----------------------------
bwiernik:

oops, sorry! fixed.

----------------------------
bwiernik:

With two groups at a position, everything seems to be shifted down by .5 * width. Not sure the generalization

----------------------------
mjskay:

hmmm yeah. This gets into code I was not wanting to touch :)

Basically I have to hack around the fact that position_dodge() is a bit weird in that it doesn't maintain the relative justification of x/y values and xmin/xmax/ymin/ymax values when dodging, so based on where things have been dodged to and the `justification` parameter I have to figure out where to position the slabs relative to the intervals. This is handled by a bunch of crap approximately here:

https://github.com/mjskay/ggdist/blob/de20d5ca28407f3f241f1d46617dfda9f87104fe/R/geom_slabinterval.R#L35-L53

I *think* it should be possible to adjust this to move the min/max around the center (x/y) instead of adjust the x/y. May also have to change some stuff here:

https://github.com/mjskay/ggdist/blob/de20d5ca28407f3f241f1d46617dfda9f87104fe/R/geom_slabinterval.R#L581-L587

It would probably break some old charts to fix this, but it is probably worth it. Ideally the fix should only break charts that use dodging.


----------------------------
mjskay:

(this might also be totally unfixable without making a different version of position_dodge, I recall I either came to that conclusion or gave up when I originally was working on this problem, but I can't remember which)

----------------------------
mjskay:

k i am attempting to fix this on the [fix-just](https://github.com/mjskay/ggdist/tree/fix-just) branch. Not sure how successful it is so far but you're welcome to take a look.

----------------------------
mjskay:

Ah yup now I remember why this ended up the way it was --- plot bounds can be incorrect. I'll post some examples later when I have time. Possibly the solution will be to change how justifications are calculated but also provide a modified version of position_dodge that will work better in some cases.

----------------------------
bwiernik:

That fix does work for my case here, but I do see how the slabs are ending up closer to the top of the panel and that might cause issues. 

Are you thinking the default would be the ""plays well with others"" dodge in the fix-just branch and the new one being an alternative if things turn out poorly with that?

----------------------------
mjskay:

So, the issue is that position_dodge always moves the point (x or y depending on orientation, but let's say x here) to the center of the box the geom will be drawn in after dodging (xmin/xmax). The solution in the existing version of ggdist is to use the justification to move the interval relative to the slab:

```r
dist_df = tribble(
    ~group, ~subgroup, ~mean, ~sd,
    1,          ""h"",     5,   1,
    2,          ""h"",     7,   1.5,
    3,          ""h"",     8,   1,
    3,          ""i"",     9,   1,
    3,          ""j"",     7,   1
)
```

```r
dist_df %>%
  ggplot(aes(x = group, dist = dist_normal(mean, sd), fill = interaction(group,subgroup))) +
  stat_dist_halfeye(position = ""dodge"") +
  geom_rect(
    aes(xmin = group, xmax = group + 1, ymin = 2, ymax = 13, color = interaction(group, subgroup)), 
    position = ""dodge"", alpha = 0.1
  ) +
  geom_point(
    aes(x = group, y = 7.5, xmin = group, xmax = group + 1, color = interaction(group, subgroup)), 
    position = ""dodge"",
    shape = 1,
    size = 4
  ) +
  scale_fill_brewer(palette = ""Set2"") +
  scale_color_brewer(palette = ""Dark2"")
```
![image](https://user-images.githubusercontent.com/6345019/124150202-fa851380-da56-11eb-9089-3f3f5b7dab73.png)

This works but obviously means that points positioned using dodge won't line up correctly. The version on the fix-just branch instead moves the slab relative to the point position, which means things line up but can go outside the allotted area for the geom, hence the issues near plot edges:

```r
# same code, just running it on fix-just now
dist_df %>%
  ggplot(aes(x = group, dist = dist_normal(mean, sd), fill = interaction(group,subgroup))) +
  stat_dist_halfeye(position = ""dodge"") +
  geom_rect(
    aes(xmin = group, xmax = group + 1, ymin = 2, ymax = 13, color = interaction(group, subgroup)), 
    position = ""dodge"", alpha = 0.1
  ) +
  geom_point(
    aes(x = group, y = 7.5, xmin = group, xmax = group + 1, color = interaction(group, subgroup)), 
    position = ""dodge"",
    shape = 1,
    size = 4
  ) +
  scale_fill_brewer(palette = ""Set2"") +
  scale_color_brewer(palette = ""Dark2"")
```
![image](https://user-images.githubusercontent.com/6345019/124150558-4a63da80-da57-11eb-9da4-bf498aaeee62.png)

I'm honestly not sure the best solution. One option is to position slabs relative to the points like in the fix-just branch and add a ""justified dodge"", `position_justdodge()` or something like that, which could position the points correctly when dodging. Another might be to let people change the positioning approach with an option to the geom (I'm not a big fan of that though). I'm open to suggestions.


----------------------------
bwiernik:

I think making `position_dodge()` follow the fix-just behavior and having an alternative `position_*()` function makes the most sense. The fix-just behavior works in a most cases and it plays nicely with other geoms if users want to layer. I think it also makes sense to avoid an anti-pattern by having the different behavior be associated with a different function (e.g., easier to explain in documentation that the new function has a different behavior than the explain that it is the regular behavior normally expected from `position_dodge()`).

It took me a while to realize how the word ""justification"" applied to the behavior (that you are left/bottom justifying the geoms to their bounding box, rather than center/middle justifying them). But I see it now. I think `position_dodgejust()` or `position_dodgejustified()` might be a little clearer? Maybe give both as an alias? This function could have a `just` argument ala `hjust` in some `geoms`, defaulting to 0. 

----------------------------
mjskay:

The fix-just branch now has a `position_dodgejust()` with some examples in `?position_dodgejust`. If you have a chance to try it out I'd appreciate it! I'd especially like to know if these changes address your needs here and in #86.

----------------------------
mjskay:

Okay I think this is all fixed and documented now. Feel free to ping back around if there's something not working for it.",TRUE,"enhancement,refactor",2021-07-01 01:37:41,2021-07-07 04:17:50,,,CLOSED,2021-07-07 04:17:51,3.0.0,,MDU6SXNzdWU5MzQyNzQzNzE=
84,https://github.com/mjskay/ggdist/issues/84,https://github.com/mjskay/ggdist/issues/84,mjskay,remove workarounds for missing coverage on geoms,"If/when https://github.com/r-lib/covr/issues/113 is fixed, drop workarounds used to get coverage on functions inside geoms
(search for ""#84"" in the code)",FALSE,,FALSE,cleanup,2021-06-26 04:56:24,NA,,,OPEN,2021-06-26 04:56:56,NA,,MDU6SXNzdWU5MzA2MTU3OTk=
83,https://github.com/mjskay/ggdist/issues/83,https://github.com/mjskay/ggdist/issues/83,mjskay,See if we can merge stat_sample and stat_dist,"This might require some monkeying around with setup_layer but the general idea would be to allow distribution objects to be mapped onto x or y aesthetics (which should obvs then influence orientation detection) instead of the dist aesthetic. Would have to figure out how to support the old format (string plus args aesthetics). Would want to use this as an opportunity to merge the slab function code together (which probably means dist implementations of point_interval and maybe moving all the density/cdf/quantile code into a separate file).

This is just to reduce the set of geoms and eliminate the annoying usage bug of switching from one form to the other but forgetting to change the name and being confused why stuff isn't working.

Plan is something like:

- [x] allow stat_dist to support dists mapped to `xdist` or `ydist`
  - [x] ~~mapping dist to x or y gets re-written to a dist-based mapping internally~~
  - [x] ~~create `scale_x_dist()` and `scale_y_dist()` to deal with errors on things like this:~~ this turned out to be a bad idea; see https://github.com/mjskay/ggdist/issues/83#issuecomment-973756034
   ```r
   set.seed(1243);
   data.frame(x = c(1,2), y = dist_sample(list(0,0.2))) %>% 
     ggplot(aes(x, y=y)) +
     stat_dist_halfeye(slab_color = ""blue"", orientation = ""vertical"") +
     scale_y_continuous()
   ```
- [x] detect dist-like objects being passed to `x` / `y` aesthetic and give a helpful error message.
- [x] #103 
- [x] allow stat_dist to support numerics mapped to x or y by wrapping them in dist_sample()
- [x] #106 
- [x] forward slab function to compute_slab_sample when used on sample data (for densities at least)
- [x] make sure samples with NAs work in stat_dist
- [x] make sure stat_dist supports all arguments from stat_sample:
  - [x] `point_interval`
  - [x] `slab_type = ""histogram""`
  - [x] `adjust`
  - [x] `trim`
  - [x] `expand`
  - [x] `breaks`
  - [x] `outline_bars`
- [x] decide what to do about trimming the slab input limits to the limits of sample data on sample distributions (probably want to mimic this behavior from stat_sample_ in stat_dist_). 
  - [x] add new parameter `expand` to handle this: whether the slab only covers the sample data should be determined by `expand`, not `slab_type` (as it is in stat_sample_)
  - [x] make trimming to sample limits depend on `expand`, not `slab_type`
  - [x] make `expand = TRUE` the default for the ccdf / cdf stat_dists
  - [x] make sure compute_limits in stat_dist correctly handles the case where `trim = FALSE` when used on sample data
- [x] drop the limits_function args and whatnot from stat_slabinterval and make these be methods of StatSlabinterval instead (basically, don't want these exposed; this should simplify the public interface)
  - [x] limits_function, limits_args
  - [x] slab_function, slab_args
  - [x] interval_function, interval_args
  - [x] add all of these to `help(""ggdist-deprecated"")`
- [x] update dotsinterval
  - [x] ensure all args from sample version are in dist version
  - [x] make `quantiles` default to `NA` (but then have it use `100` by default on analytical distributions)
- [x] update lineribbon
- [x] ensure point_interval works on old distributional
- [x] rename:
  - [x] StatSlabinterval -> AbstractStatSlabinterval
  - [x] StatDistXXX -> StatXXX (leave old Dist names as aliases)
  - [x] remember to add StatHistinterval
  - [x] make StatSampleSlabinterval and StatDistSlabinterval aliases for StatSlabinterval
  - [x] search for stat_dist, StatDist, stat_sample, StatSample and switch them
- [x] merge docs and examples from stat_sample_... and stat_dist_... and old stat_slabinterval into new stat_slabinterval
- [x] implement hdci for distributional objects
- [x] rename `stat_dist_slabinterval.R` and `stat_sample_slabinterval.R`
- [x] mention deprecation of stat_dist_ in ggdist-deprecated
- [x] see if `sample_density` is still needed
- [x] simplify `compute_slab_sample`
- [x] simplify `compute_limits_sample`
- [x] simplify `compute_slab_dots_sample`
- [x] split apart shortcut geom docs
- [x] update slabinterval vignette
- [x] update cheat sheet
- [x] test geoms/stats in tidybayes
- [x] do a revdepcheck on this branch
- [x] test on both versions of distributional (or wait till new version is out and #116 is done)
- [x] check coverage
",TRUE,"----------------------------
bwiernik:

Could this perhaps be done with S3 dispatch on numeric vs posterior vs distributional arguments?

----------------------------
mjskay:

Unfortunately I think the solution has to be more complicated, because I suspect base ggplot will break if distributional objects are assigned to the `x` or `y` aesthetics.

The sketch of a solution I've been putting together in my head (but haven't tried yet) is something like:
- use `setup_layer()` to detect dist or rvar objects mapped onto `x` or `y` aesthetics and rewrite them into mappings onto `xdist` or `ydist` --- `setup_layer()` is a mostly-internally-used ggplot function that allows you to rewrite the data and the aesthetic mappings early in the pipeline
- would need a helper for later functions to figure out which of `x`/`xdist` or `y`/`ydist` is being used based on some consistent rules. 
- `setup_params()` would then look for either `x` or `y` or `xdist` or `ydist`, requiring only one or the other, and use these to figure out orientation
- `setup_data()` might (I'm not sure about this one) wrap sample data into a distributional object or an rvar. Then by the time `compute_panel()` hits everything is either a dist or an rvar.


----------------------------
mitchelloharawild:

> Unfortunately I think the solution has to be more complicated, because I suspect base ggplot will break if distributional objects are assigned to the `x` or `y` aesthetics.

Have you looked into adding `scale_x_distribution` and `scale_y_distribution` functions with an associated `scale_type(<distribution>)` method and distribution scale ggproto? I think it might be possible to allow `<distribution>` vectors to be specified for `x` and `y` aesthetics, but you might have trouble generating appropriate errors when distributions are used with non-dist supporting functions (say `geom_line()`).

----------------------------
mjskay:

> Have you looked into adding scale_x_distribution and scale_y_distribution functions with an associated scale_type(<distribution>) method and distribution scale ggproto?

Yeah, this is the current approach I am trying. So far it is not without some warts: mostly, users have to know that they can't use `scale_x_continuous()` or `scale_x_discrete()` or any of the `scale_x_[trans]` shortcuts anymore, and the resulting error messages can't be finagled to help them realize this as far as I can tell; also, I think `ggdist` has to be attached to the namespace for ggplot2 to find `scale_x/y_dist()` unless the user manually adds it. I'm going to continue prototyping it this way for a little bit and see how it goes.

The alternatives as I see it now are: (1) use `setup_layer()` to rewrite mappings like `x = [some distributon]` into `xdist = [some distribution]` or (2) keep the implementation of x/y mappings with scale_x_dist / scale_y_dist but also expose (and encourage use of) the `xdist = ...` and `ydist = ...` as the primary aesthetics for distributions or (3) don't support distributions in the `x/y` aesthetics at all (only `xdist` / `ydist`).

I plan at some point to poke some existing users to get them to try this stuff out both to find bugs and see how awkward it is. It's going to be a big change and I want to avoid breaking existing code.

----------------------------
mitchelloharawild:

> Yeah, this is the current approach I am trying. So far it is not without some warts: mostly, users have to know that they can't use `scale_x_continuous()` or `scale_x_discrete()` or any of the `scale_x_[trans]` shortcuts anymore, and the resulting error messages can't be finagled to help them realize this as far as I can tell; 

Yes - I think this is a ggplot2 issue in obscure error measures. I think think unsupported scale type errors can be improved over there, but it's hard to say if this would/could cause new issues elsewhere.

I also think that `scale_x_[trans]` is a design issue in ggplot2, as it forces `scale_x_continuous()`. I wonder if it's possible for ggplot2 to add `scale_x_inherit(...)` to override `...` in the current x scale.

> also, I think `ggdist` has to be attached to the namespace for ggplot2 to find `scale_x/y_dist()` unless the user manually adds it.
Yes, I believe it does.
 
> The alternatives as I see it now are: (1) use `setup_layer()` to rewrite mappings like `x = [some distributon]` into `xdist = [some distribution]` or (2) keep the implementation of x/y mappings with scale_x_dist / scale_y_dist but also expose (and encourage use of) the `xdist = ...` and `ydist = ...` as the primary aesthetics for distributions or (3) don't support distributions in the `x/y` aesthetics at all (only `xdist` / `ydist`).

(1) Sounds hackier than needed, especially when the alternative is for users to learn good ggplot2 practices.
(2) So both are handled in geoms/stats? Why not only allow `x=<dist>` and `y=<dist>`, and require users to know scales better? It has caused some user friction with `tsibble::scale_x_year***()` scales, but I think that is more of a documentation issue. Would you then transform the distribution axis with `scale_x_distribution(trans = ???)`?
(3) Another good option. Generally speaking I like adding some descriptor of axis for the distribution - I currently have some trouble recalling how to plot distributions on specific axis with the `dist` aesthetic alone. To transform the distribution axis, would you use `scale_x_continuous()` or `scale_xdist_continuous()`?

----------------------------
mjskay:

> (3) Another good option. Generally speaking I like adding some descriptor of axis for the distribution - I currently have some trouble recalling how to plot distributions on specific axis with the dist aesthetic alone. To transform the distribution axis, would you use scale_x_continuous() or scale_xdist_continuous()?

`scale_x_continuous()` (or `scale_x_discrete()` for a discrete distribution). This is basically how it works now with the `dist` aesthetic (which I agree is a little error-prone in current usage). Personally I think this works better, as distributions are often combined with other things on the same scale that are not distributions, so we aren't really setting up a scale for distributions per se, but whatever the underlying data type is (this brings up another wrinkle with putting distributions on x/y using `scale_x_dist()`: the `limits()` function doesn't really work with it (thus `xlim`/`ylim` don't really work) because the limits aren't expressed as distributional objects, but as objects of the underlying data type (numeric or integer or what have you).

So, I am kind of coming to the conclusion that unlike things like dates/times, which are legitimately other data types from a scale perspective, distributions don't really match that paradigm. Especially if you add support for other data types in `dist_sample()`: then we'd want dist scales for any other arbitrary data type. So maybe I'll just stick with `xdist` and `ydist` for now.

So I'm now leaning away from (2).

In the absence of option (2), the argument for option (1) is twofold: (A) that it allows x/y axis titles to be generated automatically from variable names and (B) that errors often happen when people accidentally map distributions to `x` or `y` instead of `dist`. Under option (3) I think (B) could be solved with the introduction of `xdist` / `ydist` and an error message if someone maps a distribution to `x` or `y` that tells them to map it to `xdist` or `ydist`. So the only question remaining is if (A) matters.

----------------------------
bwiernik:

Re (A), I think the automatic axis titles are so rarely finalized that it's a minor concern. Users usually have to tweak capitalization/spacing/etc using labs() or similar, so it's not much of a concern. 

----------------------------
mjskay:

Yeah makes sense. Barring objections I'll probably go with (3) then. 

----------------------------
mjskay:

If anyone out there is interested, this is working now and can be tested on the `unify-dist` branch via:

```r
devtools::install_github(""mjskay/ggdist@unify-dist"")
```

Under the hood all the `stat_dist_...` stats are now just aliases for their `stat_...` counterparts, which can now take `xdist`/`ydist`/`dist` aesthetics in addition to `x`/`y`. The result is that *in theory* all existing code should ""just work"", except that you don't need to remember to use `stat_dist_...` anymore in new code, you can just use `stat_...`.

Would be curious if anyone has any particularly weird existing code using ggdist that breaks on this version


----------------------------
bwiernik:

This complicated one using stat_dist_*() works great with the feature branch without code modifications

![image](https://user-images.githubusercontent.com/4773225/144323393-7d4e3fae-8cec-469d-aaf2-05829e0a498b.png)


----------------------------
mjskay:

@bwiernik thanks for testing it, that's great news! 

----------------------------
dmphillippo:

I've tested this with the [multinma](https://github.com/dmphillippo/multinma) R package which depends on ggdist - all seems to be working great.

Thank you @mjskay for this excellent package!

----------------------------
mjskay:

Thanks @dmphillippo, that's excellent to hear :). That reminds me I could do a revdepcheck on this branch to stress test it.

----------------------------
mjskay:

this is now on master",FALSE,"refactor,formalism",2021-06-21 03:47:51,2021-12-30 22:49:52,,,CLOSED,2021-12-30 22:49:52,Next release ,,MDU6SXNzdWU5MjU3OTI4NjA=
82,https://github.com/mjskay/ggdist/issues/82,https://github.com/mjskay/ggdist/issues/82,ASKurz,IRT-based ICCs,Would the **ggdist** package be a good place to support  item characteristic curves (ICCs) and item information curves (IICs) from item-response theory (IRT) models? This is related to a recent [thread](https://discourse.mc-stan.org/t/item-characteristic-curves-and-item-information-curves-from-item-response-models/22964) on the Stan forums.,TRUE,"----------------------------
mjskay:

Hmmm not sure. I'm assuming you can generate these from a model and then plot them with geom_line or with a lineribbon (if with uncertainty?). I'm not sure what additional support is needed?

----------------------------
ASKurz:

After dwelling on this, more, you're right. The bulk of the labor is in the data wrangling, not the plotting, itself. Thanks for entertaining the thought.

----------------------------
mjskay:

Of course! Always ",TRUE,help,2021-06-18 22:48:30,2021-06-27 14:00:26,,,CLOSED,2021-06-27 15:37:24,NA,,MDU6SXNzdWU5MjUyNDg4ODM=
81,https://github.com/mjskay/ggdist/issues/81,https://github.com/mjskay/ggdist/issues/81,rcalinjageman,Help or Feature Request: Set fill conditions dynamically,"I'm using ggdist to visualize minimal effect and equivalence tests, setting the fill on a distribution of expected error based on if it is inside or outside of a region of practical equivalence (ROPE).  

When all variables have the same ROPE, this is easy to do and very intuitive (thanks!):

```
rope <- 0.5
...
# Works
fill = stat(x > -rope & x < rope)
...

```

But I was hoping to allow for cases where the rope is set in SD units, and in that case, each test would have a different ROPE.  And there I run into trouble.   Inside stat, the column names in the graph data aren't recognized.  

```
my_data$rope = my_data$se * 0.5
...
# Won't work
fill = stat(x > -rope & x < rope)
...

```

I could pass values into stat manually (x > -my_data$rope), but that's nonsense.  Feels like maybe I need to pass the check to a function, but not sure what I could pass to it that would let me determine what row of data is currently being processed.

I realize this might cross the line from ""feature request"" to ""provide me with help on my pet project""--so feel free to delete or ignore.  


```
# Here is a toy example  of what I'm working on
library(ggplot2)
library(ggdist)
library(distributional)

my_data <- data.frame(
  outcome_variable = c(""SWB"", ""SWB"", ""Self_Esteem"", ""Self_Esteem""),
  effect_size_label = c(""Intervention1 - Control"", ""Intervention2 - Control"",
                         ""Intervention1 - Control"", ""Intervention2 - Control""),
  effect_size = c(0, 1, 1.5, 0.2),
  se = c(0.50, 0.50, 1, 1),
  df = c(50, 50, 50, 50)
)

rope <- 0.3

my_data$rope_upper <- my_data$se * rope
my_data$rope_lower <- -my_data$rope_upper

my_plot <- ggplot2::ggplot(
  data = my_data,
  ggplot2::aes(
    x = effect_size,
    y = effect_size_label
  )
)  + ggplot2::facet_grid(cols = ggplot2::vars(outcome_variable))

my_plot <- my_plot + ggdist::stat_dist_halfeye(
  ggplot2::aes(
    dist = distributional::dist_student_t(
      df = df,
      mu = effect_size,
      sigma = se
    )
    # This fill command works
    , fill = stat(x > -rope & x < rope)
    # But I'd like to have something like
    #, fill = stat(x > rope_upper & x > rope_lower)
  )
)

my_plot
```",TRUE,"----------------------------
mjskay:

It's a really interesting problem, so thanks for posing it! At first I thought there was no easy solution. The problem is that when `stat`s are computed, variables from the original data are mapped onto aesthetic variables (like x, y, color, etc) and the `stat` is computed on those, then the result of that computation creates another data frame which is passed onto the geom. Expressions like `fill = stat(...)` act on that final data frame, and hence cannot directly access any columns of the original data frame (you can read more about this stuff [here](https://ggplot2.tidyverse.org/reference/aes_eval.html)).

**However,** it turns out (I just discovered) you can get around this in some cases (depending on the `stat`) by assigning variables from your input data to fake aesthetics. In most ggdist `stat`s (and in particular the `stat_dist_` ones) these fake aesthetics should survive the transformation pipeline and be passed on to the geom.

So one solution here is to assign your lower/upper bounds to some fake aesthetics (say `l` and `u`) and then use those in your `stat(...)` calculation:

```r
library(ggplot2)
library(ggdist)
library(distributional)

my_data <- data.frame(
  outcome_variable = c(""SWB"", ""SWB"", ""Self_Esteem"", ""Self_Esteem""),
  effect_size_label = c(""Intervention1 - Control"", ""Intervention2 - Control"",
                         ""Intervention1 - Control"", ""Intervention2 - Control""),
  effect_size = c(0, 1, 1.5, 0.2),
  se = c(0.50, 0.50, 1, 1),
  df = c(50, 50, 50, 50)
)

rope <- 0.3

my_data$rope_upper <- my_data$se * rope
my_data$rope_lower <- -my_data$rope_upper

my_plot <- ggplot2::ggplot(
  data = my_data,
  ggplot2::aes(
    x = effect_size,
    y = effect_size_label
  )
)  + ggplot2::facet_grid(cols = ggplot2::vars(outcome_variable))

my_plot <- my_plot + ggdist::stat_dist_halfeye(
  ggplot2::aes(
    dist = distributional::dist_student_t(
      df = df,
      mu = effect_size,
      sigma = se
    ),
    # assign bounds to fake aesthetics (`l` and `u`) so that they are available
    # after the stat has been calculated (for use in the `fill` expression)
    l = rope_lower,
    u = rope_upper,
    fill = stat(x > l & x < u)
  )
)

my_plot
```
```
## Warning message:
## Ignoring unknown aesthetics: l, u 
```
![image](https://user-images.githubusercontent.com/6345019/122614100-9ff9b980-d04b-11eb-8ba1-b6e30e3d7ebc.png)

While it does warn about unknown aesthetics I don't think this should be a problem in this case. You can always wrap the call to `ggdist::stat_dist_halfeye()` in `suppressWarnings()` if you don't want the spurious warning.


----------------------------
mjskay:

Also: lemme know if that helps or if you run into trouble with it. Closing for now otherwise.

----------------------------
rcalinjageman:

Wow!  Thanks.  This will work.  I appreciate the time and the help.  ",TRUE,help,2021-06-18 16:07:47,2021-06-18 22:22:45,,,CLOSED,2021-06-23 12:37:27,NA,,MDU6SXNzdWU5MjUwMzg2OTc=
80,https://github.com/mjskay/ggdist/issues/80,https://github.com/mjskay/ggdist/issues/80,mjskay,get test coverage back up to ~90%,"bunch of changes lately have us down to ~75%, need to get back up to something reasonable before next release",TRUE,"----------------------------
mjskay:

Oh, I guess it's actually at 86% and covr was lying to me. Oh well, still should be better.

----------------------------
mjskay:

coverage now at 97%, that seems good for now",FALSE,cleanup,2021-06-16 15:27:18,2021-06-26 23:44:51,,,CLOSED,2021-06-26 23:44:51,3.0.0,,MDU6SXNzdWU5MjI3NjI4NzQ=
78,https://github.com/mjskay/ggdist/issues/78,https://github.com/mjskay/ggdist/issues/78,mjskay,allow side (and scale?) to be applied as an aesthetic within a geom,"this is basically done now, including testing. just need to:

- [x] add example to slabinterval vignette",TRUE,,FALSE,"enhancement,formalism",2021-06-15 20:56:18,2021-07-07 03:57:14,documentation,,CLOSED,2021-07-07 03:57:14,3.0.0,,MDU6SXNzdWU5MjE3OTI3NTU=
77,https://github.com/mjskay/ggdist/issues/77,https://github.com/mjskay/ggdist/issues/77,mjskay,Factor out dynamic dotplot binning algorithm,"Based on https://github.com/easystats/see/issues/147#issuecomment-860401725

> While that function looks like a beast, it's really just three main steps: (1) determine bin size, (2) calculate data positions using that bin size, (3) create the grobs. Most likely I will end up with a function for (1) and a function for (2); (3) is pretty straightforward on its own. Hopefully you will then be able to use those two functions to make a custom grob easily.

Plan is something like:

- [x] make a `find_dotplot_binwidth()` function that figures out the binwidth
  - ~~[ ] (possibly) make the above more generic (i.e. not make assumptions about graphics environment) and have a convenience function like `find_dotplot_grob_binwidth()` that calls down to the above while figuring out x/y ratios and whatnot from the {grid} environment (on the assumption it is called inside a grob)~~
- [x] make a `bin_dots()` function that does the actual binning given a binwidth
- [x] add examples to docs",TRUE,#NAME?,TRUE,refactor,2021-06-14 18:50:41,2021-06-29 05:26:06,documentation,,CLOSED,2021-06-29 05:26:06,3.0.0,,MDU6SXNzdWU5MjA2ODQ1Nzg=
76,https://github.com/mjskay/ggdist/issues/76,https://github.com/mjskay/ggdist/issues/76,Rishabh261998,Default value of binwidth in geom_dots,Can anyone please tell me how does `geom_dots` calculate the default `binwidth`? I am unable to find it. Thanks ,TRUE,"----------------------------
mjskay:

Given the plot size and the `scale` parameter, ggdist uses binary search to find the number of bins (and corresponding bin width) that will fit into the available space (where `scale = 1` means ""fill up all the space between points on the y axis"" when plotting horizontally). This is a rough sketch of what it does; there are a few other heuristics and corner cases involved (e.g. It has a minimum number of bins determined by some histogram binning alrogithms to try to prevent things from getting too ridiculous looking with a very small number of bins if there's a lot of vertical space available).

Does that help? Did you have a more specific question about it? 

----------------------------
Rishabh261998:

Yes, it helps, just wanted to know how do you find the `binwidth` from the `number of bins` because for Wilkinson's algorithm I am not sure if `binwidth` = range/(`number of bins`) holds or does it?. Also, it would be great if you could provide the file path where this is implemented so that I can go a bit deeper. Thanks

----------------------------
mjskay:

> Yes, it helps, just wanted to know how do you find the binwidth from the number of bins because for Wilkinson's algorithm I am not sure if binwidth = range/(number of bins) holds or does it?

It doesn't quite necessarily, but for the purposes of the dynamic binning algorithm I roughly assume it does. This doesn't make a big difference because I have to run a (modified) Wilkinson binning algorithm to determine max bin height anyway, so really I'm just using number of bins as a discretization of bin width in the search (in fact the search itself is a bastardized binary search because it doesn't require number of bins to be an integer). Probably at some point I should just switch to optimizing binwidth directly, but the current approach has been working well enough (and quickly enough) that I haven't had the motivation to do that.

Your question is a bit serendipitous as I've been meaning to factor out the dynamic binning code to make it easier for others to use (see #77). Unfortunately until I do that the code is a bit tightly coupled with the dotplot drawing code; apologies :). See the [`makeContent.dots_grob()` function](https://github.com/mjskay/ggdist/blob/8818eaf8b9e7d3c267c330171733ba2af8ff260d/R/geom_dotsinterval.R#L33) and particularly [this part](https://github.com/mjskay/ggdist/blob/8818eaf8b9e7d3c267c330171733ba2af8ff260d/R/geom_dotsinterval.R#L109).

----------------------------
Rishabh261998:

Thanks a lot
",TRUE,help,2021-06-14 17:39:58,2021-06-15 19:10:43,,,CLOSED,2021-06-15 19:10:43,NA,,MDU6SXNzdWU5MjA2MzQyNjU=
75,https://github.com/mjskay/ggdist/issues/75,https://github.com/mjskay/ggdist/issues/75,mjskay,allow specification of upper limit on geom_dots binwidth,probably just do it by passing a vector of length 2 to binwidth giving the min and max,TRUE,,FALSE,enhancement,2021-06-14 03:47:19,2021-06-14 05:41:21,,,CLOSED,2021-06-14 05:41:21,NA,,MDU6SXNzdWU5MTk5NzA5MTE=
74,https://github.com/mjskay/ggdist/issues/74,https://github.com/mjskay/ggdist/issues/74,mjskay,geom_dots fails if manually-defined categorical axis limits exclude values,"Example:

```r
palmerpenguins::penguins %>%
  ggplot(aes(x = body_mass_g, y = sex)) +
  ggdist::geom_dots() +
  scale_y_discrete(limits = c(""male"", ""female""))
```",TRUE,,FALSE,bug,2021-06-14 01:57:06,2021-06-14 02:41:53,,,CLOSED,2021-06-14 02:41:53,NA,,MDU6SXNzdWU5MTk5MzgyOTU=
72,https://github.com/mjskay/ggdist/issues/72,https://github.com/mjskay/ggdist/issues/72,thomasp85,Issues with the next version of ggplot2,"Hi Matthew

We are preparing the next ggplot2 release and our reverse dependency tests has showed an issue with ggdist. The issue revolves around a better check of the scale type in `scale_colour_continuous()` and related functions where it is now checked that what comes out of the `type` argument actually matches the aesthetic of the enclosing function. This change means that two of your calls in your unit tests errors:

```r
Error (test.scales.R:67:3): mapping custom aesthetics works
Error: The `type` argument of `scale_colour_discrete()` must return a continuous scale for the colour aesthetic. The provided scale works with the following aesthetics: point_colour
```

and 

```r
Error (test.stat_dist_slabinterval.R:68:3): stat fill aesthetic on halfeye works
Error: The `type` argument of `scale_colour_discrete()` must return a continuous scale for the colour aesthetic. The provided scale works with the following aesthetics: slab_colour
```

We hope to release the next version next week but this issue flew under my radar - let me know if it is possible to prepare a fix by then

best
Thomas",TRUE,"----------------------------
mjskay:

Sure, I'll take a look today or tomorrow and see if I can fix it quick

----------------------------
mjskay:

@thomasp85 thanks for all the help and for putting in the work to check all the zillions of ggplot dependencies, it is really appreciated :)

I think I've got this fixed, I'll submit to cran in the next day or two and post a followup here when it's accepted.


----------------------------
mjskay:

Thanks again Thomas, the fixed version of ggdist is now on CRAN.",TRUE,bug,2021-06-08 09:17:27,2021-06-10 05:29:19,,,CLOSED,2021-06-10 14:00:06,NA,,MDU6SXNzdWU5MTQ2NTk5NDU=
71,https://github.com/mjskay/ggdist/issues/71,https://github.com/mjskay/ggdist/issues/71,arthur-albuquerque,Different set of colors in aes(fill = stat(...)),"Similar to the section ""Highlighting and other combinations"" in https://mjskay.github.io/ggdist/articles/slabinterval.html, I want to use 2 different colours in distributions using stat_halfeye based on a cutoff. 

However, instead of using the same combination of colours in parallel distributions (just like the reference above), I would like to use different combinations. For example, I would use c(""gray85"", ""skyblue"") for the top distribution and c(""gray85"", ""firebrick"") for the bottom one.

Unfortunately, I need to plot both distributions in the same geom. I can't find a way to do what I explained above...

Is it possible to do this using stat_halfeye?

Thanks!",TRUE,"----------------------------
mjskay:

If I understand correctly, there are two ways I can think to solve it: one by constructing the necessary combinations of levels of both variables and then applying a custom color scale, and the other by using the `fill` aesthetic for one variable and ggdist's `fill_ramp` aesthetic for the other.

## First method: combine both variables with `interaction()`

We'll use this data:

```r
library(tidyverse)
library(ggdist)

set.seed(1234)
df = data.frame(
  x = rnorm(1000, c(1, 2), 2),
  y = c(""a"", ""b"")
)
theme_set(theme_ggdist())
```

My first thought was to try something like this:

```r
df %>%
  ggplot(aes(x = x, y = y, fill = stat(interaction(y, x < 0)))) +
  stat_halfeye()
```
![image](https://user-images.githubusercontent.com/6345019/120093530-84e8f900-c0e0-11eb-8fae-99a243b6fe03.png)

This shows how `interaction()` combines the variables. Now we can apply a custom color scale to get the desired output:

```r
df %>%
  ggplot(aes(x = x, y = y, fill = stat(interaction(y, x < 0)))) +
  stat_halfeye() +
  scale_fill_manual(values = c(""gray75"", ""gray75"", ""skyblue"", ""firebrick"")) 
```
![image](https://user-images.githubusercontent.com/6345019/120093695-7ea74c80-c0e1-11eb-8d2c-6779d5c73595.png)

This works, but it kind of brittle --- having to set the values manually this way won't work well if you add more variables to the combinations of levels.

## Second method: use fill_ramp

The other option would be to use `fill_ramp`. Something like this:

```r
df %>%
  ggplot(aes(x = x, y = y, fill = y, fill_ramp = stat(x < 0))) +
  stat_halfeye()
```
![image](https://user-images.githubusercontent.com/6345019/120093609-0ccf0300-c0e1-11eb-898b-afc828930ba0.png)

The default settings for the `fill_ramp` scale on discrete variables ramps to 80% white. But we can ramp to `""gray85""` instead. We can also set your custom colors on the fill scale:

```r
df %>%
  ggplot(aes(x = x, y = y, fill = y, fill_ramp = stat(x < 0))) +
  stat_halfeye() +
  scale_fill_ramp_discrete(from = ""gray85"", range = c(0,1)) +
  scale_fill_manual(values = c(""skyblue"", ""firebrick""))
```
![image](https://user-images.githubusercontent.com/6345019/120093713-8cf56880-c0e1-11eb-8087-544cff54a85e.png)


Does that help?

----------------------------
arthur-albuquerque:

Fantastic. ggdist is such a great package. Congratulations, Matthew. 

Thanks!

----------------------------
mjskay:

Thanks so much! Glad I could help 🙂",TRUE,help,2021-05-29 18:09:02,2021-05-30 18:50:13,,,CLOSED,2021-05-30 18:50:13,NA,,MDU6SXNzdWU5MDY1Mjg3NjI=
70,https://github.com/mjskay/ggdist/issues/70,https://github.com/mjskay/ggdist/issues/70,arthur-albuquerque,Manipulating the thickness of interval bar,"Hi, I notice that whenever I apply 2 widths to stat_halfeye (or any stat_), for example, "".width = c(0.5, 0.95)"", the thickness of the greater interval gets very thin. Is there any way to manipulate this so I can make it thicker? Thank you",TRUE,"----------------------------
mjskay:

Yes, the default aesthetic mappings of those stats include `size = stat(-.width)`, so you can adjust the scaling of the interval widths using `scale_size_continuous()`. The default:

```r
data.frame(x = rnorm(1000)) %>%
  ggplot(aes(x = x, y = ""a"")) +
  stat_halfeye()
```
![image](https://user-images.githubusercontent.com/6345019/118585259-1f9b1c80-b75e-11eb-878f-fde5b2fbf740.png)

An adjusted range (the default value of `range` is `c(1,6)`):

```r
data.frame(x = rnorm(1000)) %>% ggplot(aes(x = x, y = ""a"")) +
  stat_halfeye() +
  scale_size_continuous(range = c(7,15))
```
![image](https://user-images.githubusercontent.com/6345019/118585396-6c7ef300-b75e-11eb-8826-f95c2161b92c.png)


Or if you want to adjust this on a single-geom basis you can use the `interval_size_range` parameter (this parameter is a bit different than above, and has a default value of `c(0.6, 1.4)`):

```r
data.frame(x = rnorm(1000)) %>% 
  ggplot(aes(x = x, y = ""a"")) + 
  stat_halfeye(interval_size_range = c(2,4))
```
![image](https://user-images.githubusercontent.com/6345019/118585544-bd8ee700-b75e-11eb-8fa1-a21b539573a5.png)


----------------------------
arthur-albuquerque:

Excellent. Thank you very much.",TRUE,help,2021-05-17 21:34:30,2021-05-18 03:25:45,,,CLOSED,2021-05-18 10:28:09,NA,,MDU6SXNzdWU4OTM3MzM0OTY=
69,https://github.com/mjskay/ggdist/issues/69,https://github.com/mjskay/ggdist/issues/69,fkgruber,new systems requirement for installation?,"Hi
I tried to update tidybayes (and therefore ggdist) to the latest version and now it gives error related to TCL/TK support
TCL is installed on the systems it seems that R is not compiled with tcl support (by looking at capabilities()). Could this TCL requirement be made optional or something? 

thanks
FKG

```
* installing *source* package  misc3d  ...
** package  misc3d  successfully unpacked and MD5 sums checked
** using staged installation
** R
** data
** demo
** inst
** byte-compile and prepare package for lazy loading
Warning: S3 methods  as.character.tclObj ,  as.character.tclVar ,  as.double.tclObj ,  as.integer.tclObj ,  as.logical.tclObj ,  as.raw.tclObj ,  print.tclObj ,  [[.tclArray ,  [[<-.tclArray ,  $.tclArray ,  $<-.tclArray ,  names.tclArray ,  names<-.tclArray ,  length.tclArray ,  length<-.tclArray ,  tclObj.tclVar ,  tclObj<-.tclVar ,  tclvalue.default ,  tclvalue.tclObj ,  tclvalue.tclVar ,  tclvalue<-.default ,  tclvalue<-.tclVar ,  close.tkProgressBar  were declared in NAMESPACE but not found
Error: .onLoad failed in loadNamespace() for 'tcltk', details:
  call: fun(libname, pkgname)
  error: Tcl/Tk support is not available on this system
Execution halted
```",TRUE,"----------------------------
mjskay:

From the output you have this looks like a problem with the misc3d package, not ggdist? 

----------------------------
fkgruber:

Yes It appears that ggdist is now requiring misc3d. Is this really necessary? Is this just to add interactivity to 3d plots? Seems strange that this is such an important package for ggdist. 
This are the dependencies that  I get:
```
 install.packages(""ggdist"",lib=""~/R/"")
also installing the dependencies  misc3d ,  plot3D ,  hdrcde ,  ks ,  rainbow ,  fds ,  fda 
```

----------------------------
fkgruber:

I did not know ggdist supports 3d plotting. Which functions uses this?

----------------------------
mjskay:

ah it looks like this is a dependency of a dependency of fda, which was a dependency of ggdist in the current cran version. I already moved fda to 'Suggests' in the development version of ggdist awhile back since I decided it is too heavyweight a dependency (it is only there for support for one form of simultaneous interval on curves that isn't even the default). So if you install the ggdist version from github you should be fine.",TRUE,cleanup,2021-05-07 14:33:55,2021-05-07 15:13:42,,,CLOSED,2021-05-07 15:13:42,NA,,MDU6SXNzdWU4NzkxMTczNjY=
68,https://github.com/mjskay/ggdist/issues/68,https://github.com/mjskay/ggdist/issues/68,bwiernik,"Unexpected behavior with alpha and fill=""transparent""","I am getting some weird behavior with `stat_slab()` when I include both `fill = ""transparent""` and `alpha` parameters.

It seems to set the fill to white then apply the alpha level to that fill, causing multiple stacked layers to effectively have a solid white fill). I get the expected behavior (a transparent fill) if I either omit `alpha` or set `fill = NA`.

Compare:
```r
library(ggplot2)
library(dplyr)
library(tidyr)
library(purrr)
library(ggdist)
library(palmerpenguins)

boots <- rsample::bootstraps(penguins, times = 100, strata = ""species"")
penguins %>% 
	drop_na(c(species, bill_length_mm)) %>% 
	ggplot() +
	aes(y = factor(species), x = bill_length_mm, color = species) +
	map(boots$splits,
			~ stat_slab(
				data = drop_na(as.data.frame(.x), c(species, bill_length_mm)),
				size = .2,
				alpha = .2,
				fill = ""transparent"")
	) +
	stat_slab(fill = ""transparent"") +
	geom_jitter(shape = 1, width = 0, height = .1) +
	labs(y = """", x = ""Bill length (mm)"", 
			 title = ""Bill length by species for Palmer's penguins"",
			 caption = ""Thick lines are estimated density for original data. Thin lines are densities for 100 stratified bootstrap resamples."") +
	guides(color = ""none"") +
	theme_minimal() +
	theme(plot.title.position = ""plot"")
```

with:
```r
library(ggplot2)
library(dplyr)
library(tidyr)
library(purrr)
library(ggdist)
library(palmerpenguins)

boots <- rsample::bootstraps(penguins, times = 100, strata = ""species"")
penguins %>% 
	drop_na(c(species, bill_length_mm)) %>% 
	ggplot() +
	aes(y = factor(species), x = bill_length_mm, color = species) +
	map(boots$splits,
			~ stat_slab(
				data = drop_na(as.data.frame(.x), c(species, bill_length_mm)),
				size = .2,
				alpha = .2,
				fill = NA)
	) +
	stat_slab(fill = ""transparent"") +
	geom_jitter(shape = 1, width = 0, height = .1) +
	labs(y = """", x = ""Bill length (mm)"", 
			 title = ""Bill length by species for Palmer's penguins"",
			 caption = ""Thick lines are estimated density for original data. Thin lines are densities for 100 stratified bootstrap resamples."") +
	guides(color = ""none"") +
	theme_minimal() +
	theme(plot.title.position = ""plot"")
```

or:
```r
library(ggplot2)
library(dplyr)
library(tidyr)
library(purrr)
library(ggdist)
library(palmerpenguins)

boots <- rsample::bootstraps(penguins, times = 100, strata = ""species"")
penguins %>% 
	drop_na(c(species, bill_length_mm)) %>% 
	ggplot() +
	aes(y = factor(species), x = bill_length_mm, color = species) +
	map(boots$splits,
			~ stat_slab(
				data = drop_na(as.data.frame(.x), c(species, bill_length_mm)),
				size = .2,
				# alpha = .2,
				fill = ""transparent"")
	) +
	stat_slab(fill = ""transparent"") +
	geom_jitter(shape = 1, width = 0, height = .1) +
	labs(y = """", x = ""Bill length (mm)"", 
			 title = ""Bill length by species for Palmer's penguins"",
			 caption = ""Thick lines are estimated density for original data. Thin lines are densities for 100 stratified bootstrap resamples."") +
	guides(color = ""none"") +
	theme_minimal() +
	theme(plot.title.position = ""plot"")
```
",TRUE,"----------------------------
mjskay:

Yeah I agree this is unexpected and weird at first glance. However, according to the typical ggplot semantics for fill and alpha aesthetics as I understand them, it is the correct behavior. What you see is due to two things interacting with each other:

1. The `""transparent""` color is defined as white with 0 alpha:

    ```r
    col2rgb(""transparent"", alpha = TRUE)
    ```
    ```
          [,1]
    red    255
    green  255
    blue   255
    alpha    0
    ```
2. The alpha aesthetic is essentially an ""override"" for the alpha channel of the fill aesthetic. When the alpha aesthetic is not set / is `NA`, the alpha channel is left alone, otherwise the alpha channel is simply replaced with whatever value the alpha aesthetic has.

These behaviors are the same in base ggplot geoms, e.g. with `geom_rect()`:

```r
library(ggplot2)
library(dplyr)

data.frame(x = 1:4) %>%
  ggplot(aes(x = x, y = 1, width = 3, height = 3)) +
  geom_tile(fill = ""transparent"", alpha = 0.5) +
  theme_grey()
```

![image](https://user-images.githubusercontent.com/6345019/116962608-0d07ea00-ac6c-11eb-86c5-95e668e471ca.png)

Thus, I would think of the semantics of `""transparent""` as something like ""transparent white"" and not ""no fill"". The value to set for ""no fill"" is, as in your second example, `NA`. For this reason I would pretty much always use `NA` in preference to `""transparent""`.

Anyway I totally agree that this is not intuitive, it took me awhile to figure out what was supposed to happen in cases like this (actually to solve a previous bug you reported about alpha not working correctly :) )


----------------------------
bwiernik:

Ah, I was misremembering what the behavior of base geoms was. Thanks!",TRUE,help,2021-05-03 20:10:42,2021-05-04 05:06:36,,,CLOSED,2021-05-04 13:41:37,NA,,MDU6SXNzdWU4NzQ4NzI0NzM=
67,https://github.com/mjskay/ggdist/issues/67,https://github.com/mjskay/ggdist/issues/67,mjskay,post-process curve_interval to narrow intervals until they are nominal,Consider post-processing the simultaneous intervals by ordering draws by depth then using binary search to find a subset that makes the final coverage nominal. Might fix the problem of intervals that are too wide,TRUE,,FALSE,enhancement,2021-04-17 02:16:15,2021-07-07 04:19:30,,,CLOSED,2021-07-07 04:19:30,3.0.0,mjskay,MDU6SXNzdWU4NjAzMDEyNjU=
66,https://github.com/mjskay/ggdist/issues/66,https://github.com/mjskay/ggdist/issues/66,Ari04T,Scale fill ramp override aes,"Is there a way to manually control the colors for the colour/fill ramp discrete legend? Right now, if I try to override them manually, I do not get the same colour 3 times but instead I get the following.
```
scale_fill_ramp_discrete(range = c(1, 0.2), na.translate = FALSE) +    
guides(
        fill_ramp = guide_legend(override.aes = list(fill = c(""red"",
                                                              ""red"",
                                                              ""red"")))
    ) 
```
![image](https://user-images.githubusercontent.com/7259598/114292990-85f69600-9a60-11eb-98d6-050fcc71966a.png)
",TRUE,"----------------------------
mjskay:

Ah, that's because the fill_ramp aesthetic is what the legend is showing, so the color ramp (from red to white) is being applied to the legend. If you just override the fill aesthetic the fill_ramp is still applied.

What was the output you were looking for?

----------------------------
Ari04T:

Makes sense. I am happy with the way the color ramp looks on the plot with the current parameters (range 1, 0.2), but the legend with the default format is a little bit to faint, especially for the 95% interval. As you can see, I use a grey background so the original 95% fill basically blends with the background. I just wanted to manually adjust that key fill to make it a bit more visible. 

----------------------------
mjskay:

Ah makes sense. Is the plot background also gray? Assuming this is the ggplot default (`theme_gray()`), I'd first start by changing the base blend color in the color ramp to `""gray92""` (the background color of that theme) so that the colors are being blended with the background gray instead of white. I played around a bit with that, the range, and changing the foreground to a red from  [colorbrewer](https://colorbrewer2.org/#type=sequential&scheme=BuGn&n=3) and came up with this:

```r
dist_df = tibble(
  group = c(""a"",""b"",""c""),
  mean = 1:3,
  sd = 1
)
dist_df %>%
  ggplot(aes(x = group, dist = dist_normal(mean, sd))) +
  stat_dist_interval(aes(color_ramp = stat(level)), color = ""#de2d26"") +
  scale_color_ramp_discrete(from = ""gray92"", range = c(0.3,1)) +
  theme_gray()
```
![image](https://user-images.githubusercontent.com/6345019/114332291-8e57db00-9b0b-11eb-85e1-15b81f4dca7d.png)

it could probably be tweaked still, but does something in that direction help?

----------------------------
mjskay:

Hope this helped! Closing this for now but let me know if you have any issues.",TRUE,help,2021-04-11 04:55:11,2021-04-17 02:16:44,,,CLOSED,2021-04-17 02:16:45,NA,,MDU6SXNzdWU4NTUyMTg0Nzg=
65,https://github.com/mjskay/ggdist/issues/65,https://github.com/mjskay/ggdist/issues/65,a-hurst,Deprecation warning for inferred ymin/ymax in geom_pointinterval?,"Hi there,

I just updated tidybayes along with a few other packages and was very surprised to find that `geom_pointinterval` layers were no longer getting added to my plots. After a bunch of trial and error and digging through issues on this repository + the tidybayes repository, I eventually found the release notes explaining that ymin/ymax are no longer inferred automatically when the input data has `.lower` and `.upper` columns. Anyway, to save future users a similar 20-30 minutes of confusion, would you consider adding a brief informative error or warning to the function when ymin and ymax aren't specified?

Thanks in advance!

P.S. Also, thank you so much for this package and for tidybayes. Together with brms, they've made my life massively easier!

",TRUE,"----------------------------
mjskay:

Good point, that's my bad --- I've certainly been there before with changes in other packages :). I'll have to think about what the logic of that should be to prevent false positives. ",TRUE,docs,2021-03-30 21:41:06,2022-01-16 18:05:25,documentation,,CLOSED,2022-01-16 18:05:25,Next release ,,MDU6SXNzdWU4NDUzMTczMDI=
64,https://github.com/mjskay/ggdist/issues/64,https://github.com/mjskay/ggdist/issues/64,mjskay,Geom_dots with exact x position ,"Could do tournament-style selection of points in each stack, ~~alternating whether the points with the largest distance from bin center start at the top or bottom of each stack~~

- [x] basic implementation
- [x] nudging to prevent overlaps
  - [x] in dotplot layout
  - ~~[ ] when `side = ""both""` (not sure if this is easily doable, might skip)~~
- [x] tests
- [x] add examples to slabinterval vignette
  - [x] cutoffs with color where classic binning can have problems
- [x] look at adding other layouts?
  - [x] https://observablehq.com/@jtrim-ons/compact-beeswarm-plot
  - ~~[ ] https://www.linkedin.com/pulse/pursuit-diversity-data-visualization-jittering-access-daniel-zvinca/~~",TRUE,"----------------------------
jtrim-ons:

It's really nice that you're considering adding the compact beeswarm!

I thought it might be worth mentioning that Aron Eklund might include it in the beeswarm package at some point (see this [issue](https://github.com/aroneklund/beeswarm/issues/9)), so one option might be to depend on a future version of that package.

And just in case it might be interesting to see, I've very quickly attempted a [piled plot implementation in JavaScript](https://observablehq.com/@jtrim-ons/piled-plot).

----------------------------
mjskay:

Cool! Yeah, if that implementation is put in a self-contained function exported from that package I may use it that way. Otherwise I might take a look at that implementation and adapt it within this package (with your permission of course). Sometimes depending on how things are written (and how much additional dependency baggage I want --- I've been trying to reduce deps for ggdist) that works better.

I'll probably wait on the resolution of that issue to decide what to do.

----------------------------
jtrim-ons:

Thanks for adding the beeswarm!

I was wondering if it would be useful to add a minimum required `beeswarm` version to the DESCRIPTION, as the `compact` option is only available from version 0.4.0? I'm not very experienced with R package versions, so I guess there might be a downside to this that I've overlooked. I'll open a PR just in case it's helpful. ",TRUE,enhancement,2021-03-27 06:09:40,2021-06-10 05:29:19,,,CLOSED,2021-06-10 10:30:59,NA,,MDU6SXNzdWU4NDI0MjgyODI=
63,https://github.com/mjskay/ggdist/issues/63,https://github.com/mjskay/ggdist/issues/63,mjskay,Make a dots_mcse geom and/or mcse histogram geom,"Would need to be on a separate branch or maybe even separate package for now, but idea would be: use ggfx to make a horizontal blur with SD = MCSE on each dot in a quantile dotplot

Amother option might be an oblong shape or even interval kind of thing around the dot. ",FALSE,"----------------------------
mjskay:

see also this stuff, including histogram ideas: https://github.com/mjskay/uncertainty-examples/blob/master/mcse_dotplots.md

----------------------------
bwiernik:

You thinking a separate branch to avoid the ggfx dependency? Could do that in Suggests?

----------------------------
mjskay:

I had a separate branch where I was playing with a ggfx approach but it turned out not to really do what I wanted as easily as I thought it would and I abandoned that. 

The examples I tried on Twitter just overlaid a bunch of dotplots, which was fine as a quick demo but isn't really a good longterm solution since the blurring really should be happening at a dot level after the layout algorithm runs (you can see in the demo this occasionally causes issues of ghost dots due to the layout resulting in an ever so slightly different binning on occasion) 

I think a better way might be to use the new gradient support in R 4.1 to construct a blurred shape of some kind, probably as a separate grob and geom from the main dots geom (or a particular option) since it wouldn't work with arbitrary shapes. 

Anyway if someone want to play with this on a branch I'd be happy to entertain it! 
",FALSE,enhancement,2021-03-27 06:06:49,NA,,,OPEN,2021-07-29 00:46:11,NA,,MDU6SXNzdWU4NDI0Mjc4Nzg=
62,https://github.com/mjskay/ggdist/issues/62,https://github.com/mjskay/ggdist/issues/62,bwiernik,"`fill = after_scale(alpha(color, .5))` not working with slab fills","I'm trying to use `after_scale()` with `alpha()` to adjust the transparency of slab fills, but it's not working for any of the slab geoms. cf. that it works as expected for `geom_boxplot()`.

```r
library(ggplot2)
library(dplyr)
library(tidyr)
library(palmerpenguins)

set.seed(123)
penguins %>%  
	drop_na(c(species, bill_depth_mm)) %>% 
	ggplot() +
	geom_boxplot(
		aes(x = bill_depth_mm,
				y = species,
				color = species, 
				fill = after_scale(alpha(color, .5))),
		width = .3
	) +
	ggdist::stat_slab(
		aes(x = bill_depth_mm,
				y = species,
				color = species, 
				fill = after_scale(alpha(color, .3))),
		height = .2, 
		position = position_nudge(y = .2)
	) 
```

Also note that functions that adjust the fill color, rather than transparency do work (e.g., `colorspace::darken()` and `colorspace::lighten()`, but `colorspace::adjust_transparency()` does not.
",TRUE,#NAME?,TRUE,bug,2021-03-22 23:44:07,2021-03-23 02:18:27,,,CLOSED,2021-03-23 02:19:06,NA,,MDU6SXNzdWU4MzgxOTEzOTE=
61,https://github.com/mjskay/ggdist/issues/61,https://github.com/mjskay/ggdist/issues/61,xf15,support for https://ggplot2.tidyverse.org/reference/expansion.html or https://erocoar.github.io/gghalves/,"I want to plot both model prediction and actual data like 
![image](https://user-images.githubusercontent.com/29473163/112068040-54a43d80-8b26-11eb-8591-28d64497e3b4.png)
but as you see the eyes overlap 

i added expansion function that i have tested to work with ggplot, but it doesn't work here

wouldn't be a problem with gghalves but they don't have eye plot ",TRUE,"----------------------------
xf15:

this is the effect i want in case i didn't make it clear 
https://stackoverflow.com/questions/39195748/how-to-change-the-distance-between-categorical-ticks-in-ggplot2


----------------------------
mjskay:

Ah, if I understand correctly you might be looking for the `scale` argument to the stats/geoms in ggdist. If you set it to 0.5 (or less) the two slabs should not overlap. I recently added an example of this here: https://mjskay.github.io/ggdist/articles/slabinterval.html#multiple-slabs-and-intervals-in-composite-plots-1

Let me know if that helps!

----------------------------
xf15:

yes that's it! i should have scrolled to the bottom... thank you!

----------------------------
mjskay:

No prob, happy to help! ",TRUE,help,2021-03-22 22:54:07,2021-03-23 22:09:45,,,CLOSED,2021-03-24 02:02:21,NA,,MDU6SXNzdWU4MzgxNjc4MTg=
60,https://github.com/mjskay/ggdist/issues/60,https://github.com/mjskay/ggdist/issues/60,mjskay,Make sure scale transformations on dists work even if some limits end up being infinite,"E.g. this example using inv_logit should be able to work without setting `limits = c(-10, 10)`, but currently doesn't:

```r
library(ggplot2)
library(dplyr)
library(distributional)
library(ggdist)

inv_logit = scales::trans_new(""inv_logit"", plogis, qlogis)

tibble(x = dist_logistic(-2, 0.6)) %>%
  ggplot(aes(dist = x, y = """")) + 
  stat_dist_slab() + 
  scale_x_continuous(
    # need to provide finite limits on logit scale
    trans = inv_logit, limits = c(-10, 10),
    breaks = qlogis(0:10/10), labels = plogis
  ) +
  coord_cartesian(expand = FALSE) +
  labs(x = ""inv_logit(x)"", y = NULL) +
  theme_ggdist()
```
![image](https://user-images.githubusercontent.com/6345019/110270855-62858a80-7f8c-11eb-9dde-f35bca3b4e34.png)
",TRUE,"----------------------------
mjskay:

This appears to be fine so long as functions that you can take symbolic derivatives of are used (previous example doesn't because plogis / qlogis have C implementations so aren't define in terms of functions that are in the derivatives table). E.g. this works fine:

```r
library(ggplot2)
library(dplyr)
library(distributional)
library(ggdist)

inv_logit = scales::trans_new(""inv_logit"", function(x) 1 / (exp(-x) + 1), function(x) log(x) - log1p(-x))

tibble(x = dist_logistic(-2, 0.6)) %>%
  ggplot(aes(dist = x, y = """")) + 
  stat_dist_slab() + 
  scale_x_continuous(
    # need to provide finite limits on logit scale
    trans = inv_logit, limits = c(-Inf, 10),
    breaks = qlogis(0:10/10), labels = plogis
  ) +
  coord_cartesian(expand = FALSE) +
  labs(x = ""inv_logit(x)"", y = NULL) +
  theme_ggdist()
```
![image](https://user-images.githubusercontent.com/6345019/121764610-e068ad00-cb0a-11eb-81a9-cbba49120fad.png)

I did add a slight improvement that handles more functions if the Deriv package is installed since its symbolic differentiation can work on functions and not just single expressions.",FALSE,bug,2021-03-08 03:32:04,2021-06-12 04:16:00,,,CLOSED,2021-06-12 04:16:00,NA,,MDU6SXNzdWU4MjQxMzA4OTU=
59,https://github.com/mjskay/ggdist/issues/59,https://github.com/mjskay/ggdist/issues/59,mjskay,Allow use of .width in slabs and slab functions in intervals,"Basically, it would be useful to be able to use calculated variables from opposite parts of the geom to do stuff like highlight intervals or whatnot. 

- [x] allow use of interval stuff (e.g. `.width` and `level`) in slabs and dots
  - [x] add tests
  - [ ] follow up on #139
- [ ] allow use of slab functions (pdf, cdf) in dots
- [x] basic version of allowing slab functions in intervals (needs to be more efficient and reliable). In the future:
  - [ ] enable this by default and remove option `""ggdist.experimental.slab_data_in_intervals""` and any mention in the docs.
  - [ ] make it not require interpolating the functions again (probably have to keep things around as distributional objects; but that also requires distribution transformation in distributional to be more reliable, which probably means waiting on changes in scales and support for analytical transformations and inverses etc...)
    - [ ] with this, need to make sure histograms are computed correctly (check points on upslope / downslope)
    - [ ] relatedly, update how stat_spike works so that it can match pdf function values on a histogram. currently this works b/c of ties = ""ordered"" in approx_pdf; need to ensure that stays the same.
  - [ ] add tests",FALSE,,FALSE,"enhancement,formalism",2021-02-23 16:34:11,NA,,,OPEN,2023-01-30 05:04:41,NA,,MDU6SXNzdWU4MTQ2Mjg4NjY=
58,https://github.com/mjskay/ggdist/issues/58,https://github.com/mjskay/ggdist/issues/58,mjskay,Add easy way to do vertical annotations on slabs: geom_spike,"Add a geom that displays spikes at thickness values instead of filled areas.

~~One way is probably a stat/geom combo for annotations that does all the work to do thickness related scaling correctly but uses users provided x values (instead of determining x from the densities). Might also need one that allows point estimates or quantiles as provided values (although that's basically the interval stat... So maybe that old idea of also calculating function values at point/interval locations is enough for that use case - #59).~~ stat version is now #124.",TRUE,,FALSE,enhancement,2021-02-23 14:53:36,2023-01-28 05:21:20,,,CLOSED,2023-01-28 05:21:20,NA,,MDU6SXNzdWU4MTQ1MzkwODU=
57,https://github.com/mjskay/ggdist/issues/57,https://github.com/mjskay/ggdist/issues/57,Famondir,Mode returned negative value for all positive vector,"Hi,
I got an interesting issue today with the Mode() function. I had a large double vector (10 million numbers) as input. It hold MCMC draws for odds ratios and thus where all >= 0. Any value was unique. Mode() then returned a negative value. This one resulted from the density() function and was the first value in density(z)$x. 

Using the tabulate(z) function will give you the first number which was not in the HDI but nevertheless at least positive.

I came up with this approach to get a value that seems to be drawn more often (approximately):
`get_mode <- function(v, signs = 23) {
  uniqv <- unique(v)
  tab <- tabulate(match(v, uniqv))

  if(max(tab) == 1 & is.numeric(v)) {
    if (signs == 23) message(paste0('There was a draw. There were ', sum(tab[tab == max(tab)]), ' modes.'))

    v <- signif(v, signs-1)

    return(get_mode(v, signs-1))
  } else {
    modus <- uniqv[which.max(tab)]
    if (signs != 23) message(paste0('No draws taking into account ', signs, ' signs.'))
  }

  return(modus)
}`

I don't know if this is something Mode() should do by default. Another way would be throw an error or print a message that the count of the value is only 1 and thus there was a draw.",TRUE,"----------------------------
mjskay:

Hmm, sounds problematic... could you create a [reprex](https://www.tidyverse.org/help/) with example data showing the problem? That would help me diagnose it.

Thanks!

----------------------------
Famondir:

I was able to sample a much smaller double vector that reproduces the behavior:
`c(8104.6708071, 2.1980919, 0.7569663, 6.2002883, 3.2318454, 2.5476119, 1.3982123, 2.9978539, 1.3471747, 2.2059935)`

Seems like occurence of some big numbers can result in a negative density() entry.

----------------------------
mjskay:

Ah I see what's happening. Some things have conspired to create problems: the mode estimator for a continuous variable we are using uses a kernel density estimator, which currently does not cut off at the bounds of the data (even though it should). That's an easy fix that will prevent negative numbers in this case.

That said, for your data it still doesn't give a great estimate of the mode. The reason is because for the density estimator we still need to pick a grid size, and given the range of your data, the default grid size is not good (in fact you don't get a good estimate of the mode on your data until the grid size is on the order of 30,000 points, which is a little ridiculous). I'm not inclined to change those defaults unless someone who knows a lot about mode estimation comes along and suggests a good general-purpose mode estimator. The [modeest](https://cran.r-project.org/package=modeest) package has a bunch but seemingly little guidance on their selection. My guess is their applicability depends on your data, which makes it hard to pick a generic one.

So:
- I've updated `Mode()` to at least use trimmed densities, which should solve the problem of getting numbers outside the range of the data. You will have to install the latest version from github to use it: `devtools::install_github(""mjskay/ggdist"")`. However the mode estimate in your case is still not great:

```r
library(ggdist)

x = c(8104.6708071, 2.1980919, 0.7569663, 6.2002883, 3.2318454, 2.5476119, 1.3982123, 2.9978539, 1.3471747, 2.2059935)

Mode(x)
## [1] 0.7569663
```


- I'd recommend looking at mode estimators in {modeest} to see if some of those serve your needs better. If you are using `mode_hdi()` currently you can define your own `point_interval` function that uses a different mode estimator by doing something like this:

```r
library(ggdist)
library(modeest)

x = c(8104.6708071, 2.1980919, 0.7569663, 6.2002883, 3.2318454, 2.5476119, 1.3982123, 2.9978539, 1.3471747, 2.2059935)

# define a point_interval function using the hsm (half sample mode) estimator from modeest
hsm_hdi = function(...) point_interval(..., .point = hsm, .interval = hdi)

hsm_hdi(x, .width = 0.66)
##          y     ymin     ymax .width .point .interval
## 1 2.202043 1.347175 3.231845   0.66    hsm       hdi
```

Hope that helps!

----------------------------
Famondir:

Thanks a lot. I'll definitly have a look at that package and look for the most fitting function there. I'm curius if some of them behave like my own function and how they are implemented. At the first glance hsm returns a similar value (.841 and .868 in the 10M vector and 2.202 and 2.2 in the short example above) as my approach (but much much faster xD).

I think the truncation is a good thing to prevent most unforseen issues. Totally agree that some research on mode implementation would be good instead of just hacking some naive approach. Big thanks for the hint how to define a custom point_interval. Great and fast support!

----------------------------
Famondir:

The hsm seems to fit best for my data structure and my understandings on how a mode function should work. Thanks again. :)

----------------------------
mjskay:

You're welcome, glad I could help! ",TRUE,bug,2021-02-15 18:40:41,2021-02-16 08:44:30,,,CLOSED,2021-02-16 15:38:23,NA,,MDU6SXNzdWU4MDg3NDg5MDE=
56,https://github.com/mjskay/ggdist/issues/56,https://github.com/mjskay/ggdist/issues/56,mjskay,various minor fixes for dist / rvar support,"- [x] can use vectorized density / cdf / quantile if applied to dist_ objects directly
- [x] ensure dist_sample objects work (should be solved by previous fix)
- [x] ensure constant dist_sample and rvar objects work (including constants with 1 sample and with more than 1 sample). Easiest fix might be to use the cdf and density code from stat_sample for those.",TRUE,,FALSE,bug,2021-02-13 22:12:30,2021-07-07 03:34:18,,,CLOSED,2021-07-07 03:34:18,3.0.0,,MDU6SXNzdWU4MDc4Mzk0Nzk=
55,https://github.com/mjskay/ggdist/issues/55,https://github.com/mjskay/ggdist/issues/55,ASKurz,dots when distributions are constants,"Consider the following.

```{r}
# load
library(tidyverse)

# simulate
set.seed(1)

data.frame(a = 0,
           b = rnorm(1e4)) %>% 
  pivot_longer(everything()) %>% 
  
  # plot
  ggplot(aes(x = value)) +
  geom_density() +
  facet_wrap(~ name)
```
<img width=""819"" alt=""Screen Shot 2021-02-11 at 2 08 59 PM"" src=""https://user-images.githubusercontent.com/19917004/107692663-b98c8e00-6c72-11eb-9491-2790f73d722e.png"">

Even though the values in the plot for `a` are all at the constant 0, we get a density. Back in the day (at least at version 2.2.1), **tidybayes** (also **ggdist**) would return somewhat similar results with the following.

```{r}
data.frame(a = 0,
           b = rnorm(1e4)) %>% 
  pivot_longer(everything()) %>% 
  
  ggplot(aes(x = value, y = name)) +
  stat_halfeye()
```

Here you'd get a density, along with dot and intervals for `b` and `a` would just be summarized as a dot. You can find a couple examples of this behavior [here](https://bookdown.org/content/3686/ordinal-predicted-variable.html#examples-not-funny.). Now when I try this, I get the error: ""Computation failed in `stat_sample_slabinterval()`: need at least two non-NA values to interpolate"". Is there a way to recapture the old behavior?



",TRUE,#NAME?,TRUE,bug,2021-02-11 20:16:28,2021-02-11 22:42:10,,,CLOSED,2021-02-11 22:57:29,NA,,MDU6SXNzdWU4MDY3MDgxODg=
54,https://github.com/mjskay/ggdist/issues/54,https://github.com/mjskay/ggdist/issues/54,gdbassett,stats_dots does not reverse when using scale_y_reverse(),"scale_y_reverse() does not turn the dot plot upside down.  This is a minor issue, but may be useful for comparing two dot plots, one above the axis and one below.

```
tibble(x=runif(1000)) %>%
  ggplot() +
      ggdist::stat_dots(aes(x=x)) +
      scale_y_reverse()
```

Expected: dots below y axis
Actual: dots above the y axis",TRUE,"----------------------------
mjskay:

Ah interesting... I think this is actually consistent with the semantics of dotplots, which is that they ignore all y axis transformations / scaling (when laid out horizontally). E.g. if you did a log scale transformation you should still see the dots laid out with equal spacing.

If you want dots to hang down, try using `stat_dots(side = ""bottom"")`. Does that work for your use case?

----------------------------
gdbassett:

Ah, that will work.  Apologize for not reading up on the 'side' parameter first.

----------------------------
mjskay:

No worries! The parameter docs aren't the best currently and there's lots of them ",TRUE,help,2021-01-28 17:43:04,2021-01-28 19:18:04,,,CLOSED,2021-01-28 19:22:56,NA,,MDU6SXNzdWU3OTYyMTY4NzM=
53,https://github.com/mjskay/ggdist/issues/53,https://github.com/mjskay/ggdist/issues/53,mjskay,allow binwidth in geom_dots to use unit(),"In some cases it may be useful to set the binwidth manually using `grid::unit()`. 

e.g. say we had facets with free scales:

```r
mtcars %>%
  ggplot(aes(x = mpg)) + 
  geom_dots() +
  facet_grid(~ am, scales = ""free"")
```
![image](https://user-images.githubusercontent.com/6345019/105946236-7dc7b680-602c-11eb-8049-8c841ab85f85.png)

and we wanted the dots to be visually the same size even if the scales across facets are different.

This should be possible with geom_dots (unlike most geoms) because binning is not applied to the data until the grob is drawn, so we can convert from viewport units to data units at that point if the user manually specifies a binwidth using `unit()`.

e.g. with the above example we would want people to be able to do something like this (**currently does not work**):

```r
mtcars %>%
  ggplot(aes(x = mpg)) + 
  geom_dots(binwidth = unit(0.1, ""npc"")) +
  facet_grid(~ am, scales = ""free"")
```

Which should make the bins 10% of the width of the facet.",TRUE,"----------------------------
mjskay:

Hmm this was a quicker fix than I thought. Should work on the dev branch now:

```r
mtcars %>%
  ggplot(aes(x = mpg)) + 
  geom_dots(binwidth = unit(0.1, ""npc"")) +
  facet_grid(~ am, scales = ""free"")
```
![image](https://user-images.githubusercontent.com/6345019/105948762-2aa43280-6031-11eb-94f3-c4eab3fb131f.png)
",FALSE,enhancement,2021-01-27 05:19:57,2021-01-27 05:58:41,,,CLOSED,2021-01-27 05:58:41,NA,,MDU6SXNzdWU3OTQ3ODA3NjI=
52,https://github.com/mjskay/ggdist/issues/52,https://github.com/mjskay/ggdist/issues/52,bearloga,stat_dist_slab CDF of a log-normal doesn't reach 1.0 ,"Hiya! Love this package and really appreciate all the work you've put into it. So thank you very much for it, Matthew!

While working with @Dpananos on a project, we came across an peculiar behavior. I'm not sure if it's something we're missing on our end or if it's a bug with {ggdist} (or maybe everything is working as intended and this is just an interesting edge case), but we're plotting CDF of lognormal with `stat_dist_slab()`:

``` r
library(ggplot2)
library(ggdist)
library(distributional)
library(tidyverse)

example <- tibble(
    mu = c(8.1, 7.9),
    sigma = c(1.95, 2.05)
)
ggplot(aes(y = 0, color = ""mcmc draw""), data = example) +
    geom_hline(yintercept = plnorm(1e6, 8, 2), linetype = ""dashed"") +
    stat_dist_slab(
        aes(dist = ""lnorm"", arg1 = mu, arg2 = sigma),
        fill = NA, slab_type = ""cdf"", limits = c(0, 1e6),
    ) +
    stat_dist_slab(
        aes(dist = ""lnorm"", arg1 = 8, arg2 = 2),
        fill = NA, slab_type = ""cdf"", color = ""red"", data = NULL
    ) +
    scale_color_manual(
        name = NULL, values = c(""mcmc draw"" = ""black""), guide = FALSE
    ) +
    scale_x_log10(breaks = 10 ^ (0:6)) +
    scale_y_continuous(breaks = seq(0, 1, 0.05), minor_breaks = NULL)
```

and the slab curves at x=1e6 don't reach up to where they should:

![cdf](https://user-images.githubusercontent.com/1807519/105737499-0565d600-5f04-11eb-8a25-f62097381bd6.png)

Weird, right?",TRUE,"----------------------------
mjskay:

Ah yup, this is due to a bit of a conflict in expected use cases for the slabinterval geometries. The short answer is you need to set `scale = 1`.

The long answer is, the defaults were really designed for the style of plots where you might want multiple slab associated with different factors on the y axis (say). The result is the need for a gap between the ""slabs"" so they don't touch, and this is handled by the `scale` parameter, the default of which is `0.9`. 

Because the original use cases I envisioned for slabs don't typically involve the numerical axis labels, this hasn't been a huge issue, but it's clear that I need some clarity in the documentation and some examples cover use cases like yours.

----------------------------
bearloga:

Ah! Thank you so much for the explanation @mjskay!

----------------------------
mjskay:

you're welcome!

----------------------------
mjskay:

I believe this should be clarified by the height/scale diagram that will be at the top of the slabinterval vignette in the next release, so closing this now.",TRUE,help,2021-01-25 16:59:19,2022-01-16 17:51:43,documentation,,CLOSED,2022-01-16 17:51:43,Next release ,,MDU6SXNzdWU3OTM1NTM5NTE=
51,https://github.com/mjskay/ggdist/issues/51,https://github.com/mjskay/ggdist/issues/51,gdbassett,na.rm appears not to propagate to the transform in stat_dots,"```
chunk %>%
    filter(!is.na(tdiff)) %>%
    mutate(tdiff = if_else(tdiff == 0, 1, tdiff)) %>%
  ggplot() + 
    ggdist::stat_dots(aes(x=tdiff, y=0), quantiles=100,
                      na.rm=TRUE
    ) +
    scale_x_log10() +
    NULL
```

results in the error:
```
Warning message in self$trans$transform(x):
“NaNs produced”
Warning message:
“Transformation introduced infinite values in continuous x-axis”
```

It appears as if the `na.rm=TRUE` is not getting correctly propagated to the transform.  The error doesn't occur when either `quantiles` is not set or `scale_x_log10()` is not used.",TRUE,"----------------------------
gdbassett:

I've found I also run into what appears to be a similar issue setting limits on the x scale:
```
Warning message:
“Computation failed in `stat_dots()`:
missing values and NaN's not allowed if 'na.rm' is FALSE”
Warning message in rep(yes, length.out = len):
“'x' is NULL so the result will be NULL”
ERROR while rich displaying an object: Error in ans[ypos] <- rep(yes, length.out = len)[ypos]: replacement has length zero
```

----------------------------
mjskay:

@gdbassett this should be fixed now (sadly not on the cran version; I didn't get to it in time, but will be in the next release!)

thanks again for all the feedback!

----------------------------
gdbassett:

You're welcome.  Thank you for fixing it!

Gabe",TRUE,bug,2021-01-20 22:23:23,2021-06-11 05:48:09,,,CLOSED,2021-06-11 18:16:47,NA,,MDU6SXNzdWU3OTAzODMyNTI=
50,https://github.com/mjskay/ggdist/issues/50,https://github.com/mjskay/ggdist/issues/50,xiaoyingpu,Adding an aesthetic changes dotplot layout,"This works:

```
mtcars %>%
  ggplot(aes(mpg, factor(cyl))) + 
  stat_dots(aes(fill = factor(cyl)))
```
![image](https://user-images.githubusercontent.com/8374573/104733323-835bfd00-570c-11eb-8709-0980557e6426.png)

But this changes the layout of the dotplot and hides some dots too. Probably has to do with the `fill` aesthetic adding grouping to the data and the dot bins being created from those subgroups

```{r}
mtcars %>%
  ggplot(aes(mpg, factor(cyl))) + 
  stat_dots(aes(fill = factor(am)))  
```

![image](https://user-images.githubusercontent.com/8374573/104733469-bc946d00-570c-11eb-83ab-6eb4ea04a0e0.png)

Maybe this is a more reasonable behavior 
<img width=""537"" alt=""image"" src=""https://user-images.githubusercontent.com/8374573/104733829-480dfe00-570d-11eb-8bdb-7557669dea89.png"">



",TRUE,"----------------------------
mjskay:

Ah I that's the intended behavior I think (unless you can convince me it should be otherwise :) ) --- different colors should create different groups when working with stat_dots since it's analogous to stat_halfeye and the like, where you want to be able to do summarization on different groups (e.g. using the `quantiles` argument) and then dodge those groups together as units.

If you are doing any summarization on the samples you should be able to use `geom_dots` instead of `stat_dots` and get the behavior you are looking for. Does that work?

----------------------------
xiaoyingpu:

`geom_dots` creates the same thing as `stat_dots`, which it should?

```
mtcars %>%
  ggplot(aes(mpg, factor(cyl))) + 
  geom_dots(aes(fill = factor(am)))
```

![image](https://user-images.githubusercontent.com/8374573/104814448-f03ec800-57dc-11eb-814a-9845273d9e33.png)

(I haven't thought through this yet but in terms of PGoG, there can be two versions of this dotplot with the same `ggdist` aesthetics🤔

<img width=""834"" alt=""image"" src=""https://user-images.githubusercontent.com/8374573/104814417-bb327580-57dc-11eb-8c7f-3dd392681e56.png"">


----------------------------
mjskay:

Hrm, must be a function of passing things through with stats then when it does work (like the examples in the vignettes)

As I recall from the ggplot docs the behavior you're seeing is the expected behavior though: categorical variables contribute to groups, which in geom_dots means separate groups of dots (you should see similar behavior with geom_dotplot for example). The slabinterval stuff is a bit different because it handles position_stack differently than base, but you aren't using that here, so it makes sense they're drawn on top of each other. 

If you don't want the color to contribute to grouping I think you can bypass it (maybe with group =NA or something like that?) 

----------------------------
xiaoyingpu:

Yay `group = NA` works 

```
mtcars %>%
  ggplot(aes(mpg, factor(cyl))) + 
  geom_dots(aes(fill = factor(am), group = NA))
```

![image](https://user-images.githubusercontent.com/8374573/104823237-bd192a80-5816-11eb-83b5-d94a7c450ea7.png)

(My only quibble now is that without `group = NA`, and if the dots are drawn on top of each other without some reasonable offset, it can appear as if there are fewer dots than there are in the dataset)

----------------------------
mjskay:

> (My only quibble now is that without group = NA, and if the dots are drawn on top of each other without some reasonable offset, it can appear as if there are fewer dots than there are in the dataset)

Yeah fair. that's analogous to drawing area plots on top of each other though, which is what stat_slab does. I think this behavior makes sense for the semantics of ggdist but not so much for pgog.

----------------------------
mjskay:

closing this since this was a pgog thing that is resolved now yes?",TRUE,help,2021-01-15 13:41:37,2021-02-27 23:18:44,,,CLOSED,2021-02-27 23:18:44,NA,,MDU6SXNzdWU3ODY5MDQ1NDY=
49,https://github.com/mjskay/ggdist/issues/49,https://github.com/mjskay/ggdist/issues/49,mjskay,One-sided intervals,"Per a request for one-sided intervals, should add them. My initial thought is that the obvious way to add them is via a new interval type in the `point_interval` family, so that `.width` and such can continue to be used and everything else will just work fine (TM). By analogy to current naming scheme (`qi` / `hdi`) should be something like `loweri` / `upperi` or `li` / `ui` or `lowi` / `highi` or `lefti` / `righti` or `ll` / `ul` or `lowerl` / `upperl`. Not sold on any of the names yet.

Changes would need to be:

- [x] add the interval functions
- [x] add the `mean_`/`median_`/`mode_` + interval functions
- [x] figure out how to support these in `stat_dist_...`, which might involve adding a `point_interval` argument there that takes character vectors in the pattern of `point_interval` functions in `stat_sample_...`. Would also want to double-check `stat_sample...` does match.fun on character vector args for consistency across the two sub-families. (This would simultaneously solve the problem of using something other than median on distributions: could call down to the mean function for {distributional} objects for example if the mean is requested in analytical distributions). Or could add implementations of `qi`/`hdi` for distributional objects, which would simplify making `point_interval` implementation for them.
",TRUE,,TRUE,enhancement,2021-01-14 04:58:27,2022-01-15 19:36:45,,,CLOSED,2022-01-15 19:36:45,Next release ,,MDU6SXNzdWU3ODU2NTE0MjQ=
48,https://github.com/mjskay/ggdist/issues/48,https://github.com/mjskay/ggdist/issues/48,mitchelloharawild,Add stat_ribbon(),"Much like `stat_dist_lineribbon()`, but without the line. Alternatively, `stat_dist_lineribbon()` could be extended to support 0 or >1 functions to allow 0 or more than 1 line.

This will be used by fabletools v0.4.0 as `distributional::geom_hilo_ribbon()` gets deprecated.

---

The motivating example for this is showing both mean and median forecasts for asymmetric distributions, such as the Log-normal distributions below.

``` r
library(fable)
#> Loading required package: fabletools
eggs <- as_tsibble(fma::eggs)
eggs %>% 
  model(ETS(log(value))) %>% 
  forecast(h = 100) %>% 
  autoplot(eggs, point_forecast = tibble::lst(mean, median))
```

![](https://i.imgur.com/Su0uIRU.png)

<sup>Created on 2021-01-10 by the [reprex package](https://reprex.tidyverse.org) (v0.3.0)</sup>",TRUE,"----------------------------
mjskay:

Good idea! Thoughts:

- I like the simplicity of `stat_dist_ribbon()`. For consistency with the ggdist naming scheme I would probably also want to add a `stat_ribbon()` for sample data. My only concern is that there would then be no corresponding `geom_ribbon()` (or more correctly, it wouldn't be `ggplot2::geom_ribbon()` but rather `ggdist::geom_lineribbon()` with some setting to suppress the line), which might be confusing to people... it breaks the naming scheme in the rest of ggdist a bit.
- Because of the organization of the data tables generating by `stat_dist...` (specifically that the points and intervals are in the same rows, not separate rows), generating an arbitrary number of lines not tied to the intervals in some way would probably be messy. I'm not necessarily averse to changing that, but it's a big change that touches a lot of things, and I'd need to be convinced it's worth it.
- Given that, I'd probably prefer `stat_dist_ribbon()` and/or an option in `stat_dist_lineribbon()` to turn off the line (probably `stat_dist_lineribbon(show_line = FALSE)` to mirror the options in the slabinterval geoms/stats.

Probably adding `show_line` to `geom_lineribbon()` is the starting point, then adding `stat_ribbon()` and `stat_dist_ribbon()` as aliases if desired. Would that cover your use cases?

----------------------------
mitchelloharawild:

Sounds good to me, removing the line via an argument should work.

Regarding stat_ribbon(), how does this differ from using stat_dist_ribbon()
with a dist_sample()? I suspect if there exists a conflict, it would only
be from the data preprocessing steps and not the geometry (unless the geom
should be called geom_multiribbon() or something). I haven't thought about
this much yet, just writing some ideas down before I sleep.

On Sun, 10 Jan 2021, 5:34 pm Matthew Kay, <notifications@github.com> wrote:

> Good idea! Thoughts:
>
>    - I like the simplicity of stat_dist_ribbon(). For consistency with
>    the ggdist naming scheme I would probably also want to add a
>    stat_ribbon() for sample data. My only concern is that there would
>    then be no corresponding geom_ribbon() (or more correctly, it wouldn't
>    be ggplot2::geom_ribbon() but rather ggdist::geom_lineribbon() with
>    some setting to suppress the line), which might be confusing to people...
>    it breaks the naming scheme in the rest of ggdist a bit.
>    - Because of the organization of the data tables generating by
>    stat_dist... (specifically that the points and intervals are in the
>    same rows, not separate rows), generating an arbitrary number of lines not
>    tied to the intervals in some way would probably be messy. I'm not
>    necessarily averse to changing that, but it's a big change that touches a
>    lot of things, and I'd need to be convinced it's worth it.
>    - Given that, I'd probably prefer stat_dist_ribbon() and/or an option
>    in stat_dist_lineribbon() to turn off the line (probably stat_dist_lineribbon(show_line
>    = FALSE) to mirror the options in the slabinterval geoms/stats.
>
> Probably adding show_line to geom_lineribbon() is the starting point,
> then adding stat_ribbon() and stat_dist_ribbon() as aliases if desired.
> Would that cover your use cases?
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/mjskay/ggdist/issues/48#issuecomment-757425862>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AD3BJF2HWT2QUWKOGJUXZBTSZFDA7ANCNFSM4V4CAI6Q>
> .
>


----------------------------
mjskay:

> Regarding stat_ribbon(), how does this differ from using stat_dist_ribbon()
with a dist_sample()?

It doesn't differ that much, really, but it saves a data transformation step or two for users. It's also a workflow that a lot of people use, since it was the original workflow from tidybayes before ggdist got split off, and it's one I want to continue supporting across all geoms/stats. It is also currently faster, until `density()` for distributional objects is vectorized (since the KDE for each variable is only calculated once instead of once per variable per x position).

----------------------------
mjskay:

(sidebar: is there a timeline you are planning to hit that depends on this change? I am steeped in teaching prep and grad app reviews at the moment, so I might not have much time for changes for the two weeks or so)

----------------------------
mitchelloharawild:

> It doesn't differ that much, really, but it saves a data transformation step or two for users. It's also a workflow that a lot of people use, since it was the original workflow from tidybayes before ggdist got split off, and it's one I want to continue supporting across all geoms/stats. 

I agree that working with a long format data structure is more familiar and can be better suited to a ggplot workflow here.

> It is also currently faster, until `density()` for distributional objects is vectorized (since the KDE for each variable is only calculated once instead of once per variable per x position).

I'll make that a priority for `{distributional}`.

> (sidebar: is there a timeline you are planning to hit that depends on this change? I am steeped in teaching prep and grad app reviews at the moment, so I might not have much time for changes for the two weeks or so)

`{distributional}` can hold onto the `{ggplot2}` dependency until you have time, so no rush here. There's plenty of other things to work on in the meantime.

----------------------------
mjskay:

> I'll make that a priority for {distributional}.

Sweet thanks! It occurred to me I dumped a bunch of unsolicited opinions about formats for multivariate densities into that other thread awhile back :). To be honest, after reflecting on it for awhile I think as long as there's a simple way to get vectorized density values from a single distribution (i.e. a {distributional} vector of length one) it'll probably work well for my use cases.

> {distributional} can hold onto the {ggplot2} dependency until you have time, so no rush here. There's plenty of other things to work on in the meantime.

Cool, I've added this issue to the Next Release milestone.

----------------------------
mitchelloharawild:

Revisiting this, I can remove the line with a bit of a hack - setting the colour aesthetic to be NA or transparent in some way.
So in that sense it is less urgent, but would certainly be nice to have :)

----------------------------
mjskay:

Yeah, setting color to `NA` is probably the preferred method in the short term. Do let me know if you run into any weirdness with that.

Long term, I am in the midst of restructuring essentially the entire stat/geom codebase on the `unify-dist` branch for #83, after which it will be *much* easier to add and maintain additional shortcut stats/geoms without a pile of boilerplate (courtesy #106). Then it should be trivial to implement a `stat_ribbon()`.


----------------------------
mjskay:

The `stat_ribbon()` shortcut stat is now on master.",TRUE,enhancement,2021-01-10 02:51:30,2022-01-15 19:36:20,,,CLOSED,2022-01-15 19:36:20,Next release ,,MDU6SXNzdWU3ODI3Mjk3MTk=
47,https://github.com/mjskay/ggdist/issues/47,https://github.com/mjskay/ggdist/issues/47,mjskay,Ensure slab fill colors can have alpha set manually,"- [x] `fill = alpha(some_color, some_alpha)` and `slab_fill = alpha(some_color, some_alpha)` should work
- [x] should work with fill_ramp 

See https://github.com/mjskay/tidybayes/issues/136",TRUE,"----------------------------
mjskay:

This just came up again in #62 so I finally looked into it. Turns out the fix was easier than I thought, so it should be fixed on master now.",TRUE,bug,2021-01-07 02:28:42,2021-03-23 02:19:20,,,CLOSED,2021-03-23 02:19:20,NA,,MDU6SXNzdWU3ODA5NzgxOTQ=
46,https://github.com/mjskay/ggdist/issues/46,https://github.com/mjskay/ggdist/issues/46,lapotok,cut_cdf_qi is missing,"Hi,

I'm trying to use `cut_cdf_qi()` function as in the cheatsheet, but it's not available. Neither after loading ggdist through `library(ggdist)`, nor through `ggdist::cut_cdf_qi()` nor through `ggdist:::cut_cdf_qi()`. And there is no help page for that function...
I've installed **ggdist** using `install.packages(""ggdist"")` (it's version 2.3.0). Tried to reinstall through `devtools::install_github(""mjskay/ggdist"")`, but it gets stuck forever on downloading.

Do you know, what could be the problem? Thanks in advance!
Evgeny

```
> sessionInfo()
R version 4.0.0 (2020-04-24)
Platform: x86_64-apple-darwin17.0 (64-bit)
Running under: macOS Catalina 10.15.7

Matrix products: default
BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] ggdist_2.3.0

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.5           rstudioapi_0.13      magrittr_2.0.1       tidyselect_1.1.0    
 [5] munsell_0.5.0        colorspace_2.0-0     R6_2.5.0             rlang_0.4.9         
 [9] fansi_0.4.1          dplyr_1.0.2          tools_4.0.0          grid_4.0.0          
[13] packrat_0.5.0        gtable_0.3.0         cli_2.2.0            ellipsis_0.3.1      
[17] assertthat_0.2.1     tibble_3.0.4         lifecycle_0.2.0      crayon_1.3.4.9000   
[21] tidyr_1.0.2          farver_2.0.3         purrr_0.3.4          ggplot2_3.3.2       
[25] vctrs_0.3.5          glue_1.4.2           compiler_4.0.0       pillar_1.4.7        
[29] forcats_0.5.0        generics_0.0.2       scales_1.1.1         distributional_0.2.1
[33] pkgconfig_2.0.3  
```",TRUE,"----------------------------
lapotok:

Sorry to bother, `install_github()` didn't work for some reason, but now it did and I got `cut_cdf_ci()` working.
And ggdist 2.3.0 version seems not to have `cut_cdf_qi()` as I just checked at cran/ggdist repo.

----------------------------
mjskay:

Yeah, cut_cdf_qi() is currently only in the github version. Next release it should hit cran. Sorry for the confusion!",TRUE,help,2020-12-10 09:29:39,2020-12-11 06:53:34,,,CLOSED,2020-12-11 06:53:34,NA,,MDU6SXNzdWU3NjEwNjcwMDY=
45,https://github.com/mjskay/ggdist/issues/45,https://github.com/mjskay/ggdist/issues/45,mjskay,Add support for p boxes,"Maybe:

- [ ] vector type for p boxes (maybe put in another package) 
- [ ] stat_pbox or something like that",FALSE,,FALSE,enhancement,2020-12-10 07:09:27,NA,,,OPEN,2020-12-10 07:09:27,NA,,MDU6SXNzdWU3NjA5NzYzMDg=
44,https://github.com/mjskay/ggdist/issues/44,https://github.com/mjskay/ggdist/issues/44,mjskay,Support rendering gradient fills as linearGradients in R 4.1,"See here: https://developer.r-project.org/Blog/public/2020/07/15/new-features-in-the-r-graphics-engine/

Should probably be optional since not all graphics engines support it and on some geometries it may not be desirable.

Also see here: https://github.com/tidyverse/ggplot2/issues/3997",TRUE,,FALSE,enhancement,2020-11-28 04:32:40,2021-06-13 06:21:50,,,CLOSED,2021-06-13 06:21:50,3.0.0,,MDU6SXNzdWU3NTI1OTU0MjA=
33,https://github.com/mjskay/ggdist/issues/33,https://github.com/mjskay/ggdist/issues/33,mjskay,Make curve_interval() work directly inside stat_lineribbon(),this is more of a questioning thing... not sure I want to re-architect treatment of the `point_interval` argument to `stat_lineribbon()` to support this since it involves making more assumptions about the type of function that can be passed there (since the function must be able to do grouping itself instead of having the grouping be done by the stat prior to calling the function). Better option might be to just add an example where use of `curve_interval()` with the `data` argument to `geom_lineribbon()` is shown.,FALSE,,FALSE,enhancement,2020-11-25 04:40:27,NA,question,,OPEN,2020-11-25 04:40:50,NA,,MDU6SXNzdWU3NTA0MTg4Mzg=
32,https://github.com/mjskay/ggdist/issues/32,https://github.com/mjskay/ggdist/issues/32,steveharoz,stat_histinterval: odd behavior for groups with no variance,"If all values in a group are the same (not uncommon for a baseline or control condition), the histogram borks.
Maybe something to do with bin size?

```r
set.seed(1234)
df = tribble(
  ~group, ~value,
  ""a"",    rep(10, 1000), # no variance here
  ""b"",    rnorm(1000, mean = -5),
  ""c"",    rnorm(1000, mean = 10),
) %>%
  unnest(value)

df %>%
  ggplot(aes(y = group, x = value)) +
  stat_histinterval(slab_type = ""histogram"") +
  theme_ggdist()
```

![image](https://user-images.githubusercontent.com/2257540/98709546-d1f2c100-2382-11eb-82d7-d4d547d7654f.png)


A workaround is to filter out the non-variant group and add it as an annotation.

",TRUE,"----------------------------
steveharoz:

The same thing happens with `hist(rep(10, 1000))`, so this probably isn't worth fixing in ggdist.

----------------------------
mjskay:

Hmph that is kinda obnoxious though. I assume it's the default binning for data that's all equal. I have been considering swapping out the binning algorithm, and this might be a good motivation to do it.

Either way you'd probably need to special case this, since constants will have much taller bins and everything else would get scaled down too much. On the other hand this isn't am uncommon use case so having an argument to just drop the slab on constants might be useful? 

----------------------------
steveharoz:

Yeah, dropping the slab could work. Although the single bar conveys the point really well even if it's vertically truncated. As you saw elsewhere, I wound up replacing the baseline condition with a `geom_vline()`, so maybe that's a general recommendation for folks with similar data.

Here's a related quirk and feature request:
It'd be great to be able to specify the bin width (not the breaks) for all of the histograms, so it's visually consistent. It would somewhat solve the above problem too.

```
set.seed(1234)
tribble(
  ~group, ~value,
  ""b"",    rnorm(1000, mean = 6, sd = 3),
  ""c"",    rnorm(1000, mean = 8, sd = 2),
  ""d"",    rnorm(1000, mean = 10),
) %>%
  unnest(value)  %>%
  ggplot() +
  aes(y = group, x = value) +
  stat_histinterval(slab_type = ""histogram"") +
  theme_ggdist()
```

![image](https://user-images.githubusercontent.com/2257540/98964433-14460a80-2509-11eb-951d-efd362424ed0.png)
 
It'd be nice if there were a parameter to specify fixed bin sizes for all histograms. Like `bindwidth = 0.5, binstart=-0.25`. And then all bins would be [ -0.25 + 0.5n, -0.25 + 0.5(n+1) )

----------------------------
mjskay:

This is now fixed as a consequence of restructuring in #103 and #83 in the `unify-dist` branch. Constant distributions are detected and rendered as point masses throughout the `stat_slabinterval()` family. In this case that results in this:

```r
set.seed(1234)
df = tribble(
  ~group, ~value,
  ""a"",    rep(10, 1000), # no variance here
  ""b"",    rnorm(1000, mean = -5),
  ""c"",    rnorm(1000, mean = 10),
) %>%
  unnest(value)

df %>%
  ggplot(aes(y = group, x = value)) +
  stat_histinterval(slab_type = ""histogram"") +
  theme_ggdist()
```
![image](https://user-images.githubusercontent.com/6345019/144774550-8f8e6094-5b87-4148-8db7-4ba094cdb344.png)

Which may seem a big odd, but if you enable the outline on the slab you can see what's going on:

```r
df %>%
  ggplot(aes(y = group, x = value)) +
  stat_histinterval(slab_type = ""histogram"", slab_color = ""gray75"") +
  theme_ggdist()
```
![image](https://user-images.githubusercontent.com/6345019/144774643-dc2bcee2-ed68-4a00-b47a-39595e6fb972.png)

And the new `expand` parameter can also let you see this in a more ridgeline-like way:

```r
df %>%
  ggplot(aes(y = group, x = value)) +
  stat_histinterval(slab_type = ""histogram"", slab_color = ""gray75"", expand = TRUE) +
  theme_ggdist()
```
![image](https://user-images.githubusercontent.com/6345019/144774787-c3eb44d0-799f-4f0c-bb2c-de8a58ae2b45.png)

```",TRUE,enhancement,2020-11-10 17:31:55,2021-12-06 01:51:41,"enhancement,rewrite",,CLOSED,2021-12-06 01:51:42,NA,,MDU6SXNzdWU3NDAxMDU5NTU=
31,https://github.com/mjskay/ggdist/issues/31,https://github.com/mjskay/ggdist/issues/31,mjskay,switch to vectorized cdf/pdf/quantile for distributional,Whenever https://github.com/mitchelloharawild/distributional/issues/52 and whatnot are fixed,TRUE,,FALSE,cleanup,2020-10-29 03:39:43,2021-06-10 05:29:19,"waiting,internals",,CLOSED,2021-06-10 05:29:19,NA,,MDU6SXNzdWU3MzE5NjkyOTk=
30,https://github.com/mjskay/ggdist/issues/30,https://github.com/mjskay/ggdist/issues/30,ASKurz,overlap from the bottom,"I am summarizing multiple posteriors with `stat_slab()` with value on the x and key on the y. I'd like the densities to overlap a bit, say with `height = 1.5` and `alpha = 3/4`. With this setup, it appears that the densities higher up on the y-axis overlap those on the bottom. Is is possible to reverse this behavior so that the tops of the densities lower on the y overlap the bottoms of the densities above them?

```
library(tidyverse)
library(tidybayes)

n <- 1e4

tibble(x = rnorm(n),
       y = rnorm(n)) %>% 
  gather() %>% 
  ggplot(aes(x = value, y = key)) +
  stat_slab(height = 1.5, color = ""black"", alpha = 3/4)
```

I get the desired behavior with `ggridges::geom_density_ridges()`.",TRUE,"----------------------------
mjskay:

Ah good catch, that's a bug! It is supposed to work as you expect automatically. Seems I introduced a bug that broke it when I added automatic orientation detection. I just pushed a fix along with some new tests that should catch it if it breaks again.

----------------------------
ASKurz:

woot!",TRUE,bug,2020-09-27 21:55:30,2020-09-27 23:15:01,,,CLOSED,2020-09-27 23:18:17,NA,,MDU6SXNzdWU3MDk4MjM1NTM=
29,https://github.com/mjskay/ggdist/issues/29,https://github.com/mjskay/ggdist/issues/29,Famondir,Feature-request: stat_lineribbon with continuous filling,"Dear reader,
it would be awesome to get the possibility of filling the stat_lineribbon with a continuous (but maybe binned) colour sclae. This way I hope to prevent the legend in vertical box theme from taking two rows when there are mor than for levels.

Sincerely, Simon",TRUE,"----------------------------
mjskay:

This is possible using the current lineribbon, though admittedly not well documented :). The lineribbon stat generates both a `level` statistic and a `.width` statistic. The `level` statistic is a factor and is assigned to the `fill` aesthetic by default, on the assumption that you want a small number of discrete levels. However, you can override this behavior by assigning the `.width` statistic to the `fill` aesthetic instead, which should produce a continuous scale:

```r
library(ggplot2)
library(ggdist)
set.seed(1234)
ggplot(data.frame(y = rnorm(10000), x = c(1, 2)), aes(x, y)) +
    stat_lineribbon(aes(fill = stat(.width)), .width = ppoints(100))
```
![image](https://user-images.githubusercontent.com/6345019/93559476-d46e0700-f94d-11ea-9ba1-0817f6466655.png)

Hope that helps!",TRUE,help,2020-09-16 18:25:20,2020-09-18 05:26:03,,,CLOSED,2020-09-18 05:26:03,NA,,MDU6SXNzdWU3MDI5ODE0ODM=
28,https://github.com/mjskay/ggdist/issues/28,https://github.com/mjskay/ggdist/issues/28,jebyrnes,geom_raincloud,"Any chance this might happen? I know, I know, this might be an annoying request, but..... ",TRUE,"----------------------------
mjskay:

Ha not annoying at all! I'll have to think about it... currently I like the fact that most of the existing geoms fit within a coherent family (and I'm already planning some ways to make that family *more* coherent). 

If by rainclouds you mean a combination of a density *and* jittered points (or maybe a dotplot), I'm not sure exactly how to fit something like that into the existing family. The slabinterval geoms are already composites of three geoms (slab/point/interval) and adding a fourth seems unwieldy to me.

If you just want a density with a dotplot you might be able to do something like this:

```r
library(ggplot2)
library(ggdist)
set.seed(1234)
ggplot(data.frame(x = rnorm(100)), aes(x)) +
  stat_slab() +
  stat_dots(side = ""bottom"")
```
![image](https://user-images.githubusercontent.com/6345019/93558918-7bea3a00-f94c-11ea-8c24-adac77d27b33.png)


It might help me to better understand the use case / what you're after. Is it something like the above? Is it something with jittering instead?

----------------------------
mjskay:

@jebyrnes I'm closing this for now unless you want to ping again and reopen :). Let me know, I'm happy to discuss!",TRUE,enhancement,2020-09-12 17:32:45,2021-06-11 05:53:38,waiting,,CLOSED,2021-06-11 05:53:38,NA,,MDU6SXNzdWU3MDAzMTQyMjA=
27,https://github.com/mjskay/ggdist/issues/27,https://github.com/mjskay/ggdist/issues/27,bwiernik,Adjust position of points/intervals on the density axis.,"I'm trying to plot two interval distributions side-by-side (to show group overlap). I'd like to be able to adjust the position of the summary points/intervals so that they don't overlap each other, but I can't see a way to do that (e.g., to move one group's summary statistics up on the y-axis when the variable values are on the x-axis). Could something like `point_offset` and `interval_offset` parameters be added?",TRUE,"----------------------------
wzel:

`position = ""dodge""` works for me, even though it does not let you specify the distances. Check the ""Slab + interval stats and geoms"" vignette for examples.

----------------------------
bwiernik:

Thanks for the idea. That helped me to realize I could accomplish this by specifying the slap and the interval as separate stats:
```
set.seed(1234)
df <- tribble(
    ~group, ~subgroup, ~value,
    ""a"",          ""h"", rnorm(1000, mean = 5),
    ""b"",          ""h"", rnorm(1000, mean = 7, sd = 1.5),
    ""c"",          ""h"", rnorm(1000, mean = 8),
    ""c"",          ""i"", rnorm(1000, mean = 9),
    ""c"",          ""j"", rnorm(1000, mean = 7)
  ) %>%
  unnest(value)
df %>%
    ggplot(aes(fill = group, color = group, x = value)) +
    stat_halfeye(point_interval = NULL, alpha = .3) +
    stat_pointinterval(position = position_dodge(width = .1, preserve = ""single"")) +
    ggtitle(""stat_eye()"") + theme_minimal()
```

Might be nice to have the interval parameters be separately modifiable in the combined stats.

----------------------------
mjskay:

Ah okay I see what you're going for now I think. Currently my feeling tends to be that if you want the point/interval and slabs to be less tightly coupled in some customized way then using separate geoms is the best way. Dodging one part of the geom but not another would be hard to stuff into one geom without some fairly complex parameters which would probably end up with syntax about as complicated as what you do with separate geoms.

Have I missed something about your use case?

----------------------------
bwiernik:

No, I think when I was posted the question I hadn't fully realized that the slabs and intervals could also be given as separate geoms. Maybe the best solution would be to add an example like the above to a vignette?

----------------------------
mjskay:

Good idea @bwiernik, I added your example to the slabinterval vignette here: https://mjskay.github.io/ggdist/articles/slabinterval.html#independent-slabs-and-intervals-in-composite-plots

(hope that's alright!)",TRUE,"help,docs",2020-08-18 23:14:11,2020-11-22 05:32:26,,,CLOSED,2020-11-22 05:35:07,NA,,MDU6SXNzdWU2ODEzOTYwMDc=
26,https://github.com/mjskay/ggdist/issues/26,https://github.com/mjskay/ggdist/issues/26,bwiernik,Consistent y-axis height for stat_dots,"I love the stat_dots() slab element, especially the quantile version. But it seems to have inherited the major limitation of geom_dotplot() that the [linear scale of the y-axis is meaningless](https://github.com/tidyverse/ggplot2/issues/2203). 

I'm interested in combining a dots slab with a curve (e.g., to show the observed group distributions against reference normal distributions), but I'm struggling with a way to get consistent y-axis heights for the dots stacks and the density curve, especially across image sizes. See the reprex below.

Is there any way that different slab elements could be forced to use the same linear y-axis scale as the dots slab?

```r
library(dplyr)
library(tidyr)
library(ggdist)
library(ggplot2)
library(broom)
library(modelr)

theme_set(theme_ggdist())

set.seed(5)
n = 10
n_condition = 5
ABC =
  tibble(
    condition = rep(c(""A"",""B"",""C"",""D"",""E""), n),
    response = rnorm(n * 5, c(0,1,2,1,-1), 0.5)
  )
m_ABC = lm(response ~ condition, data = ABC)

ABC %>%
    data_grid(condition) %>%
    augment(m_ABC, newdata = ., se_fit = TRUE) %>%
    ggplot(aes(y = condition)) +
    stat_dist_halfeye(
        aes(dist = distributional::dist_normal(.fitted, sigma(m_ABC)))
    ) +
    # we'll add the data back in too (scale = .5 above adjusts the halfeye height so
    # that the data fit in as well)
    stat_dots(quantiles = 100, aes(x = response, y = condition), data = ABC, color = ""blue"")
```",FALSE,"----------------------------
mjskay:

This is a really good question to which I would love to be able to answer ""yes"" 🙂. I like the idea of combining densities with dotplots and dearly wish it was easier... Unfortunately at the moment there's no easy fix. The problem is the automatic bin adjustment on the dotplots needs to be calculated at display time (because it depends on chart size), which can only be done by making the dotplots into their own grob objects (the underlying geometry objects used by {grid}). To coordinate across the dotplots and the densities they would *probably* all need to be in the same grob object (that, or I'd have to come up with some bizarre hack to coordinate across multiple grobs in a way {grid} is not really designed to do). That would likely require them all to be created in the same geom, or I'd have to add a way to coordinate across geoms as well. So any solution would require non-trivial re-architecting of the internal code and careful thought about what the API should look like. I'm not against this in principle (in fact I've already done this kind of thing several times in tidybayes) but it's definitely not a quick fix, and I'm not even 100% sure it's possible. I'm also not sure exactly what the right relationship between the dotplot scaling and density scaling should be. Happy to take suggestions.

So this isn't a ""no"", because it is a use case I would love to support! It just is not likely to be anytime soon 🙂.

Sidebar: in your example since you only have a few samples per group I would use regular old dotplots, not quantile dotplots. If you drop the `quantiles` argument from `stat_dots` the output looks more reasonable to me. 

----------------------------
bwiernik:

> Sidebar: in your example since you only have a few samples per group I would use regular old dotplots, not quantile dotplots. If you drop the quantiles argument from stat_dots the output looks more reasonable to me.

Yeah, I looked at that, but even then it seems quite dependent on the size of the output; it's hard to see how reasonable 

> I'm also not sure exactly what the right relationship between the dotplot scaling and density scaling should be. Happy to take suggestions.

Yeah, it's tough when the y-axis scaling in a dotplot is pretty arbitrary. I wonder if something like drawing the sample density curve, then scaling the dots based on that curve might work? Or perhaps scaling the y-axis based on a histogram with the same binwidth as the dotplot? An alternative might be to adjust the .width or scaling of the other geom, e.g., make a histogram that lines up with the dotplot, then use that y-axis scaling for the density curve?",TRUE,enhancement,2020-08-16 20:12:59,NA,"enhancement,rewrite",,OPEN,2020-11-22 21:55:54,NA,,MDU6SXNzdWU2Nzk4MTgzNDU=
25,https://github.com/mjskay/ggdist/issues/25,https://github.com/mjskay/ggdist/issues/25,mjskay,Add support for factors as input to the dist aesthetic,stat_dist could break if a data frame has a factor column for the dist aesthetic,TRUE,,FALSE,bug,2020-07-24 04:53:13,2020-10-31 02:21:01,,,CLOSED,2020-10-31 02:21:02,3.0.0,,MDU6SXNzdWU2NjQ5MTQ1Mzg=
24,https://github.com/mjskay/ggdist/issues/24,https://github.com/mjskay/ggdist/issues/24,mjskay,Should stat_dots and whatnot auto-group by numeric x/y values?,"Bit of potentially unexpected behavior revealed by this twitter thread: https://twitter.com/MYMRockMama/status/1283841342779449344?s=20

Not sure but the issue might be due to groups being determined by discrete variables only, so using a numeric y value means every dot gets its own group (and so they get auto-assigned bad bin widths):

```r
tibble(
  g = c(""a"",""b""), 
  y = as.numeric(factor(g)) - 0.1, 
  x = list(qnorm(ppoints(100)))
) %>% 
  unnest(x) %>% 
  ggplot(aes(x = x, y = y)) + 
  stat_dots()
```
![image](https://user-images.githubusercontent.com/6345019/87715604-9997f900-c77b-11ea-8aa8-bdec6e8f597b.png)

Some workarounds: (1) manually set the group aesthetic

```r
tibble(
  g = c(""a"",""b""), 
  y = as.numeric(factor(g)) - 0.1, 
  x = list(qnorm(ppoints(100)))
) %>% 
  unnest(x) %>% 
  ggplot(aes(x = x, y = y, group = y)) + 
  stat_dots()
```
![image](https://user-images.githubusercontent.com/6345019/87715682-b7fdf480-c77b-11ea-80b9-8d138563bf47.png)

(2) use a discrete variable for the y axis (and if you want to nudge positions do so with `position_nudge`:

```r
tibble(
  g = c(""a"",""b""), 
  x = list(qnorm(ppoints(100)))
) %>% 
  unnest(x) %>% 
  ggplot(aes(x = x, y = g)) + 
  stat_dots(position = position_nudge(y = -0.1))
```
![image](https://user-images.githubusercontent.com/6345019/87715802-e085ee80-c77b-11ea-877d-7710328ae366.png)


Question is, should groups be auto-created along the x/y axis to avoid the unexpected behavior? Are there any downsides?
",TRUE,#NAME?,TRUE,enhancement,2020-07-16 19:51:06,2020-11-22 21:48:57,,,CLOSED,2020-11-22 21:48:57,NA,,MDU6SXNzdWU2NTg1MTE2NzQ=
23,https://github.com/mjskay/ggdist/issues/23,https://github.com/mjskay/ggdist/issues/23,mjskay,Add fuzzygram reference to vignette,https://twitter.com/mjskay/status/1282691596232937475?s=19,TRUE,,FALSE,docs,2020-07-13 16:16:04,2020-11-24 05:48:14,documentation,,CLOSED,2020-11-24 05:48:14,NA,,MDU6SXNzdWU2NTU5NzQ4MTU=
22,https://github.com/mjskay/ggdist/issues/22,https://github.com/mjskay/ggdist/issues/22,mjskay,Add curve_interval(),"See:
https://pubmed.ncbi.nlm.nih.gov/26356979/
https://pubmed.ncbi.nlm.nih.gov/24051838/
https://arxiv.org/abs/2007.05035

- [x] finish function docs (fill in algorithm details and citations)
- [x] finish off the rest of lineribbon vignette
- [x] remove TODO / DRAFT bits from lineribbon vignette
- [x] re-export from tidybayes
- [x] implement na.rm
- [x] add `@examples`
- [x] ~~switch to curve depth per https://arxiv.org/abs/1901.00180 {curveDepth} https://cran.r-project.org/web/packages/curveDepth/index.html (though this seems a bit unreliable on testing)~~
- [x] or use the band depth approach per https://www.tandfonline.com/doi/abs/10.1198/jcgs.2011.09224 implemented in fda::fbplot() (this seems more reliable)
- [x] ref https://link.springer.com/content/pdf/10.1007/BF02595706.pdf for mean univariate data depth
- [x] add examples to lineribbon vignette describing pitfalls of both methods",TRUE,,FALSE,enhancement,2020-07-13 16:09:05,2020-11-25 06:54:33,,,CLOSED,2020-11-25 06:54:33,3.0.0,,MDU6SXNzdWU2NTU5NzAyMjM=
20,https://github.com/mjskay/ggdist/issues/20,https://github.com/mjskay/ggdist/issues/20,ASKurz,parse_dist() and lower bounds for class = sd,"Hey @mjskay,

I wanted to use `parse_dist()` and `stat_dist_halfeye()` to compare two priors for a hierarchical $\sigma$ parameter. They were Exponential(1) and half-Normal(0, 1). With **brms**, the default behavior sets the lower bounds for both to zero. However, my **tidybayes** workflow did not set the lower bound for the half-Normal. E.g., try this:

```
library(brms)
library(tidybayes)
library(tidyverse)

c(prior(exponential(1), class = sd),
  prior(normal(0, 1), class = sd)) %>% 
  parse_dist(prior) %>% 
  
  ggplot(aes(y = prior, dist = .dist, args = .args)) +
  stat_dist_halfeye(.width = .95)
```

Attempting to manually set the lower bound with `prior(normal(0, 1), class = sd, lb = 0)` won't work, either. You get a warning message, instead: `Error: Currently boundaries are only allowed for classe(s) 'b'.`. Is there an easy fix?",TRUE,"----------------------------
mjskay:

Yeah there is not a great workflow for this yet. The simplest workaround I've come up with is to use the ""trunc"" distribution family from {truncdist}. See `?truncdist::dtrunc` --- basically it is way to create truncated distributions from existing distirbution families in R, where the first argument is the distribution name, second is lower bound, and third is upper bound. Then the remaining arguments are passed to the underlying distribution.

The nice thing is this works with how ggdist uses distribution argument aesthetics pretty easily --- basically instead of passing the distribution name to `dist` aesthetic, you pass `""trunc""` to the `dist` aesthetic and the distribution name to the `arg1` aesthetic. Then lower and upper bounds go to `arg2` and `arg3`, and the remaining arguments go to `args` and everything should line up with how `dtrunc` expects its arguments to be:

```r
library(truncdist)
library(brms)
library(ggdist)   # or library(tidybayes)
library(tidyverse)

c(prior(exponential(1), class = sd),
  prior(normal(0, 1), class = sd)) %>% 
  parse_dist(prior) %>%

  ggplot(aes(y = prior, dist = ""trunc"", arg1 = .dist, arg2 = 0, arg3 = Inf, args = .args)) +
  stat_dist_halfeye()
```
![image](https://user-images.githubusercontent.com/6345019/86287601-733c6000-bbb6-11ea-8349-f3fec40cb84f.png)

Once https://github.com/mjskay/ggdist/issues/14 is done I want to come up with a better workflow for brms priors using distribution objects from {distributional} which should hopefully make stuff like this more straightforward. Hopefully this workaround is pretty okay for the meantime.

----------------------------
ASKurz:

Thanks @mjskay. This looks like a nice temporary workaround. Since it looks like the issue might be resolved as a special case of a broader workflow change, it seems like we can close this issue.

----------------------------
ASKurz:

Hey @mjskay, is this still the recommended workflow for truncated distributions? My current use case is to plot $\operatorname{Exponential}(1 / 4.309458)$, with an upper bound of 10. Here's my workflow:

```{r}
library(truncdist)
library(brms)
library(ggdist)   # or library(tidybayes)
library(tidyverse)

# 1 / 4.309458 is about 0.2320477
prior(exponential(0.2320477), class = sigma, ub = 10) %>% 
  parse_dist() %>% 
  
  ggplot(aes(y = 0, dist = ""trunc"", arg1 = .dist, arg2 = 0, arg3 = 10, arg4 = 1 / 4.309458, args = .args)) +
  stat_halfeye() +
  geom_vline(xintercept = 10, linetype = 2)+
  labs(title = ""Exponential(1 / 4.309458), truncated at 10"",
       x = NULL) +
  coord_cartesian(xlim = c(0, 20))
```
<img width=""735"" alt=""Screen Shot 2023-02-01 at 11 51 22 AM"" src=""https://user-images.githubusercontent.com/19917004/216123160-6231a93e-b670-4dc3-84db-527aa6ccb4b1.png"">



----------------------------
mjskay:

Ah right, I did promise to come up with a better workflow once distributional support was added, thanks for reminding me :).

I just added an attempt at such a workflow on the `dev` branch if you want to test it via `remotes::install_github(""mjskay/ggdist@dev"")`. Basically, in addition to the existing `.dist` and `.args` columns, `parse_dist()` now generates a `.dist_obj` column containing a {distributional} object representing the distribution. If the `lb` and `ub` columns are present (as in output from `brms::prior()`), this object will also have the appropriate truncation applied to it using `dist_truncated()`.

This should make sd parameters much easier to visualize:

``` r
library(distributional)
library(ggdist) # remotes::install_github(""mjskay/ggdist@dev"")
library(ggplot2)
library(brms)

c(
  prior(exponential(0.2320477), class = sigma, ub = 10), 
  prior(normal(0,4), class = sd, lb = 0)
) |>
  parse_dist() |> 
  ggplot(aes(xdist = .dist_obj, y = format(.dist_obj))) + 
  stat_halfeye()
```

![](https://i.imgur.com/07kpyNF.png)<!-- -->

Does that help?

----------------------------
ASKurz:

Overall I like it @mjskay, but there are two points to consider. Notice how the y-axis label suggests there is no lower bound for the exponential prior, even though there is a definitional bound at 0. Also, it's not totally clear with the pic you uploaded, but if you look closely, you'll see that the point at which the exponential density gets truncated at 10 is slightly slanted. Here's a zoomed in version of the pic from my computer:

<img width=""141"" alt=""Screen Shot 2023-02-01 at 2 43 36 PM"" src=""https://user-images.githubusercontent.com/19917004/216159034-79c13074-036f-48d1-9af5-4c67b0f5aa93.png"">

The slant seems odd.

----------------------------
mjskay:

The name just comes from what `format()` outputs for `dist_truncated()`: there's no left truncation so the lower bound is `-Inf`. You could set lb = 0 on that prior if you want that to be different.

The slant is a byproduct of needing to define a grid to draw the density over. If you increase the `n` argument to `stat_halfeye()` the grid will be finer and the slant less noticeable.

----------------------------
ASKurz:

I see. Okay, that works. Thanks!

For posterity, here's the update with your recommendations:

```
c(
  prior(exponential(0.2320477), class = sigma, lb = 0, ub = 10), 
  prior(normal(0,4), class = sd, lb = 0)
) |>
  parse_dist() |> 
  ggplot(aes(xdist = .dist_obj, y = format(.dist_obj))) + 
  stat_halfeye(n = 1e4)
```
<img width=""873"" alt=""Screen Shot 2023-02-02 at 9 40 59 AM"" src=""https://user-images.githubusercontent.com/19917004/216370756-26798ef3-e2fc-405d-b691-a97f23c0d683.png"">



----------------------------
mjskay:

Awesome, that's great!

----------------------------
ASKurz:

Hey @mjskay, one last follow-up (*last*, he says...). Would you recommend the `xdist = .dist_obj, y = format(.dist_obj)` style syntax as a general approach, now? For example, I just ran across a use case where I wanted to plot some default `brm()` priors

$$
\begin{align}
\beta_0 & \sim \operatorname{Student-t}(3, 49.5, 3.6) \\
\sigma & \sim \operatorname{Student-t}^+(3, 0, 3.6).
\end{align}
$$

I used the code

```{r}
c(prior(student_t(3, 49.5, 3.6)),
  prior(student_t(3, 0, 3.6), class = sigma, lb = 0)) %>% 
  parse_dist() %>% 
  
  ggplot(aes(xdist = .dist_obj, y = format(.dist_obj))) + 
  stat_halfeye()
```

<img width=""863"" alt=""Screen Shot 2023-03-12 at 3 57 20 PM"" src=""https://user-images.githubusercontent.com/19917004/224573241-d7dab784-5df2-402e-b8d8-cba3a3852c77.png"">


It worked great. Are there contexts where the other `dist = .dist, args = .args` type snytax would be more appropriate?

----------------------------
mjskay:

Yeah, in general the `.dist_obj` object should be the preferred thing to use going forward. The `dist` and `args` aesthetics aren't going anywhere for backwards compatibility, but the object-based representation is just easier to pass around I think.

Also, really glad it's working well!! :)

----------------------------
ASKurz:

Cool. I'm teaching a beginner's workshop a week from now and that's the approach I'll show them, then.",TRUE,enhancement,2020-07-01 16:08:16,2020-07-01 21:39:32,,,CLOSED,2023-03-13 02:26:14,NA,,MDU6SXNzdWU2NDkxMDE3NzM=
19,https://github.com/mjskay/ggdist/issues/19,https://github.com/mjskay/ggdist/issues/19,mjskay,Detect discrete distributions ,"And do something sensible with their slab functions (histogram ish things?). May wait on https://github.com/mitchelloharawild/distributional/issues/8

TODOs:
- [x] do this for stat_dist_
  - [x] tests
- ~~[ ] do this for stat_sample_~~ not needed atm, there's always histinterval
- [x] add example to vignette",TRUE,"----------------------------
isabellaghement:

Hi Matthew, 

Here is the promised R code for displaying discrete conditional Poisson distributions for various values of an X variable.  In the graph, I relabeled the X values as 1 through 5, although they were originally set to something different.  The graph looks like this:
![image](https://user-images.githubusercontent.com/57458528/115442812-50238100-a1c7-11eb-8444-550887999228.png)

The R code is as follows: 

`
library(ggplot2)
theme_set(theme_bw())

beta0 <- 3
beta1 <- -0.5

x <- 1:5 

mu <- exp(beta0 + beta1*x)

mu 

mu <- round(mu)

mu

set.seed(235)
dpois_mu_x_1 <- dpois(0:20, lambda = mu[1])
set.seed(568)
dpois_mu_x_2 <- dpois(0:20, lambda = mu[2])
set.seed(397)
dpois_mu_x_3 <- dpois(0:20, lambda = mu[3])
set.seed(397)
dpois_mu_x_4 <- dpois(0:20, lambda = mu[4])
set.seed(690)
dpois_mu_x_5 <- dpois(0:20, lambda = mu[5])



M <- max(c(dpois_mu_x_1, dpois_mu_x_2, dpois_mu_x_3, 
           dpois_mu_x_4, dpois_mu_x_5))

xM <- c(1, 1 + M, 1 + 2*M, 1 + 3*M, 1 + 4*M)

ggplot(data = NULL, aes(x = xM, y = 1:20)) + 
  geom_segment(aes(x = xM[1], 
                   y = 0:20, 
                   xend = xM[1] + dpois_mu_x_1, 
                   yend = 0:20), size = 1, colour=""grey0"") + 
  geom_vline(xintercept = xM[1], linetype=2, colour=""grey0"") + 
  geom_segment(aes(x = xM[2], 
                   y = 0:20, 
                   xend = xM[2] + dpois_mu_x_2, 
                   yend = 0:20), size = 1, colour=""grey10"") +
  geom_vline(xintercept = xM[2], linetype=2, colour=""grey10"") + 
  geom_segment(aes(x = xM[3], 
                   y = 0:20, 
                   xend = xM[3] + dpois_mu_x_3, 
                   yend = 0:20), size = 1, colour=""grey10"") + 
  geom_vline(xintercept = xM[3], linetype=2, colour=""grey10"") + 
  geom_segment(aes(x = xM[4], 
                   y = 0:20, 
                   xend = xM[4] + dpois_mu_x_4, 
                   yend = 0:20), size = 1, colour=""grey10"") + 
  geom_vline(xintercept = xM[4], linetype=2, colour=""grey10"") + 
  geom_segment(aes(x = xM[5], 
                   y = 0:20, 
                   xend = xM[5] + dpois_mu_x_5, 
                   yend = 0:20), size = 1, colour=""grey10"") +
  geom_vline(xintercept = xM[5], linetype=2, colour=""grey10"") + 
  coord_cartesian(ylim = c(0,20), xlim = c(xM[1]-0.1, xM[5]+0.3)) + 
  geom_line(aes(x = xM, y = mu), size = 1, colour=""darkorange2"") + 
  geom_point(aes(x = xM[1], y = mu[1]), size=3.5, colour=""darkorange2"") + 
  geom_point(aes(x = xM[2], y = mu[2]), size=3.5, colour=""darkorange2"") + 
  geom_point(aes(x = xM[3], y = mu[3]), size=3.5, colour=""darkorange2"") +
  geom_point(aes(x = xM[4], y = mu[4]), size=3.5, colour=""darkorange2"") +
  geom_point(aes(x = xM[5], y = mu[5]), size=3.5, colour=""darkorange2"") + 
  xlab(""X (Predictor Variable)"") + 
  ylab(""Y (Count Variable)"") + 
  scale_x_continuous(breaks = xM, labels = 1:5)
`

Please tag me on Twitter at @IsabellaGhement if you have any questions or comments about the code.  

----------------------------
mjskay:

Thanks for this! I'll have to think about what this could look like for the slabinterval family. For those geoms a solution to this would probably come out looking more like a stat_histinterval but with bin sizes automatically set to 1 and centered on each integer. The segment-based approach would probably have to be a new geom altogether.

As for auto-detecting discrete distributions, the only thing I can come up with at the moment is to check if a random draw from the distribution is an integer (I had hoped checking a quantile would work, but all the quantile functions in base seem to return floating point values even if they are from discrete distributions).

----------------------------
isabellaghement:

You're welcome!   If the segments (or bar charts) are used to plot density values associated with integers - as is the case in my plot - I think there might be a ""hacky"" way to detect that by paying attention to the warnings thrown by R.  

Compare this:

`dpois(c(0,1,2,3), lambda = 2)`

> dpois(c(0,1,2,3), lambda = 2)
[1] 0.1353353 0.2706706 0.2706706 0.1804470

with this:

`dpois(c(0,1.2,2.3,3.4), lambda = 2)`

> dpois(c(0,1.2,2.3,3.4), lambda = 2)
[1] 0.1353353 0.0000000 0.0000000 0.0000000
Warning messages:
1: In dpois(c(0, 1.2, 2.3, 3.4), lambda = 2) : non-integer x = 1.200000
2: In dpois(c(0, 1.2, 2.3, 3.4), lambda = 2) : non-integer x = 2.300000
3: In dpois(c(0, 1.2, 2.3, 3.4), lambda = 2) : non-integer x = 3.400000

So, behind the scenes, you could feed a non-integer value x to the dpois() (or some other discrete density) function as part of the test to see if it's a discrete density, collect the warning produced by R and then search in that (vector of) warning(s) for the phrase _non-integer x_.  If you find that phrase (presuming there is a warning to begin with), you can declare the density as being discrete.  

To collect warnings after calling dpois(), you can try something like this (inspired by the thread https://stackoverflow.com/questions/3903157/how-can-i-check-whether-a-function-call-results-in-a-warning):
 
    library(purrr)

    ##create a version of dpois() which will return not just results, but also warnings
    qdpois <- quietly(dpois) 

    ##apply the version of dpois which will return the results and warnings
    dens <- qdpois(c(0,1.2,2.3,3.4), lambda = 2)

    ##access the results
    dens$result

    ##access the warnings 
    dens$warnings


What comes out from the above code will be something like this: 

    > dens
    $result
    [1] 0.1353353 0.0000000 0.0000000 0.0000000

    $output
    [1] """"

    $warnings
    [1] ""non-integer x = 1.200000"" ""non-integer x = 2.300000"" ""non-integer x = 3.400000""

    $messages
    character(0)

Then you can pull dens$warnings and check if it has non-zero length first.  If it does have non-zero length, check if any of the warnings include the phrase  ""non-integer x"" (or even just ""non-integer"").  If yes, declare dpois to be a discrete distribution. 

This presumes that R throws such a warning any time you try to compute a discrete density for a non-integer value (not sure that is the case - you would need to check this).
  
Another way to verify you are dealing with a discrete distribution would be to check whether the density distribution name (e.g., dpois) falls among a comprehensive list of all discrete density distributions.  

The third way to verify this is to place the onus on the user to declare the distribution type.  For instance, add a parameter like ""type"" or ""distribution_type"" to your function and ask the user to set it to ""discrete"" or ""continuous"".  Or add a parameter called ""discrete"" and ask the user to set it to TRUE (for discrete densities) or FALSE (for continuous densities), etc.

Fun programming problem! 😊


----------------------------
mjskay:

I think of the various options, using `is.integer(rdist(1, ...))` for whatever `dist` seems the most reliable to me, as it would be less brittle than parsing error messages. 

Maintaining a list of distributions is an interesting suggestion; if/when {distributional} gets support for a function that returns whether its distributions are discrete that will be an essentially similar solution. Probably the best path is a PR to {distributional} that does that with a fallback to `is.integer(rdist(1, ...))` for unknown distributions.

----------------------------
mjskay:

I've got a first attempt at this working on the `dev` branch currently. To fit in with the existing slab geometry I went with a fill histogram style display rather than a spike histogram. Here's an example similar to yours above:

``` r
library(tidyverse)
library(ggdist)
library(distributional)

tibble(lambda = c(13,7,4,3,2)) %>% 
  ggplot(aes(x = fct_rev(factor(lambda)), dist = dist_poisson(lambda))) + 
  stat_dist_halfeye(interval_color = NA, slab_color = ""gray50"") + 
  # re-using pointinterval here to get positions for the lines
  stat_dist_pointinterval(geom = ""line"", .width = .5, size = 1, group = 1)
```

![](https://i.imgur.com/K8DlWBQ.png)

<sup>Created on 2021-07-01 by the [reprex package](https://reprex.tidyverse.org) (v2.0.0)</sup>


----------------------------
isabellaghement:

This looks nice but the fill histogram style implies (to me at least) that the Poisson distribution is treated as if it is a _continuous_ distribution rather than a _discrete_ one.  For a discrete distribution, the spike histogram would be more appropriate.    

Just today I came upon a similar figure in Sara Stoudt's slides on GAM models (see figure on the right, which is what we should be aiming for): 

![image](https://user-images.githubusercontent.com/57458528/124330411-377a0480-db42-11eb-8a0c-d05e66f8fc41.png)

The full slides can be accessed here:  https://github.com/SocialScienceDataLab/MZES_GAMs. 


----------------------------
mjskay:

I had considered whether or not the histoline version implies the distribution is continuous, and in context I am not convinced it does: as a user you are asking for a density and then getting back a representation that is binned at an integer resolution and is clearly not smooth. That said, I could be wrong :)

I do like the more typical histogram look you suggest though! I should have mentioned that you can use `outline_bars = TRUE` to get that, as with the existing histinterval stat:

```r
library(tidyverse)
library(ggdist)
library(distributional)

tibble(lambda = c(13,7,4,3,2)) %>% 
  ggplot(aes(x = fct_rev(factor(lambda)), dist = dist_poisson(lambda))) + 
  stat_dist_halfeye(interval_color = NA, slab_color = ""gray85"", outline_bars = TRUE) + 
  # re-using pointinterval here to get positions for the lines
  stat_dist_pointinterval(geom = ""line"", .width = .5, size = 1, group = 1)
```
![image](https://user-images.githubusercontent.com/6345019/124331501-efb0a880-db54-11eb-8ad0-b1d0a10ba2ce.png)



----------------------------
isabellaghement:

This last plot looks much better to me.  I essentially look at the **footprint** of the histogram - does it imply a continuous range of data values represented by that distribution or a discrete 'range'? 

This one implies a continuous range of data values: 

![image](https://user-images.githubusercontent.com/57458528/124336378-afe8c180-db52-11eb-9624-53d3e3cf637d.png)

This one at least implies there could be a separation between data values so it's more useful for representing a discrete distribution such a Poisson, especially if the outline colours for the bars will be set to white rather than light grey: 

![image](https://user-images.githubusercontent.com/57458528/124337161-0dcad880-db56-11eb-8ffb-579bc564a56a.png)


You seem to look at the **contour** of the histogram, which is a different animal altogether.  To me, the **footprint** conveys information about where the data values actually live (e.g., a continuous range of values; a discrete set of values) . The **contour** conveys information about how many data values actually live in specific portions of that range.  


----------------------------
mjskay:

I see your point, but I find the outlines visually noisy without adding much useful information, and I'd rather not have the defaults of this function be different from histinterval anyway (which also defaults to `outline_bars = FALSE`).

The example I included in the vignette inspired by this discussion (thanks!) takes a slightly different approach to emphasizing the discrete nature of the distribution while also showing the use of multiple redundant encodings:

```r
library(tidyverse)
library(ggdist)
library(distributional)

tibble(
  group = c(""a"",""b"",""c"",""d"",""e""),
  lambda = c(13,7,4,3,2)
) %>% 
  ggplot(aes(x = group)) + 
  stat_dist_slab(aes(dist = dist_poisson(lambda), fill = stat(pdf))) + 
  geom_line(aes(y = lambda, group = NA), size = 1) +
  geom_point(aes(y = lambda), size = 2.5) +
  theme_ggdist()
```
![image](https://user-images.githubusercontent.com/6345019/124791001-49c4bb80-df11-11eb-8c62-ed1898f70031.png)

(Yes, the computed variable is called `pdf` not `pmf` since the name `pdf` is already used in stat_dist_slabinterval and changing it for different distribution types would break the generality of the code; I consider this no more egregious than the fact that the pmf of a Poisson in R is called `dpois`).

Thanks for the feedback! Closing this now.",TRUE,enhancement,2020-06-15 06:07:39,2021-07-07 16:01:18,enhancement,,CLOSED,2021-07-07 16:02:44,3.0.0,,MDU6SXNzdWU2Mzg1NzI5Mjg=
18,https://github.com/mjskay/ggdist/issues/18,https://github.com/mjskay/ggdist/issues/18,mjskay,Detect finite limits in distribution support,"Basically, if one end of `p_limits` is `NA`, check if that corresponding end is finite and if so use that, else use the current default (.001 or .99)",TRUE,,FALSE,enhancement,2020-06-15 06:05:31,2020-11-24 05:48:14,enhancement,,CLOSED,2020-11-24 05:48:14,NA,,MDU6SXNzdWU2Mzg1NzE5MTA=
17,https://github.com/mjskay/ggdist/issues/17,https://github.com/mjskay/ggdist/issues/17,mjskay,Add intro to all params to slabinterval vignette,Maybe start with breakdown of the base type before giving all the shortcuts ,TRUE,#NAME?,FALSE,docs,2020-06-15 05:53:15,2021-12-06 00:16:43,documentation,,CLOSED,2021-12-06 00:16:43,NA,,MDU6SXNzdWU2Mzg1NjYwOTI=
16,https://github.com/mjskay/ggdist/issues/16,https://github.com/mjskay/ggdist/issues/16,mjskay,Add a fill_ramp and color_ramp aesthetics for lineribbons and slabs,"Or something like that. See @mitchelloharawild's comment: https://github.com/mjskay/ggdist/issues/14#issuecomment-642373597

Thinking about this more, it is probably useful for gradientinterval as well, since it seems the case that R graphics devices don't really support alpha gradients in the way they would need to for it to be reliable. 

However, I am not sure think lightness is the right axis. I think generically allowing a color ramp from the fill to an arbitrary color (default white) in Lab space would work. Then `0` would be the other color, `1` would be the fill color, and the default limits would be set to include 0 in the input domain for continuous scales. Probably would use the same approach as alpha for discrete scales (range has lower limit 0.1). 

This way, if someone wants to use a gradient with a non-white background they can do that well enough (as long as no gradients overlap, which --- well --- if someone is trying to do that there's probably a bigger problem).

Perhaps a better name then is `scale_fill_ramp`

- [x] basic impl
- [x] add to slabinterval
- [x] add to lineribbon
  - [x] fix legend
- [x] tests for slabinterval
- [x] ~~rewrite gradientinterval with this~~ doesn't solve the problem anyway
- [x] add examples to vignettes
  - [x] slabinterval
  - [x] lineribbon
- [x] add examples to function docs
  - [x] slabinterval",TRUE,,TRUE,enhancement,2020-06-11 04:54:58,2020-12-28 06:59:19,enhancement,,CLOSED,2020-12-28 06:59:19,NA,,MDU6SXNzdWU2MzY3MTU5NDU=
14,https://github.com/mjskay/ggdist/issues/14,https://github.com/mjskay/ggdist/issues/14,mjskay,Support distributional package,"Allow dist vectors in the dist aesthetic. See https://github.com/mitchelloharawild/distributional/issues/24

- [x] fix grouping with dists
- [x] add tests
- [x] document distribution form of dist aesthetic
- [x] make sure NAs are supported
- [x] add to vignettes
  - [x] something in slabinterval
  - [x] something in freq-uncertainty-vis, possibly using an example from something in fable or related packages? Need to wait on https://github.com/mitchelloharawild/distributional/issues/28 before doing this since student_t support is needed",TRUE,"----------------------------
mjskay:

@mitchelloharawild this should now be working with all `stat_dist_...` geoms on the `dev` branch of {ggdist}. Some examples:

```r
dist_df = tribble(
    ~group, ~subgroup, ~dist,
    ""a"",       ""h"",     dist_normal(5, 1),
    ""b"",       ""h"",     dist_normal(7, 1.5),
    ""c"",       ""h"",     dist_normal(8, 1),
    ""c"",       ""i"",     dist_normal(9, 1),
    ""c"",       ""j"",     dist_normal(7, 1)
)
dist_df %>%
  ggplot(aes(x = group, dist = dist, fill = subgroup)) +
  stat_dist_eye(position = ""dodge"")
```
![image](https://user-images.githubusercontent.com/6345019/84334915-90ef4a00-ab61-11ea-99b7-02bf88da3bf2.png)

I'm particularly fond of how the syntax works out with dist_xxx() embedded in aes():

```r
data.frame(alpha = seq(5, 100, length.out = 10)) %>%
  ggplot(aes(y = """", dist = dist_beta(alpha, 10), color = alpha)) +
  stat_dist_slab(fill = NA) +
  coord_cartesian(expand = FALSE) +
  scale_color_viridis_c() +
  ggtitle(""Beta(alpha,10) distribution"")
```
![image](https://user-images.githubusercontent.com/6345019/84335113-1672fa00-ab62-11ea-9398-72b9794550d3.png)

plus the obligatory lineribbon:

```r
m_mpg = lm(mpg ~ hp * cyl, data = mtcars)

mtcars %>%
  group_by(cyl) %>%
  data_grid(hp = seq_range(hp, n = 101)) %>%
  broom::augment(m_mpg, newdata = .) %>%
  ggplot(aes(x = hp, fill = ordered(cyl), color = ordered(cyl))) +
  stat_dist_lineribbon(
    aes(dist = dist_normal(.fitted, .se.fit)), 
    alpha = 1/4
  ) +
  geom_point(aes(y = mpg), data = mtcars) +
  scale_fill_brewer(palette = ""Set2"") +
  scale_color_brewer(palette = ""Dark2"")
```
![image](https://user-images.githubusercontent.com/6345019/84335570-217a5a00-ab63-11ea-9392-d334827f593b.png)

This is really nice I think! Cleans up the syntax very well.

----------------------------
mitchelloharawild:

:heart_eyes: 
Very excited to see this in action!

----------------------------
mitchelloharawild:

Is it possible to add a legend for the ribbon shade? Or is the shade currently handled with overlapping transparent ribbons?
This is how distributional handles the ~~lineribbon~~ ribbon geom (adding a line is with `geom_line()`)

``` r
library(distributional)
library(modelr)
library(dplyr)
#> 
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#> 
#>     filter, lag
#> The following objects are masked from 'package:base':
#> 
#>     intersect, setdiff, setequal, union
library(ggplot2)
m_mpg = lm(mpg ~ hp * cyl, data = mtcars)

mtcars %>%
  group_by(cyl) %>%
  data_grid(hp = seq_range(hp, n = 101), level = c(50, 80, 95)) %>%
  broom::augment(m_mpg, newdata = .) %>%
  mutate(
    dist = dist_normal(.fitted, .se.fit),
    hilo = hilo(dist, level)
  ) %>% 
  ggplot(aes(x = hp, fill = ordered(cyl), color = ordered(cyl))) +
  geom_hilo_ribbon(aes(hilo = hilo)) +
  geom_point(aes(y = mpg), data = mtcars) +
  scale_fill_brewer(palette = ""Set2"") +
  scale_color_brewer(palette = ""Dark2"")
```

![](https://i.imgur.com/vdaYNAT.png)

<sup>Created on 2020-06-11 by the [reprex package](https://reprex.tidyverse.org) (v0.3.0)</sup>

----------------------------
mjskay:

Hmm, you are doing that by mapping level onto an aesthetic that manipulates the lightness of the fill color or something like that? Interesting idea, could add something like that to lineribbon.

Currently lineribbon's default is to map level onto the fill color itself and then leave setting the fill scale up to the user. The example I gave above overrides that default and then uses alpha so the ribbons in each group overplot. The default lineribbon approach was more designed to do something like this:

```r
mtcars %>%
  group_by(cyl) %>%
  data_grid(hp = seq_range(hp, n = 101)) %>%
  augment(m_mpg, newdata = .) %>%
  ggplot(aes(x = hp, color = ordered(cyl))) +
  stat_dist_lineribbon(aes(dist = dist_normal(.fitted, .se.fit))) +
  geom_point(aes(y = mpg), data = mtcars) +
  scale_fill_grey(start = .9, end = .7) +
  scale_color_brewer(palette = ""Dark2"")
```

![image](https://user-images.githubusercontent.com/6345019/84345904-a32ab180-ab7c-11ea-80b8-a0e31c05d7f0.png)


Admittedly legends are a bit of blind spot for me --- I basically never use them as I prefer direct labelling.

----------------------------
mitchelloharawild:

> Hmm, you are doing that by mapping level onto an aesthetic that manipulates the lightness of the fill color or something like that? Interesting idea, could add something like that to lineribbon.

Yes, it converts the RGB to HSL and changes the luminance according to the aesthetic (https://github.com/mitchelloharawild/distributional/blob/48a17b9916b5caaf069b4533a63851a3ea79bb35/R/geom_hilo.R#L171-L177)
It can be tricky to choose the right range for the luminance, but some trial and error gave me `seq(90 - pmin((n_prob - 1)*10, 30), 90)`. This can probably be improved by someone with a better understanding of colour theory.

This luminance change currently occurs in the geom (https://github.com/mitchelloharawild/distributional/blob/48a17b9916b5caaf069b4533a63851a3ea79bb35/R/geom_hilo.R#L148). Ideally it would be possible to to provide `fill_luminance` and `colour_luminance` aesthetics which modify the `fill` and `colour` for any geom, but I think this would need to happen in ggplot2.


----------------------------
mitchelloharawild:

There's also a feature of the guide (which is probably poor practice, but I don't know a better way) which changes the level aesthetic between discrete and continuous legends (https://github.com/mitchelloharawild/distributional/blob/48a17b9916b5caaf069b4533a63851a3ea79bb35/R/scale-level.R#L68-L120).

That way if you set `level = 50:99` it doesn't flood your screen with the guide legend and instead converts to a guide colourbar. 

The correct approach for this is probably to default to a colourbar as level is numeric, but I think of the level as being discrete (ordered) or continuous depending on the number of levels that are shown.

----------------------------
mjskay:

Nice!

> Ideally it would be possible to to provide fill_luminance and colour_luminance aesthetics which modify the fill and colour for any geom, but I think this would need to happen in ggplot2.

Yeah, some features to better support multivariate color scales in base ggplot2 would be cool. Barring that, creating a custom scale for luminance seems a pretty reasonable workaround.

----------------------------
mitchelloharawild:

Any ideas on how multivariate distributions from `{distributional}` could be plotted with `{ggdist}`?
This need has come about when rewriting plotting functions in `{fabletools}` to use `{ggdist}`.

Perhaps another grouping stat needs to be created for each dimension of the distribution?

``` r
library(ggplot2)
library(distributional)
library(ggdist)

library(fable)
#> Loading required package: fabletools

fc <- as_tsibble(cbind(mdeaths, fdeaths), pivot_longer = FALSE) %>%
  model(VAR(vars(mdeaths, fdeaths) ~ AR(3))) %>% 
  forecast()

fc
#> # A fable: 24 x 5 [1M]
#> # Key:     .model [1]
#>    .model                        index .distribution .mean_mdeaths .mean_fdeaths
#>    <chr>                         <mth>        <dist>         <dbl>         <dbl>
#>  1 VAR(vars(mdeaths, fdeaths… 1980 Jan        MVN[2]         1486.          575.
#>  2 VAR(vars(mdeaths, fdeaths… 1980 Feb        MVN[2]         1445.          558.
#>  3 VAR(vars(mdeaths, fdeaths… 1980 Mar        MVN[2]         1369.          528.
#>  4 VAR(vars(mdeaths, fdeaths… 1980 Apr        MVN[2]         1340.          505.
#>  5 VAR(vars(mdeaths, fdeaths… 1980 May        MVN[2]         1327.          497.
#>  6 VAR(vars(mdeaths, fdeaths… 1980 Jun        MVN[2]         1349.          505.
#>  7 VAR(vars(mdeaths, fdeaths… 1980 Jul        MVN[2]         1395.          522.
#>  8 VAR(vars(mdeaths, fdeaths… 1980 Aug        MVN[2]         1442.          540.
#>  9 VAR(vars(mdeaths, fdeaths… 1980 Sep        MVN[2]         1477.          554.
#> 10 VAR(vars(mdeaths, fdeaths… 1980 Oct        MVN[2]         1495.          561.
#> # … with 14 more rows

fc %>% 
  ggplot(aes(x = as.Date(index), dist = .distribution, fill_ramp = stat(level))) + 
  stat_dist_lineribbon(fill = ""blue"", .width = c(.8, .95), point_interval = mean_qi)
#> Warning: Duplicated aesthetics after name standardisation: point_interval
```

![](https://i.imgur.com/D2qOcfN.png)

``` r
fc %>% 
  autoplot()
```

![](https://i.imgur.com/73iT0ET.png)

<sup>Created on 2021-11-19 by the [reprex package](https://reprex.tidyverse.org) (v2.0.0)</sup>

----------------------------
mjskay:

Hmm, very good question. You can finagle it by manually pulling out the marginal distributions...

``` r
library(ggplot2)
library(distributional)
library(ggdist)
library(fable)
#> Loading required package: fabletools

fc <- as_tsibble(cbind(mdeaths, fdeaths), pivot_longer = FALSE) %>%
  model(VAR(vars(mdeaths, fdeaths) ~ AR(3))) %>% 
  forecast()

fc
#> # A fable: 24 x 4 [1M]
#> # Key:     .model [1]
#>    .model                      index .distribution .mean[,""mdeaths~ [,""fdeaths""]
#>    <chr>                       <mth>        <dist>            <dbl>        <dbl>
#>  1 VAR(vars(mdeaths, fdeat~ 1980 Jan        MVN[2]            1486.         575.
#>  2 VAR(vars(mdeaths, fdeat~ 1980 Feb        MVN[2]            1445.         558.
#>  3 VAR(vars(mdeaths, fdeat~ 1980 Mar        MVN[2]            1369.         528.
#>  4 VAR(vars(mdeaths, fdeat~ 1980 Apr        MVN[2]            1340.         505.
#>  5 VAR(vars(mdeaths, fdeat~ 1980 May        MVN[2]            1327.         497.
#>  6 VAR(vars(mdeaths, fdeat~ 1980 Jun        MVN[2]            1349.         505.
#>  7 VAR(vars(mdeaths, fdeat~ 1980 Jul        MVN[2]            1395.         522.
#>  8 VAR(vars(mdeaths, fdeat~ 1980 Aug        MVN[2]            1442.         540.
#>  9 VAR(vars(mdeaths, fdeat~ 1980 Sep        MVN[2]            1477.         554.
#> 10 VAR(vars(mdeaths, fdeat~ 1980 Oct        MVN[2]            1495.         561.
#> # ... with 14 more rows

fc_with_margins <- dplyr::bind_cols(
  tibble::as_tibble(vctrs::vec_rep(fc, times = ncol(mean(fc$.distribution)))),
  tibble::tibble(
    .variable = rep(colnames(mean(fc$.distribution)), each = nrow(fc)),
    .marginal_dist = dist_normal(c(mean(fc$.distribution)), c(sqrt(variance(fc$.distribution))))
  )
)

fc_with_margins
#> # A tibble: 48 x 6
#>    .model            index .distribution .mean[,""mdeaths~ [,""fdeaths""] .variable
#>    <chr>             <mth>        <dist>            <dbl>        <dbl> <chr>    
#>  1 VAR(vars(mdea~ 1980 Jan        MVN[2]            1486.         575. mdeaths  
#>  2 VAR(vars(mdea~ 1980 Feb        MVN[2]            1445.         558. mdeaths  
#>  3 VAR(vars(mdea~ 1980 Mar        MVN[2]            1369.         528. mdeaths  
#>  4 VAR(vars(mdea~ 1980 Apr        MVN[2]            1340.         505. mdeaths  
#>  5 VAR(vars(mdea~ 1980 May        MVN[2]            1327.         497. mdeaths  
#>  6 VAR(vars(mdea~ 1980 Jun        MVN[2]            1349.         505. mdeaths  
#>  7 VAR(vars(mdea~ 1980 Jul        MVN[2]            1395.         522. mdeaths  
#>  8 VAR(vars(mdea~ 1980 Aug        MVN[2]            1442.         540. mdeaths  
#>  9 VAR(vars(mdea~ 1980 Sep        MVN[2]            1477.         554. mdeaths  
#> 10 VAR(vars(mdea~ 1980 Oct        MVN[2]            1495.         561. mdeaths  
#> # ... with 38 more rows, and 1 more variable: .marginal_dist <dist>

fc_with_margins %>%
  ggplot(aes(x = as.Date(index), dist = .marginal_dist, fill_ramp = stat(level))) + 
  stat_dist_lineribbon(fill = ""blue"", .width = c(.8, .95), point_interval = mean_qi) +
  facet_wrap(~ .variable, scales = ""free"")
```

![](https://i.imgur.com/qvfTY2Y.png)

<sup>Created on 2021-11-18 by the [reprex package](https://reprex.tidyverse.org) (v2.0.1)</sup>

But this is obviously not a great solution. 

One solution might be to create a function for ""flattening"" or ""unnesting"" columns with multivariate distributions into two columns, one with the name of the margin and one with the marginal distribution (basically a generic version of the operation above). I think that would provide the needed flexibility to either facet on the marginal variable or map it onto the `group` aesthetic to create multiple ribbons within one facet. Dunno if something like that should live in ggdist or in distributional; I'm fine with either (and I'm not sure what your plans are for how the multivariate API will look in distributional). 

----------------------------
mitchelloharawild:

Yes - this is similar to how fable currently handles multivariate distributions. However as fable works on plotting `<hilo>` intervals rather than distributions, it is easier to compute the intervals of the multivariate distribution and then plot each interval separately. While I agree that having a method for marginalising multivariate distributions would be neat, I think that requiring it for plotting limits potential future graphics options.

With the rework of distributional methods (https://github.com/mitchelloharawild/distributional/issues/52#issuecomment-939891809), multivariate distributions now give matrix outputs - each variate as a (named) column. I think it would make most sense for `{ggdist}` to take this output and rearrange it into a long form - creating a new group from the column names. I'm not sure how this would look internally for `{ggdist}`, but I imagine that it could be placed in the `Stat` calculations. It might still be tricky in `{fabletools}`, as I'm not sure if `after_stat()` variables can be used for facetting - I think I'd still have to workaround it somehow.

----------------------------
mjskay:

> With the rework of distributional methods (mitchelloharawild/distributional#52 (comment)), multivariate distributions now give matrix outputs - each variate as a (named) column. I think it would make most sense for {ggdist} to take this output and rearrange it into a long form - creating a new group from the column names. I'm not sure how this would look internally for {ggdist}, but I imagine that it could be placed in the Stat calculations.

Hmm, this could probably happen somewhere in the `point_interval()` family. Then it would be supported either in the `stat`s or as a pre-processing step with `point_interval` (after which you could use the `geom` form instead of the `stat` --- which would allow you to do faceting on the variable without using `after_stat`).",FALSE,enhancement,2020-06-09 15:29:32,2020-11-24 05:48:14,documentation,,CLOSED,2021-11-19 04:41:42,NA,,MDU6SXNzdWU2MzU1MzczNzE=
13,https://github.com/mjskay/ggdist/issues/13,https://github.com/mjskay/ggdist/issues/13,mjskay,export GeomXXX for some remaining geoms,"- [x] GeomDots
- [x] GeomDotsinterval
- [x] GeomSlab
- [x] GeomSlabinterval
- [x] StatDistSlabinterval
- [x] StatSampleSlabinterval
- [x] StatSlabinterval",TRUE,,FALSE,cleanup,2020-06-06 16:27:52,2020-06-06 19:26:03,,,CLOSED,2020-06-06 19:26:03,NA,,MDU6SXNzdWU2MzI1NzA1NDU=
12,https://github.com/mjskay/ggdist/issues/12,https://github.com/mjskay/ggdist/issues/12,mjskay,Next CRAN release,"(this issue is never closed, just re-used for the next release)

* [x] check for existing problems on [CRAN checks for ggdist](https://cran.r-project.org/web/checks/check_results_ggdist.html)
* [x] double-check [CRAN policies](https://cran.r-project.org/web/packages/policies.html)
* [x] check package for large files: output from `devtools::build()` is less than 5MB
* [x] remove any `Remotes` in DESCRIPTION and downgrade those packages back to CRAN versions
* [x] update R and all packages
  * [x] `devtools::install_dev_deps()`
  * [x] `update.packages(ask = FALSE)`
* [x] bump version and date
  * [x] in DESCRIPTION
  * [x] in NEWS
* [x] `devtools::check(remote = TRUE, manual = TRUE)`
* [x] check tests on {tidybayes} manually
* [x] `revdepcheck::revdep_check(num_workers = 6)`
* [x] update NEWS
* [x] `spelling::spell_check_package()`
* [x] `devtools::document()`
* [x] `devtools::install()`
* [x] rebuild README
* [x] `pkgdown::clean_site()`
* [x] `pkgdown::build_site(run_dont_run = TRUE)`
* [x] `devtools::check(remote = TRUE, manual = TRUE)`
  * [x] R-release, on Windows
  * [x] Whatever platforms on Github actions
* [x] `devtools::check_win_release()`
* [x] `devtools::check_win_devel()`
* [x] `devtools::check_win_oldrelease()`
* [x] write `cran-comments.md`
* [x] `devtools::release()`

After package goes live on CRAN:

* [x] `pkgdown::build_news()`
* [x] merge `dev` onto `master` and `cran`
* [x] tag release
* [x] double check zenodo entry
  * [x] authors
  * [x] license (GPL >= 3)
  * [x] title (ggdist: Visualizations of distributions and uncertainty)
* [x] `revdepcheck::revdep_reset()`
* [x] bump to a new dev version on dev branch
* [ ] tweet

Template loosely based on <https://github.com/r-lib/usethis/issues/338>",FALSE,,FALSE,internal,2020-06-05 20:38:32,NA,,,OPEN,2023-01-18 17:27:32,NA,,MDU6SXNzdWU2MzE5MzkxOTM=
11,https://github.com/mjskay/ggdist/issues/11,https://github.com/mjskay/ggdist/issues/11,mjskay,allow calculating all distribution functions at once in stat / stat_dist,"then stick them into mappings users can use, like pdf and cdf. Would allow experimentation with even weirder custom geoms (like the Correll-style violins with faded tails)

- [x] stat_dist_...
- [x] stat_sample_...
- [x] ~~fix the appearance of some NAs in the CDF calculation in stat_dist. See here: https://github.com/mjskay/tidybayes/issues/136#issuecomment-686033107~~ this is due to interval data also being processed in the same geom; the fix is to set na.translate = FALSE on the fill scale. Added to examples
- [x] add a function for making intervals from cdfs (maybe `cut_cdf_qi`?)
  - [x] re-export from tidybayes
  - [x] add example to slabinterval vignette
- [x] add docs
- [x] add example to vignette",TRUE,,FALSE,"refactor,formalism",2020-06-05 19:46:08,2020-11-24 06:38:44,"documentation,enhancement",,CLOSED,2020-11-24 06:38:44,NA,,MDU6SXNzdWU2MzE4OTUxNjU=
9,https://github.com/mjskay/ggdist/issues/9,https://github.com/mjskay/ggdist/issues/9,mjskay,remove automatic xmin/xmax from lineribbon,,TRUE,,FALSE,cleanup,2020-06-05 18:20:34,2020-06-05 19:32:56,,,CLOSED,2020-06-05 19:32:56,NA,,MDU6SXNzdWU2MzE4MjQ1Mjg=
8,https://github.com/mjskay/ggdist/issues/8,https://github.com/mjskay/ggdist/issues/8,mjskay,fix tests,drop models folder at least,TRUE,,FALSE,cleanup,2020-06-05 05:48:12,2020-06-05 17:50:24,,,CLOSED,2020-06-05 17:50:24,NA,,MDU6SXNzdWU2MzEzMjk5NDE=
7,https://github.com/mjskay/ggdist/issues/7,https://github.com/mjskay/ggdist/issues/7,mjskay,port over relevant issues from tidybayes,,TRUE,"----------------------------
bwiernik:

Did you know about GitHub's transfer issue feature shown in the right column of the issue page?

----------------------------
mjskay:

Yeah I just have to do them all one at a time so... Haven't gotten to it 🙂",FALSE,internal,2020-06-05 05:25:56,2020-11-25 19:04:06,,,CLOSED,2020-11-25 19:04:06,NA,,MDU6SXNzdWU2MzEzMjIxMDA=
6,https://github.com/mjskay/ggdist/issues/6,https://github.com/mjskay/ggdist/issues/6,mjskay,add student_t dist,,TRUE,,FALSE,enhancement,2020-06-05 05:25:44,2020-06-05 18:15:18,,,CLOSED,2020-06-05 18:15:18,NA,,MDU6SXNzdWU2MzEzMjIwNDE=
5,https://github.com/mjskay/ggdist/issues/5,https://github.com/mjskay/ggdist/issues/5,mjskay,switch back to good size images for CRAN vignettes,now that we have a bit of extra space ,TRUE,,FALSE,docs,2020-06-05 05:25:14,2020-06-05 18:37:53,,,CLOSED,2020-06-05 18:37:53,NA,,MDU6SXNzdWU2MzEzMjE4Mjg=
4,https://github.com/mjskay/ggdist/issues/4,https://github.com/mjskay/ggdist/issues/4,mjskay,remove pkgdown eval guards on vignettes,,TRUE,,FALSE,cleanup,2020-06-05 05:24:26,2020-06-05 17:50:33,,,CLOSED,2020-06-05 17:50:33,NA,,MDU6SXNzdWU2MzEzMjE1NTU=
3,https://github.com/mjskay/ggdist/issues/3,https://github.com/mjskay/ggdist/issues/3,mjskay,set up coverage,,TRUE,,FALSE,cleanup,2020-06-05 03:32:59,2020-06-05 19:11:17,,,CLOSED,2020-06-05 19:11:17,NA,,MDU6SXNzdWU2MzEyODUyOTQ=
2,https://github.com/mjskay/ggdist/issues/2,https://github.com/mjskay/ggdist/issues/2,mjskay,update github preview,github-preview.pdf and readme preview (preview.pdf),TRUE,,FALSE,cleanup,2020-06-05 03:27:45,2020-06-05 04:32:19,,,CLOSED,2020-06-05 04:32:19,NA,,MDU6SXNzdWU2MzEyODM0NzA=
1,https://github.com/mjskay/ggdist/issues/1,https://github.com/mjskay/ggdist/issues/1,mjskay,get a doi from zenodo,"update inst/CITATION, README, etc",TRUE,,FALSE,internal,2020-06-05 03:10:44,2020-06-05 19:11:48,,,CLOSED,2020-06-05 19:11:48,NA,,MDU6SXNzdWU2MzEyNzc1NjE=
37,https://github.com/mjskay/ggdist/issues/37,https://github.com/mjskay/ggdist/issues/37,fkgruber,stat_lineribbon and multimodal distributions,"Hi
I'm using stat_lineribbon with mode_hdi to plot a multimodal distribution changing with time.

It correctly plots the uncertainty in splitted intervals but it only shows a global mode. It is possible to show all the modes instead of the biggest one only? Is this functionality implemented?

thanks
FKG",FALSE,"----------------------------
mjskay:

Yeah there isn't an easy way to do this currently, unfortunately. If you had code that got you the second mode you could plot it separately just using a geom_line... I suppose given the two sets of intervals you could subset the data and find the mode within the two regions of high density. This could be done prior to plotting, then you would plot the ribbons with geom_lineribbon(color = NA) (to turn off the line) then plot the lines separately using geom_line.

I do wonder a bit why you need to plot a line along each mode? Without being able to see the chart I obviously can't say, but my guess is the location of the second mode is probably fairly obvious visually even without the line along it.

----------------------------
fkgruber:

Hi
I generated some data with multimodal sample:
```
library(tidyverse)
library(tidybayes)

N = 100
Nt = 50
Ns = 200
mydata = tibble(
  patid = paste0(""pat"", 1:N), 
  treatment = sample(c('d1', ""d2""), N, replace = T)
  )
mydata = mydata %>% group_by(patid) %>%
  do((function(df){
    param1 = runif(Ns, -0.3, -0.1)
    param2 = runif(Ns, -1.5, -1.3)
    param2b = runif(Ns, -1, -0.5)
    ng = sample(c(1, 2), Ns, prob = c(0.5, 0.5), replace = T)
    time = seq(1, 20, length.out = Nt)
    map_df(time,
           function(tt){
             tibble(
               samples = 1:Ns, 
               time = tt, 
               treatment = df$treatment, 
               Surv = ifelse(treatment == ""d1"",
                             exp(param1* time),
                             exp(ifelse(ng == 1, param2, param2b)* time))
             )
           })
  })(.))
```

the intervals I'm getting are odd:

```
mydata %>% ggplot(aes(x = time, y = Surv, fill = treatment)) +
  stat_lineribbon(point_interval = median_hdi, .width = c(0.8))+
  scale_fill_brewer()
```
![image](https://user-images.githubusercontent.com/4311763/82687571-73dfef00-9c25-11ea-9484-4a708f446b88.png)

However, if I manually create this plot:
```
mydatasum = mydata %>%
    group_by(time, treatment) %>% 
    do(.,{
      allhdis = HDInterval::hdi(density(.$Surv), 0.8, allowSplit = TRUE)
      med = median(.$Surv)
      if(class(allhdis) == 'matrix'){
	data.frame(
          Median = med, 
          lower = allhdis[, ""begin""],
          upper = allhdis[, ""end""],
          group = 1:nrow(allhdis)
        )
      }else{
	data.frame(
		   Median = med, 
          lower = allhdis[""lower""], upper = allhdis[""upper""],
          group = 1
		   )
	}
    })

mydatasum %>%
  ggplot(aes(x = time, y = Median)) + 
  geom_ribbon(aes(
    fill = treatment, 
    ymin = lower,
                  ymax = upper,
                  group = interaction(treatment, group))) + 
  geom_line(aes(group = treatment)) +
  scale_fill_brewer() 
```

![image](https://user-images.githubusercontent.com/4311763/82687690-9d991600-9c25-11ea-97d4-8b40877b5250.png)

Questions:
- stat_lineribbon is really not showing the multimodality even with median_hdi. In fact it seems to be showing the 2nd mode.
- wouldn't it make sense to show a median per mode
- I would love to see your suggestions on how to better plot something like this.  

thanks!
FKG",TRUE,enhancement,2020-05-15 14:37:31,NA,"enhancement,rewrite",,OPEN,2020-11-25 19:00:50,NA,,MDU6SXNzdWU3NTEwNTM1MjU=
36,https://github.com/mjskay/ggdist/issues/36,https://github.com/mjskay/ggdist/issues/36,mjskay,improve parameter docs for slabinterval,"Need some nice way of getting all the possible arguments (including from the geoms) into the documentation page of each stat/geom. Currently the multiple-chains-of-... and the stat/geom thing make it so that some args don't propagate all the way to each documentation page. Easiest thing might be to just make a template function that does this rather than trying to use the parameter inheritance stuff.

Because of #106 this is basically done except for getting geom stuff copied into the stats in a nice way. Might actually be able to handle that using param inheritance. 

done for:
- [x] slabinterval stats
- [x] slabinterval geoms
- [x] dotsinterval stats
- [x] dotsinterval geoms
- [x] lineribbon stat
",TRUE,,FALSE,docs,2020-05-13 17:36:23,2021-12-06 00:14:33,documentation,,CLOSED,2021-12-06 00:14:33,Next release ,,MDU6SXNzdWU3NTEwNTI1ODg=
10,https://github.com/mjskay/ggdist/issues/10,https://github.com/mjskay/ggdist/issues/10,mjskay,add confidence distribution ref to freq uncertainty vis vignette,something like: https://www.stat.rutgers.edu/home/mxie/RCPapers/insr.12000.pdf,TRUE,,FALSE,docs,2020-05-11 15:10:01,2020-06-05 20:40:27,,,CLOSED,2020-06-05 20:40:27,First release,,MDU6SXNzdWU2MzE4ODYxOTE=
38,https://github.com/mjskay/ggdist/issues/38,https://github.com/mjskay/ggdist/issues/38,dylanhmorris,position_jitter() leads to duplication and separation of pointintervals,"Attempt to jitter a default ``pointinterval`` (or any ``pointinterval`` showing multiple ranges) leads to multiple separated ``pointintervals`` for each set of observations. I believe this occurs because the multiple bounds are constructed by the layering of multiple ``geom_pointinterval()`` instances on top of one another. These are then treated as separate items to jitter by ``position_jitter()``.

 Reproducible example:

```R
library(ggplot2)
library(tidybayes)
library(tibble)
library(magrittr)

## create some data
data <- tibble(
    xs = rep(c(rnorm(1), rnorm(1)), 20),
    ys = rnorm(40),
    groups = rep(rep(1:4), 10))

## plotting gives us overplotted pointintervals
data %>% ggplot(
             aes(x = xs,
                 y = ys,
                 point_fill = factor(groups),
                 group = groups)) +
    stat_pointinterval(shape = 21) +
    scale_fill_distiller()
```
[overplotted.pdf](https://github.com/mjskay/tidybayes/files/4466351/overplotted.pdf)

```R
## we try to jitter and this leads to duplication
jitter <- position_jitter(width = 0.1)
data %>% ggplot(
             aes(x = xs,
                 y = ys,
                 point_fill = factor(groups),
                 group = groups)) +
    stat_pointinterval(shape = 21,
                       position = jitter) +
    scale_fill_distiller()
```
[failed_jitter.pdf](https://github.com/mjskay/tidybayes/files/4466352/failed_jitter.pdf)",TRUE,"----------------------------
mjskay:

Copying this workaround here from [the twitter thread](https://twitter.com/mjskay/status/1249004259657560066?s=20) in case anyone wanders along looking for it: 

![image](https://user-images.githubusercontent.com/6345019/79182855-de5b6f00-7ddd-11ea-8d46-bd80f9325cd3.png)

My rough guess on this is that fixing it might require a bunch of re-architecting of slabinterval internals... unless I'm mistaken the problem is that the two intervals are different rows in the data table, which then means they are adjusted separately by position_jitter. Fixing this might require changing to list columns internally and nesting both intervals within the same row. On the one hand there might be some benefits to this approach (like allowing removal of redundant points). On the other hand it would require re-writing a bunch of stuff, and even then I'm not even sure it would completely work (e.g. in cases where someone tries to map aesthetics across different intervals within the same estimate, as one tends to do with colors in stat_interval). Would have to check that everything works fine there --- I can't remember off the top of my head if that mapping happens before the position adjustment, in which case it should work okay...

In the meantime, the above workaround should work :)

----------------------------
mjskay:

Yeah, the list approach won't work because of the need for people to be able to do additional mappings on the .width computed variable. So I think the above workaround of re-using the seed for sub-geoms is the best that can be done in this case.",TRUE,help,2020-04-12 12:54:22,2021-06-13 18:59:37,"enhancement,rewrite",,CLOSED,2021-06-13 18:59:38,NA,,MDU6SXNzdWU3NTEwNTM3MTQ=
15,https://github.com/mjskay/ggdist/issues/15,https://github.com/mjskay/ggdist/issues/15,dmi3kno,stat_dist_*() and gganimate,"I understand that `stat_dist_*()` can not be used with gganimate because it produces a list-column.
```r
library(dplyr)
library(ggplot2)
library(gganimate)
library(tidybayes)
p <- tribble(
   ~mean, ~sd, ~.iter,
   5,   1,      1,
   7,   1.5,    2,
   8,   1,      3,
   9,   1,      4,
   7,   1,      5
) %>%
  ggplot(aes(x = """", dist = ""norm"", arg1 = mean, arg2 = sd)) +
  stat_dist_eye() +
  transition_manual(.iter)

p
#> Error in mapply(FUN = f, ..., SIMPLIFY = FALSE) : 
#>   zero-length inputs cannot be mixed with those of non-zero length
```
Could you confirm that and, if possible, add something about it in the documentation?",TRUE,"----------------------------
mjskay:

Hmmmmm that's interesting... let me dig into this more. Off the top of my head (without testing) I'm not sure why this doesn't work (you might have to manually set the `group` aesthetic?) but there's probably some annoying interaction under the hood here.

----------------------------
mjskay:

Problem seems to be related to how stat_dist manipulates the `group` aesthetic internally, here: https://github.com/mjskay/ggdist/blob/54d1421be4314a6fa1b6caab56187e56f8198b05/R/stat_dist_slabinterval.R#L350-L361

Since stat_dist_lineribbon skips this and it works with gganimate as long as you set the group aesthetic (which is needed by gganimate to identify frames):

```r
data.frame(
  y = c(1,2,3,4), 
  g = c(""a"", ""a"",""b"",""b"")
) %>% 
  ggplot(aes(x = c(1:2,1:2), arg1 = y, dist = ""norm"", group = g)) + 
  stat_dist_lineribbon() + 
  transition_manual(g)
```
![stat_dist_lineribbon_animated](https://user-images.githubusercontent.com/6345019/84297389-70040600-ab1b-11ea-8f14-5c9ec955054f.gif)

So I think the solution is to not do this re-grouping here. I will try moving it later or changing the way stat_dist_slabinterval sets up the grouping and see if I can make it work. I think that grouping needs to change anyway (should be by row for most of these geoms anyway --- doesn't actually make sense for it to be otherwise, since if you have duplicate distributions that are otherwise at the same location they should still be considered to be separate generally).

----------------------------
mjskay:

K, this should work now (on the `dev` branch --- it's not on master yet):

```r
tribble(
   ~mean, ~sd, ~.iter,
   5,   1,      1,
   7,   1.5,    2,
   8,   1,      3,
   9,   1,      4,
   7,   1,      5
) %>%
  ggplot(aes(x = """", dist = ""norm"", arg1 = mean, arg2 = sd)) +
  stat_dist_eye() +
  transition_manual(.iter)
```
![ggdist-gganimate](https://user-images.githubusercontent.com/6345019/84538940-89928280-acc0-11ea-9d14-cf44e79fd714.gif)

Let me know if you have any problems with it.
",TRUE,bug,2020-03-16 14:54:45,2020-06-12 19:23:01,,,CLOSED,2020-06-12 19:24:23,NA,,MDU6SXNzdWU2MzY0MDk5NDk=
35,https://github.com/mjskay/ggdist/issues/35,https://github.com/mjskay/ggdist/issues/35,hhau,interval_size_range in geom_interval has a strange interaction with the legend,"Hello! Thanks for `tidybayes`!

I'm using `interval_size_range` as a way to increase the height of the interval (there's a lot of empty space on the y-axis without it), which is definitely not its intended use. However, it does have an annoying side effect of changing the size of the key in the legend.

Is there a better way to change the height/width of the interval? Or is there a way to change the legend key. I've tried to adjust `legend.key.height` in `ggplot2::theme`, but it appears to only affect the text size of each key.

Here's a reprex that demonstrates what I'm on about:

``` r
library(tidyverse)
library(tidybayes)
library(magrittr)
#> 
#> Attaching package: 'magrittr'
#> The following object is masked from 'package:purrr':
#> 
#>     set_names
#> The following object is masked from 'package:tidyr':
#> 
#>     extract
library(ggplot2)
library(scales)
#> 
#> Attaching package: 'scales'
#> The following object is masked from 'package:purrr':
#> 
#>     discard
#> The following object is masked from 'package:readr':
#> 
#>     col_factor

data(RankCorr, package = ""tidybayes"")

model_one_results <- RankCorr %>%
  spread_draws(u_tau[i]) %>% 
  median_qi(.width = c(.5, .8, .95, .99)) %>% 
  mutate(.model = 1) 

model_two_results <- RankCorr %>%
  spread_draws(u_tau[i]) %>% 
  mutate(u_tau = u_tau + 1) %>% 
  median_qi(.width = c(.5, .8, .95, .99)) %>% 
  mutate(.model = 2)

overall_tbl <- bind_rows(
  model_one_results,
  model_two_results
) %>% 
  mutate(.model = as.factor(.model))

ggplot(
  data = overall_tbl,
  aes(y = interaction(i, .model), x = u_tau, colour = .model)
) +
  facet_wrap(
    vars(i),
    scales = ""free"",
    ncol = 1
  ) +
  geom_intervalh(
    ## comment following line in/out to see the different in the width of 
    ## interval in the plot, and in the legend
    interval_size_range = c(12, 18),
    alpha = rescale(1 - overall_tbl$.width, to = c(0.1, 1))
  ) +
  scale_color_manual(
    aesthetics = ""colour"",
    values = c(
      ""1"" = ""#2C7FB8"",
      ""2"" = ""#B40F20""
    )
  ) 
```

![](https://i.imgur.com/BsjsHDs.png)

<sup>Created on 2020-03-10 by the [reprex package](https://reprex.tidyverse.org) (v0.3.0)</sup>",TRUE,"----------------------------
mjskay:

Hmm yeah, this is a bit problematic. `interval_size_range` is kind of hackish holdover from an older version of the API before it was possible to specify custom variants of the core aesthetics in ggplot. In general I don't recommend trying to use it for... well, anything really :). That said, I should probably make sure it doesn't interact with the legend in weird ways like this, so thanks for raising the issue!

A solution to your problem specifically might be to use the `size` aesthetic directly:

```r
ggplot(
  data = overall_tbl,
  aes(y = interaction(i, .model), x = u_tau, colour = .model)
) +
  facet_wrap(
    vars(i),
    scales = ""free"",
    ncol = 1
  ) +
  geom_intervalh(
    size = 15,
    alpha = rescale(1 - overall_tbl$.width, to = c(0.1, 1)),
  ) +
  scale_color_manual(
    aesthetics = ""colour"",
    values = c(
      ""1"" = ""#2C7FB8"",
      ""2"" = ""#B40F20""
    )
  )
```
![image](https://user-images.githubusercontent.com/6345019/76357181-997b7e80-62ed-11ea-9cc2-9b01dedae554.png)

That does *sort of* fix the legend, though the boxes are a little oversized now. However, you can override aesthetics in the legend to fix that:

```r
ggplot(
  data = overall_tbl,
  aes(y = interaction(i, .model), x = u_tau, colour = .model)
) +
  facet_wrap(
    vars(i),
    scales = ""free"",
    ncol = 1
  ) +
  geom_intervalh(
    size = 15,
    alpha = rescale(1 - overall_tbl$.width, to = c(0.1, 1)),
  ) +
  scale_color_manual(
    aesthetics = ""colour"",
    values = c(
      ""1"" = ""#2C7FB8"",
      ""2"" = ""#B40F20""
    ),
    
    # override legend aesthetics
    guide = guide_legend(override.aes = list(size = 4))
  )
```
![image](https://user-images.githubusercontent.com/6345019/76357323-df384700-62ed-11ea-88ed-be96ec773a40.png)

Does that help?


----------------------------
hhau:

Yes - exactly what I was after! Definitely should have thought about using `size` beforehand tbh.  Also definitely should have read the [Slab + interval](http://mjskay.github.io/tidybayes/articles/slabinterval.html) vignette beforehand, because it looks like I should really be using `stat_gradientinterval` instead. 

Thanks for answering my (pretty silly in hindsight) question! 

----------------------------
mjskay:

No worries, the API docs don't really make it clear that it is a hack! I'll update those

TODO for self:
- [x] update docs on `interval_size_range` (note it mostly should not be used)
- [x] ~~see if there's an easy fix for the overlapping boxes in the legend~~",TRUE,bug,2020-03-10 16:05:39,2020-11-25 19:05:00,,,CLOSED,2020-11-25 19:05:00,NA,,MDU6SXNzdWU3NTEwNDgzNjE=
21,https://github.com/mjskay/ggdist/issues/21,https://github.com/mjskay/ggdist/issues/21,jmgirard,Stan distribution functions,"I love the new `stat_dist_halfeye()` function. However, I think the current approach of matching stan distribution names to existing R functions (see below) may not be ideal. In some cases, the R function differs from the stan function in argument names, orderings, and even parameterizations. 

https://github.com/mjskay/tidybayes/blob/ed254b9920e8407536f3f2e5f7f4b034e85a0df3/R/parse_dist.R#L150-L167

To address this issue, I have been creating an R function for each stan distribution function that remains true to the stan function. See my progress at [github.com/jmgirard/standist](https://github.com/jmgirard/standist).

I wonder if you might consider using these functions in the lookup table above (similar to what is already being done for `brms::student_t()`), or permitting me to do so via PR. If you are interested, I would be open to either importing from standist or rolling this project into tidybayes.

On a related note, in that same standist repo linked above, I am working on easy single-line function calls to visualize stan distributions (for pedagogical purposes and for selecting priors). Something like `viz(""student_t(3, 0, 10)"")` or `viz(""student_t"", arg1 = seq(1, 10, 2), arg2 = 0, arg3 = 1)`. I have some basic implementation of this using `ggplot2::stat_function()` but I think it'd be more robust and flexible to use your `tidybayes::stat_dist_halfeye()` function. Any interest in collaborating on this?",FALSE,"----------------------------
mjskay:

Yeah this sounds like a great idea! Would love a PR to make this work... Would need to be careful to avoid circular dependencies if you want to build standist::viz() on top of tidybayes.

One option might be to come up with a more formal way of registering distribution mappings or of choosing desired mappings. The current approach is very ad hoc and could (should) be better. This would also help deal with the fact that if someone is using tidybayes with jags, say, they would want different parameterization than Stan; or if they wanted a base R parameterization instead of a Stan one. 

So, yeah, happy to collaborate! 

----------------------------
jmgirard:

I hadn't considered that some users might want the jags or R parameterizations. In this case, making it modular/customizable seems like the way to go. Perhaps `parse_dist()` could be made to guess which parameterization was requested and also include an explicit argument for it.

----------------------------
mjskay:

Currently the approach is that if `to_r_names = TRUE` then it uses the lookup table on normalized names and otherwise does nothing. A more generic approach would be to either allow people to swap lookup tables or give an arbitrary lookup function. The lookup table approach is probably simpler to extend except in cases where people want a more complex lookup function---but i'm struggling a bit to determine what that might look like. So one way to adjust things would be to add a parameter to `r_dist_name()` that specifies the lookup table, and add that same parameter to `parse_dist()` and pass it through to `r_dist_name()`, give it a sensible default and then have `standist` export an object containing its own lookup table that could be passed to that parameter. Thoughts?

----------------------------
jmgirard:

I wonder how many total lookup tables will be necessary. I could see one for R, one for stan, one for jags. Any others? Then an argument could point to one of these tables explicitly as you said or, in the absence of an explicit argument being provided, perhaps we could search all tables for a matching name and return a warning/error if the number of matches does not equal 1.

----------------------------
mjskay:

Yeah, there's a heavier-weight and lighter-weight variant:

1. Lookup tables are not ""registered"" in any way; any named character vector could be used as a lookup table. So some objects might be provided with names like `stan_dists` or `r_dists` or what have you that can be passed in as an argument to parse_dist. Pros: simple interface. Cons: could make life complicated if other packages have no way to ""register"" distributions to one of these lists (or would mean users have to manually combine lists in some cases). On the other hand, that might be a problem that only exists in theory (if no other packages adopt this functionality the problem never arises, so spending engineering effort solving it is a waste).

2. Lookup tables are ""registered"" through some function (and maybe also have a mechanism for packages to register functions onto specific lookup tables or something). This could make usage simpler for many common use cases (e.g. allowing users to just pass a list name). It does make things a bit more ""magical"" from an api-understanding perspective in that there is a lookup-table registration mechanism in the background that users aren't exposed to and might find harder to debug when things go wrong.

----------------------------
jmgirard:

My guess is that there will only ever be a handful of tables needed and we can probably anticipate what those will be and provide them in the package. Then we could have a small vignette or help doc of how to add a custom table for advanced users. So maybe ""registration"" is not needed.

----------------------------
mjskay:

Hmmm okay, I'm trying to think of a practical solution here that doesn't introduce a bunch more dependencies into tidybayes (which is already reasonably heavy on the deps department) and which wouldn't introduce a circular dependency with standist, while allowing us to also provide good error messages (as currently `parse_dist` errors are decidedly *not* good).

One could imagine lookup tables like:

```r
list(
  normal = ""stats::norm"",
  lognormal = ""stats::lnorm"",
  studentt = ""brms::student_t"",
)
```

Where `parse_dist` could then parse those specs into package and function family name and throw an error if the necessary package is not available during parsing (and maybe a warning if it's not loaded...). Or perhaps it would go looking for the corresponding functions and if they aren't found, check for the specified package. Another format might be more explicit, like:

```r
list(
  normal = list(""norm"", package = ""stats""),
  lognormal = list(""lnorm"", package = ""stats""),
  studentt = list(""norm"", package = ""brms""),
)
```

Where the use of the `list()` format could be optional (e.g. if a character vector of length one is provided, just search for that distribution in the loaded packages). This would also allow future extensions to search multiple packages if that's ever needed (e.g. by providing a vector to `package=`).

Then some preconfigured lists could be provided, like:

```r
r_distributions = list(...)
stan_distributions = list(...)
jags_distributions = list(...)
all_distributions = modifyList(
  modifyList(jags_distributions, stan_distributions), r_distributions
)
```

And the default would be `all_distributions`. I have some mixed feelings about dropping these variable names into the package environment, might want to think about that a bit...


----------------------------
jmgirard:

I'm going to follow your lead here, as this is your package and you're more experienced in package development than I am. I'm happy to provide a second opinion whenever helpful, but my plan is to let you decide how you want this stuff formatted. Then I can take the lead in gathering the functions up and creating the lists. I am not so familiar with JAGS so I would likely begin with implementing this for the R and STAN functions.

----------------------------
jmgirard:

This does seem like a good candidate for inclusion in ggdist. Let me know when you have time to return to it.

----------------------------
mjskay:

Yeah, there's a couple of things to consider here in light of #14.

I suspect long-term my plan is to rethink `parse_dist()` a bit and have it output distribution vectors a la #14 rather than the string-plus-args approach. If https://github.com/mitchelloharawild/distributional/issues/30 is implemented than I could imagine using it to wrap arbitrary stan distributions from brms priors and outputting those. 

On the other hand, it may then be the case that `ggdist` isn't the right place for the solution to this problem. Another way forward would be to petition @paul-buerkner to put a function in brms that outputs {distributional} vectors of brms priors, possibly using the {standist} package. Then those vectors would automatically be supported by the upcoming version of {ggdist} without having to use `ggdist::parse_dist()` at all (the `stat_dist_...` geoms on the dev branch of ggdist can already plot such objects). Would be curious what @paul-buerkner thinks about something like that?

----------------------------
paul-buerkner:

I have not yet looked at this in detail. Would you mind opening an issue on the brms issue tracker (https://github.com/paul-buerkner/brms/issues)?

----------------------------
mitchelloharawild:

The {distributional} package can now wrap arbitrary distributions (https://github.com/mitchelloharawild/distributional/issues/30).
With the recent addition of {distributional} support in {ggdist}, it should now be possible to plot arbitrary distributions:

``` r
library(ggplot2)
library(dplyr)
library(ggdist)
library(brms)
library(distributional)

tribble(
  ~ group, ~ dist,
  ""Normal"", dist_normal(mu = 0, sigma = 1),
  ""Skewed"", dist_wrap(""skew_normal"", package = ""brms"", mu = 0, sigma = 1, alpha = 10)
) %>%
  ggplot(aes(x = group, dist = dist, fill = group)) +
  stat_dist_eye(position = ""dodge"")
```

![](https://i.imgur.com/b5TEpvU.png)

<sup>Created on 2020-07-14 by the [reprex package](https://reprex.tidyverse.org) (v0.3.0)</sup>",TRUE,enhancement,2020-02-28 23:55:52,NA,,,OPEN,2020-07-14 13:59:20,NA,,MDU6SXNzdWU2NTA3ODU0MjU=
34,https://github.com/mjskay/ggdist/issues/34,https://github.com/mjskay/ggdist/issues/34,Ax3man,Further thoughts on parse_dist,"Following up on [this](https://github.com/paul-buerkner/brms/issues/694), my naive attempts fail:

```r
library(brms)
library(tidybayes)

p <- get_prior(qsec ~ hp + (1 + hp | cyl), mtcars)
parse_dist(p)

#Error in eval_tidy(enquo(dist_col), object) : object '' not found
```
Although this works, but without the rest of the table (i.e. `class`, `coef` etc.):
```r
parse_dist(p$prior)
```

I get the same error when asking for the `parse_dist` of a `prior` object:

```r
p2 <- prior(normal(0, 2))
parse_dist(p2)
```
But a direct string version works:
```r
parse_dist('normal(0, 2)')
```

I suppose my attempts fail because they are dispatching to `parse_dist.data.frame`, which requires you to define a prior column. So I defined a `brmsprior` method:
```r
parse_dist.brmsprior <- function(object, ...) tidybayes:::parse_dist.data.frame(object, 'prior', ...)
```
This works for `p2` above, but yields all NAs for `p`.",TRUE,"----------------------------
mjskay:

Ah, good points. A couple of things:

1. `parse_dist()` when used on a data frame needs the name of the column to parse. So on the results of `p = get_prior(...)` you would do something like `parse_dist(p, prior)`. I'll add an example of that to the docs and adjust the error message to be more informative, as the current message is admittedly useless :).

2. Adding an implementation for brmsprior is a good idea",TRUE,enhancement,2020-02-04 23:46:46,2020-11-25 19:04:59,,,CLOSED,2020-11-25 19:04:59,NA,,MDU6SXNzdWU3NTEwMjk3NzU=
39,https://github.com/mjskay/ggdist/issues/39,https://github.com/mjskay/ggdist/issues/39,mjskay,Add teach parameter for slabinterval shortcuts,See the ggeasy package for an example of this. Would be very useful for the slabinterval shortcut geoms. ,FALSE,#NAME?,FALSE,docs,2020-01-31 17:21:53,NA,"documentation,enhancement",,OPEN,2021-12-06 01:33:09,NA,,MDU6SXNzdWU3NTEwNTQzNzY=
89,https://github.com/mjskay/ggdist/issues/89,https://github.com/mjskay/ggdist/issues/89,crsh,ggplot extension for 2-dimensional HPD regions,"Hi there,

great package. I was wondering whether you might be interested in adding a new `ggplot2` stat and geom.

I recently wanted to plot a two-dimensional HPD region for the posterior predictions of my model. Because of my bounded outcome variable, I was unhappy with the normal approximation created with `stat_ellipse()`. Merging `emdbook::HPDregionplot()` and `StatContour()`, I came up with the following solution based on `MASS::kde2d()`:

~~~r
#' Contours of a HDP region estimate
#'
#' @param prob Numeric. Probability level of the HDP region.
#' @inheritParams ggplot2::stat_density_2d
#' @inheritParams MASS::kde2d
#' @param ...
#'
#' @return
#' @export

stat_hpd_2d <- function(mapping = NULL, data = NULL, geom = ""polygon"",
                        position = ""identity"", na.rm = FALSE, show.legend = NA,
                        inherit.aes = TRUE, n = 100, prob = 0.95, ...) {
  ggplot2::layer(
    stat = StatHPDContour, data = data, mapping = mapping, geom = geom,
    position = position, show.legend = show.legend, inherit.aes = inherit.aes,
    params = list(na.rm = na.rm, n = n, prob = prob, ...)
  )
}

StatHPDContour <- ggplot2::ggproto(
  ""hpd_2d""
  , Stat
  , compute_group = function (data, scales, na.rm = FALSE, h = NULL,
                              n = 100, prob = 0.95)
  {
    if (is.null(h)) {
      h <- c(MASS::bandwidth.nrd(data$x), MASS::bandwidth.nrd(data$y))
    }
    dens <- MASS::kde2d(data$x, data$y, h = h, n = n,
                        lims = c(scales$x$dimension(), scales$y$dimension()))
    df <- data.frame(expand.grid(x = dens$x, y = dens$y), z = as.vector(dens$z))
    df$group <- data$group[1]

    dx <- diff(dens$x[1:2])
    dy <- diff(dens$y[1:2])
    sz <- sort(dens$z)
    c1 <- cumsum(sz) * dx * dy

    breaks <- sapply(prob, function(x) {
      withCallingHandlers(
        stats::approx(c1, sz, xout = 1 - x)$y
        , warning = function(w) {
          if (grepl(""collapsing to unique 'x' values"", w$message))
            invokeRestart(""muffleWarning"")
        }
      )
    })

    ggplot2::StatContour$compute_panel(df, scales, breaks = breaks)
  }
  , required_aes = c(""x"", ""y"")
)
~~~

Here's an example:

~~~r
library(""ggplot2"")
ggplot(data = iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
    stat_hpd_2d(aes(fill = Species), prob = 0.8, alpha = 0.1, linetype = ""22"", size = 0.3) +
    geom_point(size = 3, alpha = 0.6)
~~~

![stat_hpd](https://user-images.githubusercontent.com/2195485/70143627-7a40d580-169c-11ea-81ee-b3814291a690.png)

If this is something you'd be interested in, I'd be happy to expand this into a PR (add a geom, create aliases such as `stat_hpd2d()`, etc.). What do you think?",FALSE,"----------------------------
mjskay:

This could be useful! I'm not totally clear on the difference between this and `stat_density_2d`, is it the parameterization in terms of desired mass inside the contour? (it's not immediately clear to me how to do that with `stat_density_2d` / `geom_contour` but I haven't played with them much).

----------------------------
crsh:

Good question. I probably should have laid that out more clearly.

#### Why not `stat_density_2d()`?

To control the resulting contours `stat_density_2d()` accepts only the `bins` argument, which is [passed to](https://github.com/tidyverse/ggplot2/blob/913e936ce4abfd933897ca9e5425dea76bd7d596/R/stat-density-2d.r#L80) `StatContour`. This controls how many bins are drawn, but as far as I understand, those do not readily correspond to enclosed probability masses. While `StatContour` [accepts](https://github.com/tidyverse/ggplot2/blob/913e936ce4abfd933897ca9e5425dea76bd7d596/R/stat-contour.r#L102) a `breaks` argument, which would grant greater control, this is not accessible from `stat_density_2d()`.

#### Why not `stat_contour()`?

`stat_contour()` requires a `z` aesthetic. So in order to do the above, it would be necessary to first call, for example, `MASS::kde2d()` manually (for each group), then call `stat_contour()`, and pass the `breaks` argument, which seems inconvenient. Moreover,`StatContour` does not accept breaks in units of enclosed probability mass, which I find very useful to visualize estimate uncertainty.

----------------------------
mjskay:

Makes sense. Okay yeah, I'd be happy to have something like this. I think it would be good if it was similar to stat_lineribbon in that:

- it can provide multiple levels a vector parameter of desired probability masses

- all regions with the same mass are drawn below all other regions with less mass (e.g. if the user asks for 95, 80, and 50% regions, all 95% regions are drawn, then 80% regions, then 50% regions). `geom_lineribbon` currently does this (in a fairly hackish way that could be better I think) so that if you use transparency and you have multiple different groups with some overlap it is easier to see both groups. This gives an interleaving effect that you can see in this example from `vignette(""tidy-brms"")`:

![image](https://user-images.githubusercontent.com/6345019/70569384-d9ed2400-1b67-11ea-8af7-2f43956aec44.png)

- (possibly) might be nice to be able to do a point summary as well. Having a point summary in there would potentially allow for easy uncertainty-including scatterplots of parameters, which could be cool.

Happy to accept a PR on this if you want to take it on. Name-wise I'm not too keen on ""HPD"" (there's no reason you have to use it on a posterior) so maybe something that echos ""HDI"" or even a non-acronym form (like ""geom_density_region"") might be good.

----------------------------
crsh:

Sounds good to me. I'm not sure how soon I'll get around to it, but I'll give it a go.

----------------------------
mjskay:

Great, thanks!

----------------------------
mjskay:

Moving this issue to {ggdist} as all the geoms and stuff have been moved there.

----------------------------
avehtari:

ggdensity extension to ggplot seems great for plotting 2D HPD regions
https://jamesotto852.github.io/ggdensity/",TRUE,enhancement,2019-12-04 12:55:40,NA,,,OPEN,2022-01-21 13:17:36,NA,,MDU6SXNzdWU5NDE2MDY1NDk=
42,https://github.com/mjskay/ggdist/issues/42,https://github.com/mjskay/ggdist/issues/42,mjskay,fix dotsinterval on discrete distributions,currently breaks on factors because all bins are used. Need a better fallback when min number of bins produces columns that are too tall.,TRUE,,FALSE,bug,2019-08-19 03:22:30,2021-06-12 06:49:15,bug,,CLOSED,2021-06-12 06:49:15,NA,,MDU6SXNzdWU3NTEwNTU2MTU=
40,https://github.com/mjskay/ggdist/issues/40,https://github.com/mjskay/ggdist/issues/40,mjskay,Create custom scales / aesthetics for lineribbons,"including:

- [ ] make alpha only apply to ribbons by default (? - might need to remove duplicate lines)
- [ ] make aesthetics to target alpha on ribbon versus line separately
- [ ] outline color on ribbons",FALSE,"----------------------------
ASKurz:

Just ran into this problem. I'd like to set ribbon fill, but not the line, semitransparent. Is there a current workaround for this?

----------------------------
mjskay:

The simplest workaround would probably be to disable the line (`color = NA`) and then draw the line as a separate geom. That, or you could try assigning a fill color that has an alpha component to it (not 100% sure that would work)

----------------------------
ASKurz:

Got it. After playing around, this works:

```
data %>% 
  ggplot(aes(x = x, y = Estimate, ymin = Q2.5, ymax = Q97.5,
             fill = condition, color = condition)) +
  geom_lineribbon() +
  scale_fill_viridis_d(alpha = 1/2) +
  scale_color_viridis_d()
```

----------------------------
mjskay:

Awesome! Had no idea the color scales had an alpha argument, that's very useful! ",FALSE,enhancement,2019-08-19 02:08:10,NA,enhancement,,OPEN,2020-11-25 19:02:08,NA,,MDU6SXNzdWU3NTEwNTQ3NDA=
41,https://github.com/mjskay/ggdist/issues/41,https://github.com/mjskay/ggdist/issues/41,mjskay,support weight aes in stat_sample_slabinterval,"To make everything consistent this would be a bit of a pain, so leaving it off for now. Would need to:

- [x] make a `weighted_ecdf()` function to support CDFs
- [x] make a `weighted_quantile()` function to support quantiles
- [x] make a `weighted_hist()` function to support histograms
- [ ] pull out weight aes into a list column when x/y are summarized into `dist` in compute_panel
- [ ] pass through weight to `density`, `weighted_ecdf`, and `weighted_quantile` for slabs
- [ ] use weighted histograms to support histinterval
- [ ] add support for weights in point_interval
",FALSE,,FALSE,enhancement,2019-08-04 02:40:46,NA,enhancement,,OPEN,2022-12-22 04:14:25,NA,,MDU6SXNzdWU3NTEwNTUwNzI=
43,https://github.com/mjskay/ggdist/issues/43,https://github.com/mjskay/ggdist/issues/43,mjskay,create a geom_pointinterval_2d / stat_pointinterval_2d,seems like it would be useful. Might be able to do it without creating a whole new geom after implementing #104 ,FALSE,,FALSE,enhancement,2019-07-25 03:56:20,NA,enhancement,,OPEN,2021-12-06 01:29:38,NA,,MDU6SXNzdWU3NTEwNTU3NzY=
